digraph {
	graph [size="707.55,707.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140303204616288 [label="
 (1, 1, 128, 128)" fillcolor=darkolivegreen1]
	140303207286864 [label=ConvolutionBackward0]
	140303207286096 -> 140303207286864
	140303207286096 [label=ReluBackward0]
	140303207286672 -> 140303207286096
	140303207286672 [label=CudnnBatchNormBackward0]
	140303207285760 -> 140303207286672
	140303207285760 [label=ConvolutionBackward0]
	140303207285184 -> 140303207285760
	140303207285184 [label=ReluBackward0]
	140303207284944 -> 140303207285184
	140303207284944 [label=CudnnBatchNormBackward0]
	140303207284800 -> 140303207284944
	140303207284800 [label=ConvolutionBackward0]
	140302955331152 -> 140303207284800
	140302955331152 [label=UpsampleNearest2DBackward0]
	140302518876768 -> 140302955331152
	140302518876768 [label=ReluBackward0]
	140303253257904 -> 140302518876768
	140303253257904 [label=CudnnBatchNormBackward0]
	140303202757520 -> 140303253257904
	140303202757520 [label=ConvolutionBackward0]
	140303202758432 -> 140303202757520
	140303202758432 [label=ReluBackward0]
	140303202759152 -> 140303202758432
	140303202759152 [label=CudnnBatchNormBackward0]
	140303202759584 -> 140303202759152
	140303202759584 [label=ConvolutionBackward0]
	140303202760256 -> 140303202759584
	140303202760256 [label=CatBackward0]
	140303202760544 -> 140303202760256
	140303202760544 [label=UpsampleNearest2DBackward0]
	140303202761264 -> 140303202760544
	140303202761264 [label=ReluBackward0]
	140303202761696 -> 140303202761264
	140303202761696 [label=CudnnBatchNormBackward0]
	140303202762512 -> 140303202761696
	140303202762512 [label=ConvolutionBackward0]
	140303202755936 -> 140303202762512
	140303202755936 [label=ReluBackward0]
	140303202756560 -> 140303202755936
	140303202756560 [label=CudnnBatchNormBackward0]
	140303202753344 -> 140303202756560
	140303202753344 [label=ConvolutionBackward0]
	140303202754112 -> 140303202753344
	140303202754112 [label=CatBackward0]
	140303202754256 -> 140303202754112
	140303202754256 [label=UpsampleNearest2DBackward0]
	140303202754352 -> 140303202754256
	140303202754352 [label=ReluBackward0]
	140303202754496 -> 140303202754352
	140303202754496 [label=CudnnBatchNormBackward0]
	140303202754640 -> 140303202754496
	140303202754640 [label=ConvolutionBackward0]
	140303202755072 -> 140303202754640
	140303202755072 [label=ReluBackward0]
	140303202755408 -> 140303202755072
	140303202755408 [label=CudnnBatchNormBackward0]
	140303202755552 -> 140303202755408
	140303202755552 [label=ConvolutionBackward0]
	140303202756704 -> 140303202755552
	140303202756704 [label=CatBackward0]
	140303202755696 -> 140303202756704
	140303202755696 [label=UpsampleNearest2DBackward0]
	140303202753824 -> 140303202755696
	140303202753824 [label=ReluBackward0]
	140303202756512 -> 140303202753824
	140303202756512 [label=CudnnBatchNormBackward0]
	140303202753632 -> 140303202756512
	140303202753632 [label=ConvolutionBackward0]
	140303206458144 -> 140303202753632
	140303206458144 [label=ReluBackward0]
	140303206458288 -> 140303206458144
	140303206458288 [label=CudnnBatchNormBackward0]
	140303206458384 -> 140303206458288
	140303206458384 [label=ConvolutionBackward0]
	140303205680272 -> 140303206458384
	140303205680272 [label=CatBackward0]
	140303205562352 -> 140303205680272
	140303205562352 [label=UpsampleNearest2DBackward0]
	140303257682752 -> 140303205562352
	140303257682752 [label=ReluBackward0]
	140303257682848 -> 140303257682752
	140303257682848 [label=CudnnBatchNormBackward0]
	140303257682944 -> 140303257682848
	140303257682944 [label=ConvolutionBackward0]
	140303257683136 -> 140303257682944
	140303257683136 [label=AddBackward0]
	140303257683280 -> 140303257683136
	140303257683280 [label=MulBackward0]
	140303207103984 -> 140303257683280
	140303207103984 [label=ConvolutionBackward0]
	140303207103792 -> 140303207103984
	140303207103792 [label=CatBackward0]
	140303207103408 -> 140303207103792
	140303207103408 [label=ReluBackward0]
	140303207102880 -> 140303207103408
	140303207102880 [label=CudnnBatchNormBackward0]
	140303207102688 -> 140303207102880
	140303207102688 [label=ConvolutionBackward0]
	140303207104416 -> 140303207102688
	140303207104416 [label=ReluBackward0]
	140303207101920 -> 140303207104416
	140303207101920 [label=AddBackward0]
	140303207101728 -> 140303207101920
	140303207101728 [label=MulBackward0]
	140303207101488 -> 140303207101728
	140303207101488 [label=ConvolutionBackward0]
	140303207101200 -> 140303207101488
	140303207101200 [label=CatBackward0]
	140303207100624 -> 140303207101200
	140303207100624 [label=ReluBackward0]
	140303207100288 -> 140303207100624
	140303207100288 [label=CudnnBatchNormBackward0]
	140303207099904 -> 140303207100288
	140303207099904 [label=ConvolutionBackward0]
	140303207101872 -> 140303207099904
	140303207101872 [label=ReluBackward0]
	140303207099328 -> 140303207101872
	140303207099328 [label=AddBackward0]
	140303207098944 -> 140303207099328
	140303207098944 [label=MulBackward0]
	140303207098704 -> 140303207098944
	140303207098704 [label=ConvolutionBackward0]
	140303207098512 -> 140303207098704
	140303207098512 [label=CatBackward0]
	140303207097936 -> 140303207098512
	140303207097936 [label=ReluBackward0]
	140303207097600 -> 140303207097936
	140303207097600 [label=CudnnBatchNormBackward0]
	140303207097408 -> 140303207097600
	140303207097408 [label=ConvolutionBackward0]
	140303207099280 -> 140303207097408
	140303207099280 [label=ReluBackward0]
	140303207094144 -> 140303207099280
	140303207094144 [label=AddBackward0]
	140303207097120 -> 140303207094144
	140303207097120 [label=MulBackward0]
	140303251390272 -> 140303207097120
	140303251390272 [label=ConvolutionBackward0]
	140303207202240 -> 140303251390272
	140303207202240 [label=CatBackward0]
	140303207201856 -> 140303207202240
	140303207201856 [label=ReluBackward0]
	140303207201616 -> 140303207201856
	140303207201616 [label=CudnnBatchNormBackward0]
	140303207201232 -> 140303207201616
	140303207201232 [label=ConvolutionBackward0]
	140303251390080 -> 140303207201232
	140303251390080 [label=ReluBackward0]
	140303207200656 -> 140303251390080
	140303207200656 [label=AddBackward0]
	140303207200272 -> 140303207200656
	140303207200272 [label=MulBackward0]
	140303207199936 -> 140303207200272
	140303207199936 [label=ConvolutionBackward0]
	140303207199744 -> 140303207199936
	140303207199744 [label=CatBackward0]
	140303207199168 -> 140303207199744
	140303207199168 [label=ReluBackward0]
	140303207198928 -> 140303207199168
	140303207198928 [label=CudnnBatchNormBackward0]
	140303207198736 -> 140303207198928
	140303207198736 [label=ConvolutionBackward0]
	140303207200320 -> 140303207198736
	140303207200320 [label=ReluBackward0]
	140303207197968 -> 140303207200320
	140303207197968 [label=AddBackward0]
	140303207197776 -> 140303207197968
	140303207197776 [label=MulBackward0]
	140303207197248 -> 140303207197776
	140303207197248 [label=ConvolutionBackward0]
	140303207197056 -> 140303207197248
	140303207197056 [label=CatBackward0]
	140303207196480 -> 140303207197056
	140303207196480 [label=ReluBackward0]
	140303207196240 -> 140303207196480
	140303207196240 [label=CudnnBatchNormBackward0]
	140303207196048 -> 140303207196240
	140303207196048 [label=ConvolutionBackward0]
	140303207197824 -> 140303207196048
	140303207197824 [label=ReluBackward0]
	140303207195184 -> 140303207197824
	140303207195184 [label=AddBackward0]
	140303207194992 -> 140303207195184
	140303207194992 [label=MulBackward0]
	140303207194656 -> 140303207194992
	140303207194656 [label=ConvolutionBackward0]
	140303207194272 -> 140303207194656
	140303207194272 [label=CatBackward0]
	140303207193888 -> 140303207194272
	140303207193888 [label=ReluBackward0]
	140303207193648 -> 140303207193888
	140303207193648 [label=CudnnBatchNormBackward0]
	140303207193312 -> 140303207193648
	140303207193312 [label=ConvolutionBackward0]
	140303207195040 -> 140303207193312
	140303207195040 [label=ReluBackward0]
	140303207192352 -> 140303207195040
	140303207192352 [label=AddBackward0]
	140303207192304 -> 140303207192352
	140303207192304 [label=MulBackward0]
	140303207191776 -> 140303207192304
	140303207191776 [label=ConvolutionBackward0]
	140303207191488 -> 140303207191776
	140303207191488 [label=CatBackward0]
	140303207190912 -> 140303207191488
	140303207190912 [label=ReluBackward0]
	140303207190672 -> 140303207190912
	140303207190672 [label=CudnnBatchNormBackward0]
	140303207190528 -> 140303207190672
	140303207190528 [label=ConvolutionBackward0]
	140303207192928 -> 140303207190528
	140303207192928 [label=ReluBackward0]
	140303207189568 -> 140303207192928
	140303207189568 [label=AddBackward0]
	140303207189520 -> 140303207189568
	140303207189520 [label=MulBackward0]
	140303207188800 -> 140303207189520
	140303207188800 [label=ConvolutionBackward0]
	140303207188608 -> 140303207188800
	140303207188608 [label=CatBackward0]
	140303207188032 -> 140303207188608
	140303207188032 [label=ReluBackward0]
	140303207187792 -> 140303207188032
	140303207187792 [label=CudnnBatchNormBackward0]
	140303207187648 -> 140303207187792
	140303207187648 [label=ConvolutionBackward0]
	140303207189952 -> 140303207187648
	140303207189952 [label=ReluBackward0]
	140303207186592 -> 140303207189952
	140303207186592 [label=AddBackward0]
	140303207202432 -> 140303207186592
	140303207202432 [label=MulBackward0]
	140303207202528 -> 140303207202432
	140303207202528 [label=ConvolutionBackward0]
	140303252374960 -> 140303207202528
	140303252374960 [label=CatBackward0]
	140303252375152 -> 140303252374960
	140303252375152 [label=ReluBackward0]
	140303252375296 -> 140303252375152
	140303252375296 [label=CudnnBatchNormBackward0]
	140303252375344 -> 140303252375296
	140303252375344 [label=ConvolutionBackward0]
	140303207186976 -> 140303252375344
	140303207186976 [label=CatBackward0]
	140303252589440 -> 140303207186976
	140303252589440 [label=ReluBackward0]
	140303252589632 -> 140303252589440
	140303252589632 [label=CudnnBatchNormBackward0]
	140303252589680 -> 140303252589632
	140303252589680 [label=ConvolutionBackward0]
	140303253323984 -> 140303252589680
	140303253323984 [label=ReluBackward0]
	140302954560048 -> 140303253323984
	140302954560048 [label=CudnnBatchNormBackward0]
	140302954554576 -> 140302954560048
	140302954554576 [label=ConvolutionBackward0]
	140303257686784 -> 140302954554576
	140303257686784 [label=ReluBackward0]
	140302006123680 -> 140303257686784
	140302006123680 [label=AddBackward0]
	140302006123488 -> 140302006123680
	140302006123488 [label=MulBackward0]
	140302949884320 -> 140302006123488
	140302949884320 [label=ConvolutionBackward0]
	140302949891712 -> 140302949884320
	140302949891712 [label=CatBackward0]
	140302949891280 -> 140302949891712
	140302949891280 [label=ReluBackward0]
	140302949888976 -> 140302949891280
	140302949888976 [label=CudnnBatchNormBackward0]
	140302949886864 -> 140302949888976
	140302949886864 [label=ConvolutionBackward0]
	140302006123440 -> 140302949886864
	140302006123440 [label=ReluBackward0]
	140302949886528 -> 140302006123440
	140302949886528 [label=AddBackward0]
	140302949878320 -> 140302949886528
	140302949878320 [label=MulBackward0]
	140302949879568 -> 140302949878320
	140302949879568 [label=ConvolutionBackward0]
	140302949878368 -> 140302949879568
	140302949878368 [label=CatBackward0]
	140302949883024 -> 140302949878368
	140302949883024 [label=ReluBackward0]
	140302949876976 -> 140302949883024
	140302949876976 [label=CudnnBatchNormBackward0]
	140302949888640 -> 140302949876976
	140302949888640 [label=ConvolutionBackward0]
	140302949882544 -> 140302949888640
	140302949882544 [label=ReluBackward0]
	140302949891328 -> 140302949882544
	140302949891328 [label=AddBackward0]
	140302949890704 -> 140302949891328
	140302949890704 [label=MulBackward0]
	140302949891472 -> 140302949890704
	140302949891472 [label=ConvolutionBackward0]
	140302949877312 -> 140302949891472
	140302949877312 [label=CatBackward0]
	140302949877168 -> 140302949877312
	140302949877168 [label=ReluBackward0]
	140303249097776 -> 140302949877168
	140303249097776 [label=CudnnBatchNormBackward0]
	140303249099888 -> 140303249097776
	140303249099888 [label=ConvolutionBackward0]
	140302949889984 -> 140303249099888
	140302949889984 [label=ReluBackward0]
	140303249098976 -> 140302949889984
	140303249098976 [label=AddBackward0]
	140303249099120 -> 140303249098976
	140303249099120 [label=MulBackward0]
	140303249098736 -> 140303249099120
	140303249098736 [label=ConvolutionBackward0]
	140303249098544 -> 140303249098736
	140303249098544 [label=CatBackward0]
	140303249098688 -> 140303249098544
	140303249098688 [label=ReluBackward0]
	140303249097968 -> 140303249098688
	140303249097968 [label=CudnnBatchNormBackward0]
	140303249097872 -> 140303249097968
	140303249097872 [label=ConvolutionBackward0]
	140303249099792 -> 140303249097872
	140303249099792 [label=ReluBackward0]
	140303249097632 -> 140303249099792
	140303249097632 [label=AddBackward0]
	140303249097680 -> 140303249097632
	140303249097680 [label=MulBackward0]
	140303249100320 -> 140303249097680
	140303249100320 [label=ConvolutionBackward0]
	140303256237104 -> 140303249100320
	140303256237104 [label=CatBackward0]
	140303256229424 -> 140303256237104
	140303256229424 [label=ReluBackward0]
	140303256227744 -> 140303256229424
	140303256227744 [label=CudnnBatchNormBackward0]
	140303256227120 -> 140303256227744
	140303256227120 [label=ConvolutionBackward0]
	140303249097488 -> 140303256227120
	140303249097488 [label=ReluBackward0]
	140303256107952 -> 140303249097488
	140303256107952 [label=AddBackward0]
	140303256107328 -> 140303256107952
	140303256107328 [label=MulBackward0]
	140303256104592 -> 140303256107328
	140303256104592 [label=ConvolutionBackward0]
	140303256103344 -> 140303256104592
	140303256103344 [label=CatBackward0]
	140303256101232 -> 140303256103344
	140303256101232 [label=ReluBackward0]
	140303256099552 -> 140303256101232
	140303256099552 [label=CudnnBatchNormBackward0]
	140303256098928 -> 140303256099552
	140303256098928 [label=ConvolutionBackward0]
	140303256109008 -> 140303256098928
	140303256109008 [label=ReluBackward0]
	140303256094512 -> 140303256109008
	140303256094512 [label=AddBackward0]
	140303256093888 -> 140303256094512
	140303256093888 [label=MulBackward0]
	140303256055488 -> 140303256093888
	140303256055488 [label=ConvolutionBackward0]
	140303256054384 -> 140303256055488
	140303256054384 [label=CatBackward0]
	140303256049584 -> 140303256054384
	140303256049584 [label=ReluBackward0]
	140303256053568 -> 140303256049584
	140303256053568 [label=CudnnBatchNormBackward0]
	140303256059856 -> 140303256053568
	140303256059856 [label=ConvolutionBackward0]
	140303256096624 -> 140303256059856
	140303256096624 [label=ReluBackward0]
	140303256059280 -> 140303256096624
	140303256059280 [label=AddBackward0]
	140303256059136 -> 140303256059280
	140303256059136 [label=MulBackward0]
	140303256058800 -> 140303256059136
	140303256058800 [label=ConvolutionBackward0]
	140303256058656 -> 140303256058800
	140303256058656 [label=CatBackward0]
	140303256058416 -> 140303256058656
	140303256058416 [label=ReluBackward0]
	140303256058176 -> 140303256058416
	140303256058176 [label=CudnnBatchNormBackward0]
	140303256058128 -> 140303256058176
	140303256058128 [label=ConvolutionBackward0]
	140303256059712 -> 140303256058128
	140303256059712 [label=ReluBackward0]
	140303256057456 -> 140303256059712
	140303256057456 [label=AddBackward0]
	140303256057360 -> 140303256057456
	140303256057360 [label=MulBackward0]
	140303256056976 -> 140303256057360
	140303256056976 [label=ConvolutionBackward0]
	140303256056592 -> 140303256056976
	140303256056592 [label=CatBackward0]
	140303256056352 -> 140303256056592
	140303256056352 [label=ReluBackward0]
	140303256056160 -> 140303256056352
	140303256056160 [label=CudnnBatchNormBackward0]
	140303256056112 -> 140303256056160
	140303256056112 [label=ConvolutionBackward0]
	140303256057744 -> 140303256056112
	140303256057744 [label=ReluBackward0]
	140303256055536 -> 140303256057744
	140303256055536 [label=AddBackward0]
	140303256055440 -> 140303256055536
	140303256055440 [label=MulBackward0]
	140303256055248 -> 140303256055440
	140303256055248 [label=ConvolutionBackward0]
	140303256055056 -> 140303256055248
	140303256055056 [label=CatBackward0]
	140303256054720 -> 140303256055056
	140303256054720 [label=ReluBackward0]
	140303256054336 -> 140303256054720
	140303256054336 [label=CudnnBatchNormBackward0]
	140303256054240 -> 140303256054336
	140303256054240 [label=ConvolutionBackward0]
	140303256055872 -> 140303256054240
	140303256055872 [label=ReluBackward0]
	140303256053520 -> 140303256055872
	140303256053520 [label=AddBackward0]
	140303256053472 -> 140303256053520
	140303256053472 [label=MulBackward0]
	140303256053088 -> 140303256053472
	140303256053088 [label=ConvolutionBackward0]
	140303256052944 -> 140303256053088
	140303256052944 [label=CatBackward0]
	140303256052656 -> 140303256052944
	140303256052656 [label=ReluBackward0]
	140303256052464 -> 140303256052656
	140303256052464 [label=CudnnBatchNormBackward0]
	140303256052320 -> 140303256052464
	140303256052320 [label=ConvolutionBackward0]
	140303256053808 -> 140303256052320
	140303256053808 [label=ReluBackward0]
	140303256056304 -> 140303256053808
	140303256056304 [label=AddBackward0]
	140303256051840 -> 140303256056304
	140303256051840 [label=MulBackward0]
	140303256051504 -> 140303256051840
	140303256051504 [label=ConvolutionBackward0]
	140303256051360 -> 140303256051504
	140303256051360 [label=CatBackward0]
	140303256050976 -> 140303256051360
	140303256050976 [label=ReluBackward0]
	140303256050736 -> 140303256050976
	140303256050736 [label=CudnnBatchNormBackward0]
	140303256054912 -> 140303256050736
	140303256054912 [label=ConvolutionBackward0]
	140303256052080 -> 140303256054912
	140303256052080 [label=ReluBackward0]
	140303256050256 -> 140303256052080
	140303256050256 [label=AddBackward0]
	140303256050208 -> 140303256050256
	140303256050208 [label=MulBackward0]
	140303256049872 -> 140303256050208
	140303256049872 [label=ConvolutionBackward0]
	140303256049728 -> 140303256049872
	140303256049728 [label=CatBackward0]
	140303256049344 -> 140303256049728
	140303256049344 [label=ReluBackward0]
	140303256049152 -> 140303256049344
	140303256049152 [label=CudnnBatchNormBackward0]
	140303256049056 -> 140303256049152
	140303256049056 [label=ConvolutionBackward0]
	140303256047424 -> 140303256049056
	140303256047424 [label=ReluBackward0]
	140303256048480 -> 140303256047424
	140303256048480 [label=AddBackward0]
	140303256048336 -> 140303256048480
	140303256048336 [label=MulBackward0]
	140303256047760 -> 140303256048336
	140303256047760 [label=ConvolutionBackward0]
	140303256047616 -> 140303256047760
	140303256047616 [label=CatBackward0]
	140303256047280 -> 140303256047616
	140303256047280 [label=ReluBackward0]
	140303256046992 -> 140303256047280
	140303256046992 [label=CudnnBatchNormBackward0]
	140303256046848 -> 140303256046992
	140303256046848 [label=ConvolutionBackward0]
	140303256048720 -> 140303256046848
	140303256048720 [label=ReluBackward0]
	140303256046176 -> 140303256048720
	140303256046176 [label=AddBackward0]
	140303256046080 -> 140303256046176
	140303256046080 [label=MulBackward0]
	140303256045696 -> 140303256046080
	140303256045696 [label=ConvolutionBackward0]
	140303256045552 -> 140303256045696
	140303256045552 [label=CatBackward0]
	140303256045168 -> 140303256045552
	140303256045168 [label=ReluBackward0]
	140303256044976 -> 140303256045168
	140303256044976 [label=CudnnBatchNormBackward0]
	140303256044928 -> 140303256044976
	140303256044928 [label=ConvolutionBackward0]
	140303256046560 -> 140303256044928
	140303256046560 [label=ReluBackward0]
	140303256044256 -> 140303256046560
	140303256044256 [label=AddBackward0]
	140303256044160 -> 140303256044256
	140303256044160 [label=MulBackward0]
	140303256043728 -> 140303256044160
	140303256043728 [label=ConvolutionBackward0]
	140303256043632 -> 140303256043728
	140303256043632 [label=CatBackward0]
	140303256044016 -> 140303256043632
	140303256044016 [label=ReluBackward0]
	140303256044208 -> 140303256044016
	140303256044208 [label=CudnnBatchNormBackward0]
	140303256054000 -> 140303256044208
	140303256054000 [label=ConvolutionBackward0]
	140303256044688 -> 140303256054000
	140303256044688 [label=ReluBackward0]
	140303256057264 -> 140303256044688
	140303256057264 [label=AddBackward0]
	140303256056640 -> 140303256057264
	140303256056640 [label=MulBackward0]
	140303256053904 -> 140303256056640
	140303256053904 [label=ConvolutionBackward0]
	140303256052848 -> 140303256053904
	140303256052848 [label=CatBackward0]
	140303256050544 -> 140303256052848
	140303256050544 [label=ReluBackward0]
	140303256048864 -> 140303256050544
	140303256048864 [label=CudnnBatchNormBackward0]
	140303256048240 -> 140303256048864
	140303256048240 [label=ConvolutionBackward0]
	140303256059376 -> 140303256048240
	140303256059376 [label=ReluBackward0]
	140303256043824 -> 140303256059376
	140303256043824 [label=AddBackward0]
	140303255941952 -> 140303256043824
	140303255941952 [label=MulBackward0]
	140303255939072 -> 140303255941952
	140303255939072 [label=ConvolutionBackward0]
	140303255937392 -> 140303255939072
	140303255937392 [label=CatBackward0]
	140303255934464 -> 140303255937392
	140303255934464 [label=ReluBackward0]
	140303255945024 -> 140303255934464
	140303255945024 [label=CudnnBatchNormBackward0]
	140303255944400 -> 140303255945024
	140303255944400 [label=ConvolutionBackward0]
	140303255929472 -> 140303255944400
	140303255929472 [label=ReluBackward0]
	140303255939984 -> 140303255929472
	140303255939984 [label=AddBackward0]
	140303255939360 -> 140303255939984
	140303255939360 [label=MulBackward0]
	140303255936000 -> 140303255939360
	140303255936000 [label=ConvolutionBackward0]
	140303255934944 -> 140303255936000
	140303255934944 [label=CatBackward0]
	140303255933264 -> 140303255934944
	140303255933264 [label=ReluBackward0]
	140303206983536 -> 140303255933264
	140303206983536 [label=CudnnBatchNormBackward0]
	140302584750592 -> 140303206983536
	140302584750592 [label=ConvolutionBackward0]
	140303255942096 -> 140302584750592
	140303255942096 [label=ReluBackward0]
	140303255851296 -> 140303255942096
	140303255851296 [label=AddBackward0]
	140303255847168 -> 140303255851296
	140303255847168 [label=MulBackward0]
	140303255848704 -> 140303255847168
	140303255848704 [label=ConvolutionBackward0]
	140303255850528 -> 140303255848704
	140303255850528 [label=CatBackward0]
	140303255853072 -> 140303255850528
	140303255853072 [label=ReluBackward0]
	140303255852016 -> 140303255853072
	140303255852016 [label=CudnnBatchNormBackward0]
	140303255862912 -> 140303255852016
	140303255862912 [label=ConvolutionBackward0]
	140303255855520 -> 140303255862912
	140303255855520 [label=CatBackward0]
	140303255856864 -> 140303255855520
	140303255856864 [label=ReluBackward0]
	140303255861616 -> 140303255856864
	140303255861616 [label=CudnnBatchNormBackward0]
	140303255859072 -> 140303255861616
	140303255859072 [label=ConvolutionBackward0]
	140303202755840 -> 140303255859072
	140303202755840 [label=ReluBackward0]
	140303255849568 -> 140303202755840
	140303255849568 [label=AddBackward0]
	140303255854944 -> 140303255849568
	140303255854944 [label=MulBackward0]
	140303255862192 -> 140303255854944
	140303255862192 [label=ConvolutionBackward0]
	140303255860944 -> 140303255862192
	140303255860944 [label=CatBackward0]
	140303255858832 -> 140303255860944
	140303255858832 [label=ReluBackward0]
	140303255856528 -> 140303255858832
	140303255856528 [label=CudnnBatchNormBackward0]
	140303255856096 -> 140303255856528
	140303255856096 [label=ConvolutionBackward0]
	140303255858400 -> 140303255856096
	140303255858400 [label=ReluBackward0]
	140303255851680 -> 140303255858400
	140303255851680 [label=AddBackward0]
	140303255851056 -> 140303255851680
	140303255851056 [label=MulBackward0]
	140303255848320 -> 140303255851056
	140303255848320 [label=ConvolutionBackward0]
	140303255847072 -> 140303255848320
	140303255847072 [label=CatBackward0]
	140303255766352 -> 140303255847072
	140303255766352 [label=ReluBackward0]
	140303255767216 -> 140303255766352
	140303255767216 [label=CudnnBatchNormBackward0]
	140303255766208 -> 140303255767216
	140303255766208 [label=ConvolutionBackward0]
	140303255853792 -> 140303255766208
	140303255853792 [label=ReluBackward0]
	140303255778976 -> 140303255853792
	140303255778976 [label=AddBackward0]
	140303255765056 -> 140303255778976
	140303255765056 [label=MulBackward0]
	140303255776480 -> 140303255765056
	140303255776480 [label=ConvolutionBackward0]
	140303255777392 -> 140303255776480
	140303255777392 [label=CatBackward0]
	140303255767552 -> 140303255777392
	140303255767552 [label=ReluBackward0]
	140303255771296 -> 140303255767552
	140303255771296 [label=CudnnBatchNormBackward0]
	140303255771680 -> 140303255771296
	140303255771680 [label=ConvolutionBackward0]
	140303255780896 -> 140303255771680
	140303255780896 [label=ReluBackward0]
	140303255779792 -> 140303255780896
	140303255779792 [label=AddBackward0]
	140303255779360 -> 140303255779792
	140303255779360 [label=MulBackward0]
	140303255776624 -> 140303255779360
	140303255776624 [label=ConvolutionBackward0]
	140303255775376 -> 140303255776624
	140303255775376 [label=CatBackward0]
	140303255773264 -> 140303255775376
	140303255773264 [label=ReluBackward0]
	140303255770960 -> 140303255773264
	140303255770960 [label=CudnnBatchNormBackward0]
	140303255770528 -> 140303255770960
	140303255770528 [label=ConvolutionBackward0]
	140303255779264 -> 140303255770528
	140303255779264 [label=ReluBackward0]
	140303255765920 -> 140303255779264
	140303255765920 [label=AddBackward0]
	140303255768224 -> 140303255765920
	140303255768224 [label=MulBackward0]
	140303255697152 -> 140303255768224
	140303255697152 [label=ConvolutionBackward0]
	140303255695904 -> 140303255697152
	140303255695904 [label=CatBackward0]
	140303255693792 -> 140303255695904
	140303255693792 [label=ReluBackward0]
	140303255691488 -> 140303255693792
	140303255691488 [label=CudnnBatchNormBackward0]
	140303255690864 -> 140303255691488
	140303255690864 [label=ConvolutionBackward0]
	140303255699264 -> 140303255690864
	140303255699264 [label=ReluBackward0]
	140303255686448 -> 140303255699264
	140303255686448 [label=AddBackward0]
	140303255685824 -> 140303255686448
	140303255685824 [label=MulBackward0]
	140303255683712 -> 140303255685824
	140303255683712 [label=ConvolutionBackward0]
	140303255601104 -> 140303255683712
	140303255601104 [label=CatBackward0]
	140303255598800 -> 140303255601104
	140303255598800 [label=ReluBackward0]
	140303255596688 -> 140303255598800
	140303255596688 [label=CudnnBatchNormBackward0]
	140303255596064 -> 140303255596688
	140303255596064 [label=ConvolutionBackward0]
	140303255688752 -> 140303255596064
	140303255688752 [label=ReluBackward0]
	140303255591648 -> 140303255688752
	140303255591648 [label=AddBackward0]
	140303255591024 -> 140303255591648
	140303255591024 [label=MulBackward0]
	140303255588288 -> 140303255591024
	140303255588288 [label=ConvolutionBackward0]
	140303255587232 -> 140303255588288
	140303255587232 [label=CatBackward0]
	140303255584928 -> 140303255587232
	140303255584928 [label=ReluBackward0]
	140303255517216 -> 140303255584928
	140303255517216 [label=CudnnBatchNormBackward0]
	140303255516592 -> 140303255517216
	140303255516592 [label=ConvolutionBackward0]
	140303255593952 -> 140303255516592
	140303255593952 [label=ReluBackward0]
	140303255512176 -> 140303255593952
	140303255512176 [label=AddBackward0]
	140303255511552 -> 140303255512176
	140303255511552 [label=MulBackward0]
	140303255508816 -> 140303255511552
	140303255508816 [label=ConvolutionBackward0]
	140303255507760 -> 140303255508816
	140303255507760 [label=CatBackward0]
	140303255505456 -> 140303255507760
	140303255505456 [label=ReluBackward0]
	140303255503344 -> 140303255505456
	140303255503344 [label=CudnnBatchNormBackward0]
	140303255422048 -> 140303255503344
	140303255422048 [label=ConvolutionBackward0]
	140303255514480 -> 140303255422048
	140303255514480 [label=ReluBackward0]
	140303255424976 -> 140303255514480
	140303255424976 [label=AddBackward0]
	140303255432800 -> 140303255424976
	140303255432800 [label=MulBackward0]
	140303255425600 -> 140303255432800
	140303255425600 [label=ConvolutionBackward0]
	140303255430640 -> 140303255425600
	140303255430640 [label=CatBackward0]
	140303255436400 -> 140303255430640
	140303255436400 [label=ReluBackward0]
	140303255428768 -> 140303255436400
	140303255428768 [label=CudnnBatchNormBackward0]
	140303255437216 -> 140303255428768
	140303255437216 [label=ConvolutionBackward0]
	140303255431360 -> 140303255437216
	140303255431360 [label=ReluBackward0]
	140303255425792 -> 140303255431360
	140303255425792 [label=AddBackward0]
	140303255437024 -> 140303255425792
	140303255437024 [label=MulBackward0]
	140303255426560 -> 140303255437024
	140303255426560 [label=ConvolutionBackward0]
	140303255428480 -> 140303255426560
	140303255428480 [label=CatBackward0]
	140303255427856 -> 140303255428480
	140303255427856 [label=ReluBackward0]
	140303255434912 -> 140303255427856
	140303255434912 [label=CudnnBatchNormBackward0]
	140303255422576 -> 140303255434912
	140303255422576 [label=ConvolutionBackward0]
	140303255434288 -> 140303255422576
	140303255434288 [label=CatBackward0]
	140303255434336 -> 140303255434288
	140303255434336 [label=ReluBackward0]
	140303255427232 -> 140303255434336
	140303255427232 [label=CudnnBatchNormBackward0]
	140303255429056 -> 140303255427232
	140303255429056 [label=ConvolutionBackward0]
	140303255426080 -> 140303255429056
	140303255426080 [label=MaxPool2DWithIndicesBackward0]
	140303202754064 -> 140303255426080
	140303202754064 [label=ReluBackward0]
	140303255424400 -> 140303202754064
	140303255424400 [label=CudnnBatchNormBackward0]
	140303255429008 -> 140303255424400
	140303255429008 [label=ConvolutionBackward0]
	140303255422096 -> 140303255429008
	140303255422096 [label=ReluBackward0]
	140303255421280 -> 140303255422096
	140303255421280 [label=CudnnBatchNormBackward0]
	140303255436928 -> 140303255421280
	140303255436928 [label=ConvolutionBackward0]
	140303255424784 -> 140303255436928
	140303255424784 [label=MaxPool2DWithIndicesBackward0]
	140303202760592 -> 140303255424784
	140303202760592 [label=ReluBackward0]
	140303255429392 -> 140303202760592
	140303255429392 [label=CudnnBatchNormBackward0]
	140303255427328 -> 140303255429392
	140303255427328 [label=ConvolutionBackward0]
	140303255426704 -> 140303255427328
	140303255426704 [label=ReluBackward0]
	140303255422720 -> 140303255426704
	140303255422720 [label=CudnnBatchNormBackward0]
	140303255435776 -> 140303255422720
	140303255435776 [label=ConvolutionBackward0]
	140303255426272 -> 140303255435776
	140303255426272 [label=ReluBackward0]
	140303255436544 -> 140303255426272
	140303255436544 [label=CudnnBatchNormBackward0]
	140303255422912 -> 140303255436544
	140303255422912 [label=ConvolutionBackward0]
	140303255422672 -> 140303255422912
	140301991195680 [label="model.model.encoder.conv2d_1a.conv.weight
 (32, 14, 3, 3)" fillcolor=lightblue]
	140301991195680 -> 140303255422672
	140303255422672 [label=AccumulateGrad]
	140303255426224 -> 140303255436544
	140303248880752 [label="model.model.encoder.conv2d_1a.bn.weight
 (32)" fillcolor=lightblue]
	140303248880752 -> 140303255426224
	140303255426224 [label=AccumulateGrad]
	140303255428144 -> 140303255436544
	140303257004736 [label="model.model.encoder.conv2d_1a.bn.bias
 (32)" fillcolor=lightblue]
	140303257004736 -> 140303255428144
	140303255428144 [label=AccumulateGrad]
	140303255429680 -> 140303255435776
	140303207178272 [label="model.model.encoder.conv2d_2a.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303207178272 -> 140303255429680
	140303255429680 [label=AccumulateGrad]
	140303255428672 -> 140303255422720
	140302100480624 [label="model.model.encoder.conv2d_2a.bn.weight
 (32)" fillcolor=lightblue]
	140302100480624 -> 140303255428672
	140303255428672 [label=AccumulateGrad]
	140303255426464 -> 140303255422720
	140303248848784 [label="model.model.encoder.conv2d_2a.bn.bias
 (32)" fillcolor=lightblue]
	140303248848784 -> 140303255426464
	140303255426464 [label=AccumulateGrad]
	140303255426848 -> 140303255427328
	140303257608624 [label="model.model.encoder.conv2d_2b.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140303257608624 -> 140303255426848
	140303255426848 [label=AccumulateGrad]
	140303255427520 -> 140303255429392
	140303257603584 [label="model.model.encoder.conv2d_2b.bn.weight
 (64)" fillcolor=lightblue]
	140303257603584 -> 140303255427520
	140303255427520 [label=AccumulateGrad]
	140303255423104 -> 140303255429392
	140303257615664 [label="model.model.encoder.conv2d_2b.bn.bias
 (64)" fillcolor=lightblue]
	140303257615664 -> 140303255423104
	140303255423104 [label=AccumulateGrad]
	140303255422384 -> 140303255436928
	140303207110336 [label="model.model.encoder.conv2d_3b.conv.weight
 (80, 64, 1, 1)" fillcolor=lightblue]
	140303207110336 -> 140303255422384
	140303255422384 [label=AccumulateGrad]
	140303255424496 -> 140303255421280
	140303207115856 [label="model.model.encoder.conv2d_3b.bn.weight
 (80)" fillcolor=lightblue]
	140303207115856 -> 140303255424496
	140303255424496 [label=AccumulateGrad]
	140303255428096 -> 140303255421280
	140303207117776 [label="model.model.encoder.conv2d_3b.bn.bias
 (80)" fillcolor=lightblue]
	140303207117776 -> 140303255428096
	140303255428096 [label=AccumulateGrad]
	140303255431072 -> 140303255429008
	140303207116416 [label="model.model.encoder.conv2d_4a.conv.weight
 (192, 80, 3, 3)" fillcolor=lightblue]
	140303207116416 -> 140303255431072
	140303255431072 [label=AccumulateGrad]
	140303255429824 -> 140303255424400
	140303207105216 [label="model.model.encoder.conv2d_4a.bn.weight
 (192)" fillcolor=lightblue]
	140303207105216 -> 140303255429824
	140303255429824 [label=AccumulateGrad]
	140303255425216 -> 140303255424400
	140303207117296 [label="model.model.encoder.conv2d_4a.bn.bias
 (192)" fillcolor=lightblue]
	140303207117296 -> 140303255425216
	140303255425216 [label=AccumulateGrad]
	140303255433568 -> 140303255429056
	140303208034640 [label="model.model.encoder.mixed_5b.branch0.conv.weight
 (96, 192, 1, 1)" fillcolor=lightblue]
	140303208034640 -> 140303255433568
	140303255433568 [label=AccumulateGrad]
	140303255434240 -> 140303255427232
	140303208035200 [label="model.model.encoder.mixed_5b.branch0.bn.weight
 (96)" fillcolor=lightblue]
	140303208035200 -> 140303255434240
	140303255434240 [label=AccumulateGrad]
	140303255435872 -> 140303255427232
	140303255889504 [label="model.model.encoder.mixed_5b.branch0.bn.bias
 (96)" fillcolor=lightblue]
	140303255889504 -> 140303255435872
	140303255435872 [label=AccumulateGrad]
	140303255422288 -> 140303255434288
	140303255422288 [label=ReluBackward0]
	140303255421616 -> 140303255422288
	140303255421616 [label=CudnnBatchNormBackward0]
	140303255421376 -> 140303255421616
	140303255421376 [label=ConvolutionBackward0]
	140303255435488 -> 140303255421376
	140303255435488 [label=ReluBackward0]
	140303255430832 -> 140303255435488
	140303255430832 [label=CudnnBatchNormBackward0]
	140303255428912 -> 140303255430832
	140303255428912 [label=ConvolutionBackward0]
	140303255426080 -> 140303255428912
	140303255425456 -> 140303255428912
	140303204037904 [label="model.model.encoder.mixed_5b.branch1.0.conv.weight
 (48, 192, 1, 1)" fillcolor=lightblue]
	140303204037904 -> 140303255425456
	140303255425456 [label=AccumulateGrad]
	140303255431456 -> 140303255430832
	140303204032944 [label="model.model.encoder.mixed_5b.branch1.0.bn.weight
 (48)" fillcolor=lightblue]
	140303204032944 -> 140303255431456
	140303255431456 [label=AccumulateGrad]
	140303255423824 -> 140303255430832
	140303204028304 [label="model.model.encoder.mixed_5b.branch1.0.bn.bias
 (48)" fillcolor=lightblue]
	140303204028304 -> 140303255423824
	140303255423824 [label=AccumulateGrad]
	140303255436592 -> 140303255421376
	140303204028704 [label="model.model.encoder.mixed_5b.branch1.1.conv.weight
 (64, 48, 5, 5)" fillcolor=lightblue]
	140303204028704 -> 140303255436592
	140303255436592 [label=AccumulateGrad]
	140303255428816 -> 140303255421616
	140303204029424 [label="model.model.encoder.mixed_5b.branch1.1.bn.weight
 (64)" fillcolor=lightblue]
	140303204029424 -> 140303255428816
	140303255428816 [label=AccumulateGrad]
	140303255432560 -> 140303255421616
	140303204029584 [label="model.model.encoder.mixed_5b.branch1.1.bn.bias
 (64)" fillcolor=lightblue]
	140303204029584 -> 140303255432560
	140303255432560 [label=AccumulateGrad]
	140303255421184 -> 140303255434288
	140303255421184 [label=ReluBackward0]
	140303255436448 -> 140303255421184
	140303255436448 [label=CudnnBatchNormBackward0]
	140303255436976 -> 140303255436448
	140303255436976 [label=ConvolutionBackward0]
	140303255426416 -> 140303255436976
	140303255426416 [label=ReluBackward0]
	140303255424880 -> 140303255426416
	140303255424880 [label=CudnnBatchNormBackward0]
	140303255436688 -> 140303255424880
	140303255436688 [label=ConvolutionBackward0]
	140303255436112 -> 140303255436688
	140303255436112 [label=ReluBackward0]
	140303255435392 -> 140303255436112
	140303255435392 [label=CudnnBatchNormBackward0]
	140303255434864 -> 140303255435392
	140303255434864 [label=ConvolutionBackward0]
	140303255426080 -> 140303255434864
	140303255424256 -> 140303255434864
	140303204029904 [label="model.model.encoder.mixed_5b.branch2.0.conv.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	140303204029904 -> 140303255424256
	140303255424256 [label=AccumulateGrad]
	140303255435248 -> 140303255435392
	140303204030064 [label="model.model.encoder.mixed_5b.branch2.0.bn.weight
 (64)" fillcolor=lightblue]
	140303204030064 -> 140303255435248
	140303255435248 [label=AccumulateGrad]
	140303255436016 -> 140303255435392
	140303204030384 [label="model.model.encoder.mixed_5b.branch2.0.bn.bias
 (64)" fillcolor=lightblue]
	140303204030384 -> 140303255436016
	140303255436016 [label=AccumulateGrad]
	140303255424832 -> 140303255436688
	140303204031024 [label="model.model.encoder.mixed_5b.branch2.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140303204031024 -> 140303255424832
	140303255424832 [label=AccumulateGrad]
	140303255436784 -> 140303255424880
	140303204030784 [label="model.model.encoder.mixed_5b.branch2.1.bn.weight
 (96)" fillcolor=lightblue]
	140303204030784 -> 140303255436784
	140303255436784 [label=AccumulateGrad]
	140303255428384 -> 140303255424880
	140303204030624 [label="model.model.encoder.mixed_5b.branch2.1.bn.bias
 (96)" fillcolor=lightblue]
	140303204030624 -> 140303255428384
	140303255428384 [label=AccumulateGrad]
	140303255435728 -> 140303255436976
	140303204032224 [label="model.model.encoder.mixed_5b.branch2.2.conv.weight
 (96, 96, 3, 3)" fillcolor=lightblue]
	140303204032224 -> 140303255435728
	140303255435728 [label=AccumulateGrad]
	140303255425936 -> 140303255436448
	140303204032384 [label="model.model.encoder.mixed_5b.branch2.2.bn.weight
 (96)" fillcolor=lightblue]
	140303204032384 -> 140303255425936
	140303255425936 [label=AccumulateGrad]
	140303255423680 -> 140303255436448
	140303204032544 [label="model.model.encoder.mixed_5b.branch2.2.bn.bias
 (96)" fillcolor=lightblue]
	140303204032544 -> 140303255423680
	140303255423680 [label=AccumulateGrad]
	140303255434768 -> 140303255434288
	140303255434768 [label=ReluBackward0]
	140303255425168 -> 140303255434768
	140303255425168 [label=CudnnBatchNormBackward0]
	140303255429872 -> 140303255425168
	140303255429872 [label=ConvolutionBackward0]
	140303255433520 -> 140303255429872
	140303255433520 [label=AvgPool2DBackward0]
	140303255426080 -> 140303255433520
	140303255434576 -> 140303255429872
	140303204033024 [label="model.model.encoder.mixed_5b.branch3.1.conv.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	140303204033024 -> 140303255434576
	140303255434576 [label=AccumulateGrad]
	140303255433136 -> 140303255425168
	140303204033184 [label="model.model.encoder.mixed_5b.branch3.1.bn.weight
 (64)" fillcolor=lightblue]
	140303204033184 -> 140303255433136
	140303255433136 [label=AccumulateGrad]
	140303255432416 -> 140303255425168
	140303204028864 [label="model.model.encoder.mixed_5b.branch3.1.bn.bias
 (64)" fillcolor=lightblue]
	140303204028864 -> 140303255432416
	140303255432416 [label=AccumulateGrad]
	140303255424592 -> 140303255422576
	140303204033664 [label="model.model.encoder.repeat.0.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204033664 -> 140303255424592
	140303255424592 [label=AccumulateGrad]
	140303255435968 -> 140303255434912
	140303204033104 [label="model.model.encoder.repeat.0.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204033104 -> 140303255435968
	140303255435968 [label=AccumulateGrad]
	140303255426032 -> 140303255434912
	140303204033824 [label="model.model.encoder.repeat.0.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204033824 -> 140303255426032
	140303255426032 [label=AccumulateGrad]
	140303255423152 -> 140303255428480
	140303255423152 [label=ReluBackward0]
	140303255425264 -> 140303255423152
	140303255425264 [label=CudnnBatchNormBackward0]
	140303255435920 -> 140303255425264
	140303255435920 [label=ConvolutionBackward0]
	140303255423296 -> 140303255435920
	140303255423296 [label=ReluBackward0]
	140303255430448 -> 140303255423296
	140303255430448 [label=CudnnBatchNormBackward0]
	140303255421424 -> 140303255430448
	140303255421424 [label=ConvolutionBackward0]
	140303255434288 -> 140303255421424
	140303255429776 -> 140303255421424
	140303204033904 [label="model.model.encoder.repeat.0.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204033904 -> 140303255429776
	140303255429776 [label=AccumulateGrad]
	140303255433712 -> 140303255430448
	140303204034064 [label="model.model.encoder.repeat.0.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204034064 -> 140303255433712
	140303255433712 [label=AccumulateGrad]
	140303255429632 -> 140303255430448
	140303204034384 [label="model.model.encoder.repeat.0.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204034384 -> 140303255429632
	140303255429632 [label=AccumulateGrad]
	140303255434000 -> 140303255435920
	140303204034784 [label="model.model.encoder.repeat.0.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204034784 -> 140303255434000
	140303255434000 [label=AccumulateGrad]
	140303255421760 -> 140303255425264
	140303204034864 [label="model.model.encoder.repeat.0.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204034864 -> 140303255421760
	140303255421760 [label=AccumulateGrad]
	140303255422000 -> 140303255425264
	140303204035184 [label="model.model.encoder.repeat.0.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204035184 -> 140303255422000
	140303255422000 [label=AccumulateGrad]
	140303255430688 -> 140303255428480
	140303255430688 [label=ReluBackward0]
	140303255423344 -> 140303255430688
	140303255423344 [label=CudnnBatchNormBackward0]
	140303255432272 -> 140303255423344
	140303255432272 [label=ConvolutionBackward0]
	140303255425360 -> 140303255432272
	140303255425360 [label=ReluBackward0]
	140303255424208 -> 140303255425360
	140303255424208 [label=CudnnBatchNormBackward0]
	140303255433856 -> 140303255424208
	140303255433856 [label=ConvolutionBackward0]
	140303255432896 -> 140303255433856
	140303255432896 [label=ReluBackward0]
	140303255429200 -> 140303255432896
	140303255429200 [label=CudnnBatchNormBackward0]
	140303255433664 -> 140303255429200
	140303255433664 [label=ConvolutionBackward0]
	140303255434288 -> 140303255433664
	140303255430064 -> 140303255433664
	140303204035344 [label="model.model.encoder.repeat.0.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204035344 -> 140303255430064
	140303255430064 [label=AccumulateGrad]
	140303255435680 -> 140303255429200
	140303204035664 [label="model.model.encoder.repeat.0.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204035664 -> 140303255435680
	140303255435680 [label=AccumulateGrad]
	140303255424112 -> 140303255429200
	140303204035584 [label="model.model.encoder.repeat.0.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204035584 -> 140303255424112
	140303255424112 [label=AccumulateGrad]
	140303255432944 -> 140303255433856
	140303204036144 [label="model.model.encoder.repeat.0.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204036144 -> 140303255432944
	140303255432944 [label=AccumulateGrad]
	140303255432608 -> 140303255424208
	140303204036384 [label="model.model.encoder.repeat.0.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204036384 -> 140303255432608
	140303255432608 [label=AccumulateGrad]
	140303255430736 -> 140303255424208
	140303204036704 [label="model.model.encoder.repeat.0.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204036704 -> 140303255430736
	140303255430736 [label=AccumulateGrad]
	140303255423488 -> 140303255432272
	140303204037424 [label="model.model.encoder.repeat.0.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204037424 -> 140303255423488
	140303255423488 [label=AccumulateGrad]
	140303255434096 -> 140303255423344
	140303204036624 [label="model.model.encoder.repeat.0.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204036624 -> 140303255434096
	140303255434096 [label=AccumulateGrad]
	140303255435008 -> 140303255423344
	140303204037344 [label="model.model.encoder.repeat.0.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204037344 -> 140303255435008
	140303255435008 [label=AccumulateGrad]
	140303255424064 -> 140303255426560
	140303204037504 [label="model.model.encoder.repeat.0.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204037504 -> 140303255424064
	140303255424064 [label=AccumulateGrad]
	140303255433808 -> 140303255426560
	140303204036944 [label="model.model.encoder.repeat.0.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204036944 -> 140303255433808
	140303255433808 [label=AccumulateGrad]
	140303255434288 -> 140303255425792
	140303255425024 -> 140303255437216
	140303204037984 [label="model.model.encoder.repeat.1.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204037984 -> 140303255425024
	140303255425024 [label=AccumulateGrad]
	140303255433952 -> 140303255428768
	140303204037664 [label="model.model.encoder.repeat.1.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204037664 -> 140303255433952
	140303255433952 [label=AccumulateGrad]
	140303255426320 -> 140303255428768
	140303204038144 [label="model.model.encoder.repeat.1.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204038144 -> 140303255426320
	140303255426320 [label=AccumulateGrad]
	140303255421856 -> 140303255430640
	140303255421856 [label=ReluBackward0]
	140303255425408 -> 140303255421856
	140303255425408 [label=CudnnBatchNormBackward0]
	140303255424544 -> 140303255425408
	140303255424544 [label=ConvolutionBackward0]
	140303255434624 -> 140303255424544
	140303255434624 [label=ReluBackward0]
	140303255433184 -> 140303255434624
	140303255433184 [label=CudnnBatchNormBackward0]
	140303255437072 -> 140303255433184
	140303255437072 [label=ConvolutionBackward0]
	140303255431360 -> 140303255437072
	140303255421808 -> 140303255437072
	140303204038384 [label="model.model.encoder.repeat.1.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204038384 -> 140303255421808
	140303255421808 [label=AccumulateGrad]
	140303255433376 -> 140303255433184
	140303204038704 [label="model.model.encoder.repeat.1.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204038704 -> 140303255433376
	140303255433376 [label=AccumulateGrad]
	140303255430160 -> 140303255433184
	140303204038864 [label="model.model.encoder.repeat.1.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204038864 -> 140303255430160
	140303255430160 [label=AccumulateGrad]
	140303255429296 -> 140303255424544
	140303204039264 [label="model.model.encoder.repeat.1.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204039264 -> 140303255429296
	140303255429296 [label=AccumulateGrad]
	140303255422240 -> 140303255425408
	140303204039664 [label="model.model.encoder.repeat.1.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204039664 -> 140303255422240
	140303255422240 [label=AccumulateGrad]
	140303255423920 -> 140303255425408
	140303204039744 [label="model.model.encoder.repeat.1.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204039744 -> 140303255423920
	140303255423920 [label=AccumulateGrad]
	140303255433232 -> 140303255430640
	140303255433232 [label=ReluBackward0]
	140303255423968 -> 140303255433232
	140303255423968 [label=CudnnBatchNormBackward0]
	140303255424352 -> 140303255423968
	140303255424352 [label=ConvolutionBackward0]
	140303255425504 -> 140303255424352
	140303255425504 [label=ReluBackward0]
	140303255432512 -> 140303255425504
	140303255432512 [label=CudnnBatchNormBackward0]
	140303255423440 -> 140303255432512
	140303255423440 [label=ConvolutionBackward0]
	140303255436064 -> 140303255423440
	140303255436064 [label=ReluBackward0]
	140303255434384 -> 140303255436064
	140303255434384 [label=CudnnBatchNormBackward0]
	140303255433328 -> 140303255434384
	140303255433328 [label=ConvolutionBackward0]
	140303255431360 -> 140303255433328
	140303255431024 -> 140303255433328
	140303204040064 [label="model.model.encoder.repeat.1.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204040064 -> 140303255431024
	140303255431024 [label=AccumulateGrad]
	140303255433760 -> 140303255434384
	140303204040304 [label="model.model.encoder.repeat.1.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204040304 -> 140303255433760
	140303255433760 [label=AccumulateGrad]
	140303255435440 -> 140303255434384
	140303204040384 [label="model.model.encoder.repeat.1.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204040384 -> 140303255435440
	140303255435440 [label=AccumulateGrad]
	140303255436496 -> 140303255423440
	140303204614368 [label="model.model.encoder.repeat.1.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204614368 -> 140303255436496
	140303255436496 [label=AccumulateGrad]
	140303255427136 -> 140303255432512
	140303204614528 [label="model.model.encoder.repeat.1.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204614528 -> 140303255427136
	140303255427136 [label=AccumulateGrad]
	140303255431888 -> 140303255432512
	140303204614608 [label="model.model.encoder.repeat.1.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204614608 -> 140303255431888
	140303255431888 [label=AccumulateGrad]
	140303255422960 -> 140303255424352
	140303204615088 [label="model.model.encoder.repeat.1.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204615088 -> 140303255422960
	140303255422960 [label=AccumulateGrad]
	140303255422816 -> 140303255423968
	140303204615168 [label="model.model.encoder.repeat.1.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204615168 -> 140303255422816
	140303255422816 [label=AccumulateGrad]
	140303255431552 -> 140303255423968
	140303204615248 [label="model.model.encoder.repeat.1.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204615248 -> 140303255431552
	140303255431552 [label=AccumulateGrad]
	140303255435536 -> 140303255425600
	140303204615728 [label="model.model.encoder.repeat.1.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204615728 -> 140303255435536
	140303255435536 [label=AccumulateGrad]
	140303255435104 -> 140303255425600
	140303204615808 [label="model.model.encoder.repeat.1.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204615808 -> 140303255435104
	140303255435104 [label=AccumulateGrad]
	140303255431360 -> 140303255424976
	140303255434720 -> 140303255422048
	140303204615328 [label="model.model.encoder.repeat.2.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204615328 -> 140303255434720
	140303255434720 [label=AccumulateGrad]
	140303255433424 -> 140303255503344
	140303204615968 [label="model.model.encoder.repeat.2.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204615968 -> 140303255433424
	140303255433424 [label=AccumulateGrad]
	140303255431264 -> 140303255503344
	140303204616048 [label="model.model.encoder.repeat.2.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204616048 -> 140303255431264
	140303255431264 [label=AccumulateGrad]
	140303255506080 -> 140303255507760
	140303255506080 [label=ReluBackward0]
	140303255503776 -> 140303255506080
	140303255503776 [label=CudnnBatchNormBackward0]
	140303255422864 -> 140303255503776
	140303255422864 [label=ConvolutionBackward0]
	140303255434432 -> 140303255422864
	140303255434432 [label=ReluBackward0]
	140303255437120 -> 140303255434432
	140303255437120 [label=CudnnBatchNormBackward0]
	140303255429536 -> 140303255437120
	140303255429536 [label=ConvolutionBackward0]
	140303255514480 -> 140303255429536
	140303255429968 -> 140303255429536
	140303204616448 [label="model.model.encoder.repeat.2.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204616448 -> 140303255429968
	140303255429968 [label=AccumulateGrad]
	140303255426512 -> 140303255437120
	140303204616528 [label="model.model.encoder.repeat.2.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204616528 -> 140303255426512
	140303255426512 [label=AccumulateGrad]
	140303255430016 -> 140303255437120
	140303204616688 [label="model.model.encoder.repeat.2.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204616688 -> 140303255430016
	140303255430016 [label=AccumulateGrad]
	140303255424736 -> 140303255422864
	140303204617088 [label="model.model.encoder.repeat.2.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204617088 -> 140303255424736
	140303255424736 [label=AccumulateGrad]
	140303255424640 -> 140303255503776
	140303204617168 [label="model.model.encoder.repeat.2.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204617168 -> 140303255424640
	140303255424640 [label=AccumulateGrad]
	140303255421040 -> 140303255503776
	140303204617248 [label="model.model.encoder.repeat.2.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204617248 -> 140303255421040
	140303255421040 [label=AccumulateGrad]
	140303255506704 -> 140303255507760
	140303255506704 [label=ReluBackward0]
	140303255430496 -> 140303255506704
	140303255430496 [label=CudnnBatchNormBackward0]
	140303255431648 -> 140303255430496
	140303255431648 [label=ConvolutionBackward0]
	140303255432704 -> 140303255431648
	140303255432704 [label=ReluBackward0]
	140303255428288 -> 140303255432704
	140303255428288 [label=CudnnBatchNormBackward0]
	140303255427040 -> 140303255428288
	140303255427040 [label=ConvolutionBackward0]
	140303255424928 -> 140303255427040
	140303255424928 [label=ReluBackward0]
	140303255423248 -> 140303255424928
	140303255423248 [label=CudnnBatchNormBackward0]
	140303255422192 -> 140303255423248
	140303255422192 [label=ConvolutionBackward0]
	140303255514480 -> 140303255422192
	140303255354288 -> 140303255422192
	140303204617728 [label="model.model.encoder.repeat.2.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204617728 -> 140303255354288
	140303255354288 [label=AccumulateGrad]
	140303255422624 -> 140303255423248
	140303204617808 [label="model.model.encoder.repeat.2.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204617808 -> 140303255422624
	140303255422624 [label=AccumulateGrad]
	140303255424304 -> 140303255423248
	140303204617888 [label="model.model.encoder.repeat.2.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204617888 -> 140303255424304
	140303255424304 [label=AccumulateGrad]
	140303255425552 -> 140303255427040
	140303204618288 [label="model.model.encoder.repeat.2.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204618288 -> 140303255425552
	140303255425552 [label=AccumulateGrad]
	140303255427664 -> 140303255428288
	140303204618448 [label="model.model.encoder.repeat.2.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204618448 -> 140303255427664
	140303255427664 [label=AccumulateGrad]
	140303255429344 -> 140303255428288
	140303204618528 [label="model.model.encoder.repeat.2.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204618528 -> 140303255429344
	140303255429344 [label=AccumulateGrad]
	140303255430400 -> 140303255431648
	140303204619168 [label="model.model.encoder.repeat.2.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204619168 -> 140303255430400
	140303255430400 [label=AccumulateGrad]
	140303255434816 -> 140303255430496
	140303204619248 [label="model.model.encoder.repeat.2.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204619248 -> 140303255434816
	140303255434816 [label=AccumulateGrad]
	140303255435152 -> 140303255430496
	140303204619328 [label="model.model.encoder.repeat.2.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204619328 -> 140303255435152
	140303255435152 [label=AccumulateGrad]
	140303255508192 -> 140303255508816
	140303204619968 [label="model.model.encoder.repeat.2.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204619968 -> 140303255508192
	140303255508192 [label=AccumulateGrad]
	140303255509872 -> 140303255508816
	140303204620128 [label="model.model.encoder.repeat.2.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204620128 -> 140303255509872
	140303255509872 [label=AccumulateGrad]
	140303255514480 -> 140303255512176
	140303255513232 -> 140303255516592
	140303204620288 [label="model.model.encoder.repeat.3.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204620288 -> 140303255513232
	140303255513232 [label=AccumulateGrad]
	140303255518272 -> 140303255517216
	140303204620368 [label="model.model.encoder.repeat.3.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204620368 -> 140303255518272
	140303255518272 [label=AccumulateGrad]
	140303255515536 -> 140303255517216
	140303204620448 [label="model.model.encoder.repeat.3.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204620448 -> 140303255515536
	140303255515536 [label=AccumulateGrad]
	140303255585552 -> 140303255587232
	140303255585552 [label=ReluBackward0]
	140303255513856 -> 140303255585552
	140303255513856 [label=CudnnBatchNormBackward0]
	140303255510496 -> 140303255513856
	140303255510496 [label=ConvolutionBackward0]
	140303255505024 -> 140303255510496
	140303255505024 [label=ReluBackward0]
	140303255425984 -> 140303255505024
	140303255425984 [label=CudnnBatchNormBackward0]
	140303255428720 -> 140303255425984
	140303255428720 [label=ConvolutionBackward0]
	140303255593952 -> 140303255428720
	140303255423872 -> 140303255428720
	140303204621088 [label="model.model.encoder.repeat.3.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204621088 -> 140303255423872
	140303255423872 [label=AccumulateGrad]
	140303255426608 -> 140303255425984
	140303204621008 [label="model.model.encoder.repeat.3.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204621008 -> 140303255426608
	140303255426608 [label=AccumulateGrad]
	140303255432176 -> 140303255425984
	140303204621248 [label="model.model.encoder.repeat.3.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204621248 -> 140303255432176
	140303255432176 [label=AccumulateGrad]
	140303255507136 -> 140303255510496
	140303204621568 [label="model.model.encoder.repeat.3.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204621568 -> 140303255507136
	140303255507136 [label=AccumulateGrad]
	140303255509440 -> 140303255513856
	140303204621648 [label="model.model.encoder.repeat.3.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204621648 -> 140303255509440
	140303255509440 [label=AccumulateGrad]
	140303255517648 -> 140303255513856
	140303204621728 [label="model.model.encoder.repeat.3.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204621728 -> 140303255517648
	140303255517648 [label=AccumulateGrad]
	140303255586176 -> 140303255587232
	140303255586176 [label=ReluBackward0]
	140303255512800 -> 140303255586176
	140303255512800 [label=CudnnBatchNormBackward0]
	140303255432080 -> 140303255512800
	140303255432080 [label=ConvolutionBackward0]
	140303255354912 -> 140303255432080
	140303255354912 [label=ReluBackward0]
	140303255351552 -> 140303255354912
	140303255351552 [label=CudnnBatchNormBackward0]
	140303255350496 -> 140303255351552
	140303255350496 [label=ConvolutionBackward0]
	140303255348192 -> 140303255350496
	140303255348192 [label=ReluBackward0]
	140303255346512 -> 140303255348192
	140303255346512 [label=CudnnBatchNormBackward0]
	140303255345456 -> 140303255346512
	140303255345456 [label=ConvolutionBackward0]
	140303255593952 -> 140303255345456
	140303255343152 -> 140303255345456
	140303204622448 [label="model.model.encoder.repeat.3.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204622448 -> 140303255343152
	140303255343152 [label=AccumulateGrad]
	140303255345888 -> 140303255346512
	140303204622688 [label="model.model.encoder.repeat.3.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204622688 -> 140303255345888
	140303255345888 [label=AccumulateGrad]
	140303255347568 -> 140303255346512
	140303204622768 [label="model.model.encoder.repeat.3.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204622768 -> 140303255347568
	140303255347568 [label=AccumulateGrad]
	140303255348816 -> 140303255350496
	140303204623168 [label="model.model.encoder.repeat.3.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204623168 -> 140303255348816
	140303255348816 [label=AccumulateGrad]
	140303255350928 -> 140303255351552
	140303204623248 [label="model.model.encoder.repeat.3.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204623248 -> 140303255350928
	140303255350928 [label=AccumulateGrad]
	140303255352608 -> 140303255351552
	140303204623328 [label="model.model.encoder.repeat.3.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204623328 -> 140303255352608
	140303255352608 [label=AccumulateGrad]
	140303255353664 -> 140303255432080
	140303204623808 [label="model.model.encoder.repeat.3.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204623808 -> 140303255353664
	140303255353664 [label=AccumulateGrad]
	140303255421568 -> 140303255512800
	140303204623888 [label="model.model.encoder.repeat.3.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204623888 -> 140303255421568
	140303255421568 [label=AccumulateGrad]
	140303255431120 -> 140303255512800
	140303204623968 [label="model.model.encoder.repeat.3.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204623968 -> 140303255431120
	140303255431120 [label=AccumulateGrad]
	140303255587856 -> 140303255588288
	140303204624448 [label="model.model.encoder.repeat.3.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204624448 -> 140303255587856
	140303255587856 [label=AccumulateGrad]
	140303255589344 -> 140303255588288
	140303204624528 [label="model.model.encoder.repeat.3.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204624528 -> 140303255589344
	140303255589344 [label=AccumulateGrad]
	140303255593952 -> 140303255591648
	140303255592704 -> 140303255596064
	140303204624688 [label="model.model.encoder.repeat.4.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204624688 -> 140303255592704
	140303255592704 [label=AccumulateGrad]
	140303255597744 -> 140303255596688
	140303204624768 [label="model.model.encoder.repeat.4.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204624768 -> 140303255597744
	140303255597744 [label=AccumulateGrad]
	140303255595008 -> 140303255596688
	140303204624848 [label="model.model.encoder.repeat.4.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204624848 -> 140303255595008
	140303255595008 [label=AccumulateGrad]
	140303255599424 -> 140303255601104
	140303255599424 [label=ReluBackward0]
	140303255593328 -> 140303255599424
	140303255593328 [label=CudnnBatchNormBackward0]
	140303255589968 -> 140303255593328
	140303255589968 [label=ConvolutionBackward0]
	140303255514912 -> 140303255589968
	140303255514912 [label=ReluBackward0]
	140303255349248 -> 140303255514912
	140303255349248 [label=CudnnBatchNormBackward0]
	140303255352176 -> 140303255349248
	140303255352176 [label=ConvolutionBackward0]
	140303255688752 -> 140303255352176
	140303255342096 -> 140303255352176
	140303204625328 [label="model.model.encoder.repeat.4.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204625328 -> 140303255342096
	140303255342096 [label=AccumulateGrad]
	140303255349872 -> 140303255349248
	140303204625408 [label="model.model.encoder.repeat.4.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204625408 -> 140303255349872
	140303255349872 [label=AccumulateGrad]
	140303255353232 -> 140303255349248
	140303204625488 [label="model.model.encoder.repeat.4.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204625488 -> 140303255353232
	140303255353232 [label=AccumulateGrad]
	140303255518896 -> 140303255589968
	140303204027184 [label="model.model.encoder.repeat.4.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204027184 -> 140303255518896
	140303255518896 [label=AccumulateGrad]
	140303255588912 -> 140303255593328
	140303204027984 [label="model.model.encoder.repeat.4.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204027984 -> 140303255588912
	140303255588912 [label=AccumulateGrad]
	140303255597120 -> 140303255593328
	140303204027104 [label="model.model.encoder.repeat.4.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204027104 -> 140303255597120
	140303255597120 [label=AccumulateGrad]
	140303255600048 -> 140303255601104
	140303255600048 [label=ReluBackward0]
	140303255586608 -> 140303255600048
	140303255586608 [label=CudnnBatchNormBackward0]
	140303255594384 -> 140303255586608
	140303255594384 [label=ConvolutionBackward0]
	140303255344832 -> 140303255594384
	140303255344832 [label=ReluBackward0]
	140303255340416 -> 140303255344832
	140303255340416 [label=CudnnBatchNormBackward0]
	140303255339360 -> 140303255340416
	140303255339360 [label=ConvolutionBackward0]
	140303257350976 -> 140303255339360
	140303257350976 [label=ReluBackward0]
	140303257350448 -> 140303257350976
	140303257350448 [label=CudnnBatchNormBackward0]
	140303257350640 -> 140303257350448
	140303257350640 [label=ConvolutionBackward0]
	140303255688752 -> 140303257350640
	140303257346608 -> 140303257350640
	140303204026864 [label="model.model.encoder.repeat.4.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204026864 -> 140303257346608
	140303257346608 [label=AccumulateGrad]
	140303257341760 -> 140303257350448
	140303204025984 [label="model.model.encoder.repeat.4.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204025984 -> 140303257341760
	140303257341760 [label=AccumulateGrad]
	140303257338928 -> 140303257350448
	140303204026304 [label="model.model.encoder.repeat.4.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204026304 -> 140303257338928
	140303257338928 [label=AccumulateGrad]
	140303257344544 -> 140303255339360
	140303248621792 [label="model.model.encoder.repeat.4.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303248621792 -> 140303257344544
	140303257344544 [label=AccumulateGrad]
	140303255339792 -> 140303255340416
	140303204102320 [label="model.model.encoder.repeat.4.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204102320 -> 140303255339792
	140303255339792 [label=AccumulateGrad]
	140303255341472 -> 140303255340416
	140303204105040 [label="model.model.encoder.repeat.4.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204105040 -> 140303255341472
	140303255341472 [label=AccumulateGrad]
	140303255342720 -> 140303255594384
	140303204097520 [label="model.model.encoder.repeat.4.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204097520 -> 140303255342720
	140303255342720 [label=AccumulateGrad]
	140303255343776 -> 140303255586608
	140303204097760 [label="model.model.encoder.repeat.4.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204097760 -> 140303255343776
	140303255343776 [label=AccumulateGrad]
	140303255347136 -> 140303255586608
	140303204097920 [label="model.model.encoder.repeat.4.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204097920 -> 140303255347136
	140303255347136 [label=AccumulateGrad]
	140303255588144 -> 140303255683712
	140303204098400 [label="model.model.encoder.repeat.4.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204098400 -> 140303255588144
	140303255588144 [label=AccumulateGrad]
	140303255599856 -> 140303255683712
	140303204098960 [label="model.model.encoder.repeat.4.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204098960 -> 140303255599856
	140303255599856 [label=AccumulateGrad]
	140303255688752 -> 140303255686448
	140303255687504 -> 140303255690864
	140303204100080 [label="model.model.encoder.repeat.5.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204100080 -> 140303255687504
	140303255687504 [label=AccumulateGrad]
	140303255692544 -> 140303255691488
	140303204098880 [label="model.model.encoder.repeat.5.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204098880 -> 140303255692544
	140303255692544 [label=AccumulateGrad]
	140303255689808 -> 140303255691488
	140303204100240 [label="model.model.encoder.repeat.5.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204100240 -> 140303255689808
	140303255689808 [label=AccumulateGrad]
	140303255694224 -> 140303255695904
	140303255694224 [label=ReluBackward0]
	140303255688128 -> 140303255694224
	140303255688128 [label=CudnnBatchNormBackward0]
	140303255684768 -> 140303255688128
	140303255684768 [label=ConvolutionBackward0]
	140303255592272 -> 140303255684768
	140303255592272 [label=ReluBackward0]
	140303255341040 -> 140303255592272
	140303255341040 [label=CudnnBatchNormBackward0]
	140303255355344 -> 140303255341040
	140303255355344 [label=ConvolutionBackward0]
	140303255699264 -> 140303255355344
	140303257339600 -> 140303255355344
	140303204100720 [label="model.model.encoder.repeat.5.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204100720 -> 140303257339600
	140303257339600 [label=AccumulateGrad]
	140303257348624 -> 140303255341040
	140303204100880 [label="model.model.encoder.repeat.5.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204100880 -> 140303257348624
	140303257348624 [label=AccumulateGrad]
	140303257346704 -> 140303255341040
	140303204101120 [label="model.model.encoder.repeat.5.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204101120 -> 140303257346704
	140303257346704 [label=AccumulateGrad]
	140303255598368 -> 140303255684768
	140303204101520 [label="model.model.encoder.repeat.5.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204101520 -> 140303255598368
	140303255598368 [label=AccumulateGrad]
	140303255684144 -> 140303255688128
	140303204102400 [label="model.model.encoder.repeat.5.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204102400 -> 140303255684144
	140303255684144 [label=AccumulateGrad]
	140303255692112 -> 140303255688128
	140303204102080 [label="model.model.encoder.repeat.5.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204102080 -> 140303255692112
	140303255692112 [label=AccumulateGrad]
	140303255694848 -> 140303255695904
	140303255694848 [label=ReluBackward0]
	140303255600480 -> 140303255694848
	140303255600480 [label=CudnnBatchNormBackward0]
	140303255344400 -> 140303255600480
	140303255344400 [label=ConvolutionBackward0]
	140303257343584 -> 140303255344400
	140303257343584 [label=ReluBackward0]
	140303257351120 -> 140303257343584
	140303257351120 [label=CudnnBatchNormBackward0]
	140303257342864 -> 140303257351120
	140303257342864 [label=ConvolutionBackward0]
	140303257342960 -> 140303257342864
	140303257342960 [label=ReluBackward0]
	140303257339504 -> 140303257342960
	140303257339504 [label=CudnnBatchNormBackward0]
	140303257340368 -> 140303257339504
	140303257340368 [label=ConvolutionBackward0]
	140303255699264 -> 140303257340368
	140303257343008 -> 140303257340368
	140303204104880 [label="model.model.encoder.repeat.5.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204104880 -> 140303257343008
	140303257343008 [label=AccumulateGrad]
	140303257349680 -> 140303257339504
	140303204104640 [label="model.model.encoder.repeat.5.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204104640 -> 140303257349680
	140303257349680 [label=AccumulateGrad]
	140303257342384 -> 140303257339504
	140303204103920 [label="model.model.encoder.repeat.5.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204103920 -> 140303257342384
	140303257342384 [label=AccumulateGrad]
	140303257350592 -> 140303257342864
	140303204099520 [label="model.model.encoder.repeat.5.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204099520 -> 140303257350592
	140303257350592 [label=AccumulateGrad]
	140303257339696 -> 140303257351120
	140303204099680 [label="model.model.encoder.repeat.5.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204099680 -> 140303257339696
	140303257339696 [label=AccumulateGrad]
	140303257346032 -> 140303257351120
	140303204099920 [label="model.model.encoder.repeat.5.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204099920 -> 140303257346032
	140303257346032 [label=AccumulateGrad]
	140303257341808 -> 140303255344400
	140303204099040 [label="model.model.encoder.repeat.5.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204099040 -> 140303257341808
	140303257341808 [label=AccumulateGrad]
	140303255689184 -> 140303255600480
	140303204099760 [label="model.model.encoder.repeat.5.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204099760 -> 140303255689184
	140303255689184 [label=AccumulateGrad]
	140303257346848 -> 140303255600480
	140303204098480 [label="model.model.encoder.repeat.5.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204098480 -> 140303257346848
	140303257346848 [label=AccumulateGrad]
	140303255696528 -> 140303255697152
	140303204097040 [label="model.model.encoder.repeat.5.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204097040 -> 140303255696528
	140303255696528 [label=AccumulateGrad]
	140303255698208 -> 140303255697152
	140303204097200 [label="model.model.encoder.repeat.5.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204097200 -> 140303255698208
	140303255698208 [label=AccumulateGrad]
	140303255699264 -> 140303255765920
	140303255767168 -> 140303255770528
	140303204095520 [label="model.model.encoder.repeat.6.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204095520 -> 140303255767168
	140303255767168 [label=AccumulateGrad]
	140303255772016 -> 140303255770960
	140303204095760 [label="model.model.encoder.repeat.6.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204095760 -> 140303255772016
	140303255772016 [label=AccumulateGrad]
	140303255769280 -> 140303255770960
	140303204095920 [label="model.model.encoder.repeat.6.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204095920 -> 140303255769280
	140303255769280 [label=AccumulateGrad]
	140303255773696 -> 140303255775376
	140303255773696 [label=ReluBackward0]
	140303255767600 -> 140303255773696
	140303255767600 [label=CudnnBatchNormBackward0]
	140303255766544 -> 140303255767600
	140303255766544 [label=ConvolutionBackward0]
	140303255687072 -> 140303255766544
	140303255687072 [label=ReluBackward0]
	140303257351360 -> 140303255687072
	140303257351360 [label=CudnnBatchNormBackward0]
	140303257351216 -> 140303257351360
	140303257351216 [label=ConvolutionBackward0]
	140303255779264 -> 140303257351216
	140303257340560 -> 140303257351216
	140303204094960 [label="model.model.encoder.repeat.6.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204094960 -> 140303257340560
	140303257340560 [label=AccumulateGrad]
	140303257346992 -> 140303257351360
	140303204094880 [label="model.model.encoder.repeat.6.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204094880 -> 140303257346992
	140303257346992 [label=AccumulateGrad]
	140303257342240 -> 140303257351360
	140303204095040 [label="model.model.encoder.repeat.6.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204095040 -> 140303257342240
	140303257342240 [label=AccumulateGrad]
	140303255693168 -> 140303255766544
	140303204093760 [label="model.model.encoder.repeat.6.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204093760 -> 140303255693168
	140303255693168 [label=AccumulateGrad]
	140303255771584 -> 140303255767600
	140303204093040 [label="model.model.encoder.repeat.6.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204093040 -> 140303255771584
	140303255771584 [label=AccumulateGrad]
	140303255697584 -> 140303255767600
	140303204093920 [label="model.model.encoder.repeat.6.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204093920 -> 140303255697584
	140303255697584 [label=AccumulateGrad]
	140303255774320 -> 140303255775376
	140303255774320 [label=ReluBackward0]
	140303255695472 -> 140303255774320
	140303255695472 [label=CudnnBatchNormBackward0]
	140303255768848 -> 140303255695472
	140303255768848 [label=ConvolutionBackward0]
	140303257340608 -> 140303255768848
	140303257340608 [label=ReluBackward0]
	140303257345792 -> 140303257340608
	140303257345792 [label=CudnnBatchNormBackward0]
	140303257339936 -> 140303257345792
	140303257339936 [label=ConvolutionBackward0]
	140303257349296 -> 140303257339936
	140303257349296 [label=ReluBackward0]
	140303257341904 -> 140303257349296
	140303257341904 [label=CudnnBatchNormBackward0]
	140303257340224 -> 140303257341904
	140303257340224 [label=ConvolutionBackward0]
	140303255779264 -> 140303257340224
	140303257339456 -> 140303257340224
	140303204092400 [label="model.model.encoder.repeat.6.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204092400 -> 140303257339456
	140303257339456 [label=AccumulateGrad]
	140303257349056 -> 140303257341904
	140303204092160 [label="model.model.encoder.repeat.6.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204092160 -> 140303257349056
	140303257349056 [label=AccumulateGrad]
	140303257340512 -> 140303257341904
	140303204092320 [label="model.model.encoder.repeat.6.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204092320 -> 140303257340512
	140303257340512 [label=AccumulateGrad]
	140303257348768 -> 140303257339936
	140303255787920 [label="model.model.encoder.repeat.6.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303255787920 -> 140303257348768
	140303257348768 [label=AccumulateGrad]
	140303257344256 -> 140303257345792
	140303258015824 [label="model.model.encoder.repeat.6.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303258015824 -> 140303257344256
	140303257344256 [label=AccumulateGrad]
	140303257347712 -> 140303257345792
	140303258013184 [label="model.model.encoder.repeat.6.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303258013184 -> 140303257347712
	140303257347712 [label=AccumulateGrad]
	140303257346944 -> 140303255768848
	140303207258592 [label="model.model.encoder.repeat.6.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303207258592 -> 140303257346944
	140303257346944 [label=AccumulateGrad]
	140303257342000 -> 140303255695472
	140303207254432 [label="model.model.encoder.repeat.6.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303207254432 -> 140303257342000
	140303257342000 [label=AccumulateGrad]
	140303257342192 -> 140303255695472
	140303207257152 [label="model.model.encoder.repeat.6.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303207257152 -> 140303257342192
	140303257342192 [label=AccumulateGrad]
	140303255776000 -> 140303255776624
	140303208031760 [label="model.model.encoder.repeat.6.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303208031760 -> 140303255776000
	140303255776000 [label=AccumulateGrad]
	140303255777680 -> 140303255776624
	140303251842576 [label="model.model.encoder.repeat.6.conv2d.bias
 (320)" fillcolor=lightblue]
	140303251842576 -> 140303255777680
	140303255777680 [label=AccumulateGrad]
	140303255779264 -> 140303255779792
	140303255781040 -> 140303255771680
	140303252216688 [label="model.model.encoder.repeat.7.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303252216688 -> 140303255781040
	140303255781040 [label=AccumulateGrad]
	140303255765536 -> 140303255771296
	140303257423120 [label="model.model.encoder.repeat.7.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303257423120 -> 140303255765536
	140303255765536 [label=AccumulateGrad]
	140303255778016 -> 140303255771296
	140303257423440 [label="model.model.encoder.repeat.7.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303257423440 -> 140303255778016
	140303255778016 [label=AccumulateGrad]
	140303255772112 -> 140303255777392
	140303255772112 [label=ReluBackward0]
	140303255777248 -> 140303255772112
	140303255777248 [label=CudnnBatchNormBackward0]
	140303255778304 -> 140303255777248
	140303255778304 [label=ConvolutionBackward0]
	140303255698640 -> 140303255778304
	140303255698640 [label=ReluBackward0]
	140303257340704 -> 140303255698640
	140303257340704 [label=CudnnBatchNormBackward0]
	140303257341520 -> 140303257340704
	140303257341520 [label=ConvolutionBackward0]
	140303255780896 -> 140303257341520
	140303257345024 -> 140303257341520
	140303251584352 [label="model.model.encoder.repeat.7.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303251584352 -> 140303257345024
	140303257345024 [label=AccumulateGrad]
	140303257340896 -> 140303257340704
	140303207172752 [label="model.model.encoder.repeat.7.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303207172752 -> 140303257340896
	140303257340896 [label=AccumulateGrad]
	140303257343440 -> 140303257340704
	140303207170112 [label="model.model.encoder.repeat.7.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303207170112 -> 140303257343440
	140303257343440 [label=AccumulateGrad]
	140303255772640 -> 140303255778304
	140303205891536 [label="model.model.encoder.repeat.7.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303205891536 -> 140303255772640
	140303255772640 [label=AccumulateGrad]
	140303255777056 -> 140303255777248
	140303205883056 [label="model.model.encoder.repeat.7.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303205883056 -> 140303255777056
	140303255777056 [label=AccumulateGrad]
	140303255770624 -> 140303255777248
	140303205884096 [label="model.model.encoder.repeat.7.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303205884096 -> 140303255770624
	140303255770624 [label=AccumulateGrad]
	140303255773744 -> 140303255777392
	140303255773744 [label=ReluBackward0]
	140303255774944 -> 140303255773744
	140303255774944 [label=CudnnBatchNormBackward0]
	140303255766496 -> 140303255774944
	140303255766496 [label=ConvolutionBackward0]
	140303257348480 -> 140303255766496
	140303257348480 [label=ReluBackward0]
	140303257347904 -> 140303257348480
	140303257347904 [label=CudnnBatchNormBackward0]
	140303257341376 -> 140303257347904
	140303257341376 [label=ConvolutionBackward0]
	140303257347472 -> 140303257341376
	140303257347472 [label=ReluBackward0]
	140303257342528 -> 140303257347472
	140303257342528 [label=CudnnBatchNormBackward0]
	140303257350880 -> 140303257342528
	140303257350880 [label=ConvolutionBackward0]
	140303255780896 -> 140303257350880
	140303257338208 -> 140303257350880
	140303205885376 [label="model.model.encoder.repeat.7.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303205885376 -> 140303257338208
	140303257338208 [label=AccumulateGrad]
	140303257341424 -> 140303257342528
	140303205885296 [label="model.model.encoder.repeat.7.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303205885296 -> 140303257341424
	140303257341424 [label=AccumulateGrad]
	140303257349824 -> 140303257342528
	140303205885456 [label="model.model.encoder.repeat.7.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303205885456 -> 140303257349824
	140303257349824 [label=AccumulateGrad]
	140303257338784 -> 140303257341376
	140303205886976 [label="model.model.encoder.repeat.7.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303205886976 -> 140303257338784
	140303257338784 [label=AccumulateGrad]
	140303257338880 -> 140303257347904
	140303205887136 [label="model.model.encoder.repeat.7.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303205887136 -> 140303257338880
	140303257338880 [label=AccumulateGrad]
	140303257352800 -> 140303257347904
	140303205887376 [label="model.model.encoder.repeat.7.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303205887376 -> 140303257352800
	140303257352800 [label=AccumulateGrad]
	140303257348144 -> 140303255766496
	140303205887856 [label="model.model.encoder.repeat.7.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303205887856 -> 140303257348144
	140303257348144 [label=AccumulateGrad]
	140303257338400 -> 140303255774944
	140303205888096 [label="model.model.encoder.repeat.7.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303205888096 -> 140303257338400
	140303257338400 [label=AccumulateGrad]
	140303257340464 -> 140303255774944
	140303205887936 [label="model.model.encoder.repeat.7.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303205887936 -> 140303257340464
	140303257340464 [label=AccumulateGrad]
	140303255777296 -> 140303255776480
	140303205890816 [label="model.model.encoder.repeat.7.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303205890816 -> 140303255777296
	140303255777296 [label=AccumulateGrad]
	140303255770864 -> 140303255776480
	140303205890176 [label="model.model.encoder.repeat.7.conv2d.bias
 (320)" fillcolor=lightblue]
	140303205890176 -> 140303255770864
	140303255770864 [label=AccumulateGrad]
	140303255780896 -> 140303255778976
	140303255779408 -> 140303255766208
	140303205891056 [label="model.model.encoder.repeat.8.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303205891056 -> 140303255779408
	140303255779408 [label=AccumulateGrad]
	140303255775856 -> 140303255767216
	140303205890736 [label="model.model.encoder.repeat.8.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303205890736 -> 140303255775856
	140303255775856 [label=AccumulateGrad]
	140303255768896 -> 140303255767216
	140303205890976 [label="model.model.encoder.repeat.8.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303205890976 -> 140303255768896
	140303255768896 [label=AccumulateGrad]
	140303255780032 -> 140303255847072
	140303255780032 [label=ReluBackward0]
	140303255780608 -> 140303255780032
	140303255780608 [label=CudnnBatchNormBackward0]
	140303255768080 -> 140303255780608
	140303255768080 [label=ConvolutionBackward0]
	140303255780416 -> 140303255768080
	140303255780416 [label=ReluBackward0]
	140303257347520 -> 140303255780416
	140303257347520 [label=CudnnBatchNormBackward0]
	140303257348000 -> 140303257347520
	140303257348000 [label=ConvolutionBackward0]
	140303255853792 -> 140303257348000
	140303257341184 -> 140303257348000
	140303205886736 [label="model.model.encoder.repeat.8.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303205886736 -> 140303257341184
	140303257341184 [label=AccumulateGrad]
	140303257339072 -> 140303257347520
	140303205886816 [label="model.model.encoder.repeat.8.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303205886816 -> 140303257339072
	140303257339072 [label=AccumulateGrad]
	140303257344880 -> 140303257347520
	140303205887056 [label="model.model.encoder.repeat.8.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303205887056 -> 140303257344880
	140303257344880 [label=AccumulateGrad]
	140303255766016 -> 140303255768080
	140303205886256 [label="model.model.encoder.repeat.8.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303205886256 -> 140303255766016
	140303255766016 [label=AccumulateGrad]
	140303255776096 -> 140303255780608
	140303205886496 [label="model.model.encoder.repeat.8.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303205886496 -> 140303255776096
	140303255776096 [label=AccumulateGrad]
	140303255775280 -> 140303255780608
	140303205886896 [label="model.model.encoder.repeat.8.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303205886896 -> 140303255775280
	140303255775280 [label=AccumulateGrad]
	140303255768560 -> 140303255847072
	140303255768560 [label=ReluBackward0]
	140303255774272 -> 140303255768560
	140303255774272 [label=CudnnBatchNormBackward0]
	140303255781280 -> 140303255774272
	140303255781280 [label=ConvolutionBackward0]
	140303257338304 -> 140303255781280
	140303257338304 [label=ReluBackward0]
	140303257341664 -> 140303257338304
	140303257341664 [label=CudnnBatchNormBackward0]
	140303257351024 -> 140303257341664
	140303257351024 [label=ConvolutionBackward0]
	140303257341952 -> 140303257351024
	140303257341952 [label=ReluBackward0]
	140303257339648 -> 140303257341952
	140303257339648 [label=CudnnBatchNormBackward0]
	140303257345312 -> 140303257339648
	140303257345312 [label=ConvolutionBackward0]
	140303255853792 -> 140303257345312
	140303257354192 -> 140303257345312
	140303205884976 [label="model.model.encoder.repeat.8.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303205884976 -> 140303257354192
	140303257354192 [label=AccumulateGrad]
	140303257343968 -> 140303257339648
	140303205884176 [label="model.model.encoder.repeat.8.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303205884176 -> 140303257343968
	140303257343968 [label=AccumulateGrad]
	140303257340080 -> 140303257339648
	140303205884256 [label="model.model.encoder.repeat.8.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303205884256 -> 140303257340080
	140303257340080 [label=AccumulateGrad]
	140303257348672 -> 140303257351024
	140303205883456 [label="model.model.encoder.repeat.8.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303205883456 -> 140303257348672
	140303257348672 [label=AccumulateGrad]
	140303257348240 -> 140303257341664
	140303205883536 [label="model.model.encoder.repeat.8.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303205883536 -> 140303257348240
	140303257348240 [label=AccumulateGrad]
	140303257342144 -> 140303257341664
	140303205884016 [label="model.model.encoder.repeat.8.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303205884016 -> 140303257342144
	140303257342144 [label=AccumulateGrad]
	140303257338160 -> 140303255781280
	140303205882816 [label="model.model.encoder.repeat.8.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303205882816 -> 140303257338160
	140303257338160 [label=AccumulateGrad]
	140303257346176 -> 140303255774272
	140303205882976 [label="model.model.encoder.repeat.8.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303205882976 -> 140303257346176
	140303257346176 [label=AccumulateGrad]
	140303257338448 -> 140303255774272
	140303205882896 [label="model.model.encoder.repeat.8.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303205882896 -> 140303257338448
	140303257338448 [label=AccumulateGrad]
	140303255847696 -> 140303255848320
	140303204626048 [label="model.model.encoder.repeat.8.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204626048 -> 140303255847696
	140303255847696 [label=AccumulateGrad]
	140303255849376 -> 140303255848320
	140303204626128 [label="model.model.encoder.repeat.8.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204626128 -> 140303255849376
	140303255849376 [label=AccumulateGrad]
	140303255853792 -> 140303255851680
	140303255852736 -> 140303255856096
	140303204626288 [label="model.model.encoder.repeat.9.branch0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204626288 -> 140303255852736
	140303255852736 [label=AccumulateGrad]
	140303255857776 -> 140303255856528
	140303204626368 [label="model.model.encoder.repeat.9.branch0.bn.weight
 (32)" fillcolor=lightblue]
	140303204626368 -> 140303255857776
	140303255857776 [label=AccumulateGrad]
	140303255854848 -> 140303255856528
	140303204626448 [label="model.model.encoder.repeat.9.branch0.bn.bias
 (32)" fillcolor=lightblue]
	140303204626448 -> 140303255854848
	140303255854848 [label=AccumulateGrad]
	140303255859456 -> 140303255860944
	140303255859456 [label=ReluBackward0]
	140303255853168 -> 140303255859456
	140303255853168 [label=CudnnBatchNormBackward0]
	140303255850000 -> 140303255853168
	140303255850000 [label=ConvolutionBackward0]
	140303255779024 -> 140303255850000
	140303255779024 [label=ReluBackward0]
	140303257346368 -> 140303255779024
	140303257346368 [label=CudnnBatchNormBackward0]
	140303257344688 -> 140303257346368
	140303257344688 [label=ConvolutionBackward0]
	140303255858400 -> 140303257344688
	140303257353856 -> 140303257344688
	140303204626848 [label="model.model.encoder.repeat.9.branch1.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204626848 -> 140303257353856
	140303257353856 [label=AccumulateGrad]
	140303257340992 -> 140303257346368
	140303204626928 [label="model.model.encoder.repeat.9.branch1.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204626928 -> 140303257340992
	140303257340992 [label=AccumulateGrad]
	140303257348336 -> 140303257346368
	140303204627008 [label="model.model.encoder.repeat.9.branch1.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204627008 -> 140303257348336
	140303257348336 [label=AccumulateGrad]
	140303255765392 -> 140303255850000
	140303204627488 [label="model.model.encoder.repeat.9.branch1.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303204627488 -> 140303255765392
	140303255765392 [label=AccumulateGrad]
	140303255848752 -> 140303255853168
	140303204627568 [label="model.model.encoder.repeat.9.branch1.1.bn.weight
 (32)" fillcolor=lightblue]
	140303204627568 -> 140303255848752
	140303255848752 [label=AccumulateGrad]
	140303255857152 -> 140303255853168
	140303204627648 [label="model.model.encoder.repeat.9.branch1.1.bn.bias
 (32)" fillcolor=lightblue]
	140303204627648 -> 140303255857152
	140303255857152 [label=AccumulateGrad]
	140303255859888 -> 140303255860944
	140303255859888 [label=ReluBackward0]
	140303255770144 -> 140303255859888
	140303255770144 [label=CudnnBatchNormBackward0]
	140303255854416 -> 140303255770144
	140303255854416 [label=ConvolutionBackward0]
	140303257354000 -> 140303255854416
	140303257354000 [label=ReluBackward0]
	140303257353328 -> 140303257354000
	140303257353328 [label=CudnnBatchNormBackward0]
	140303257353088 -> 140303257353328
	140303257353088 [label=ConvolutionBackward0]
	140303257352464 -> 140303257353088
	140303257352464 [label=ReluBackward0]
	140303257351696 -> 140303257352464
	140303257351696 [label=CudnnBatchNormBackward0]
	140303257351840 -> 140303257351696
	140303257351840 [label=ConvolutionBackward0]
	140303255858400 -> 140303257351840
	140303257348384 -> 140303257351840
	140303204628128 [label="model.model.encoder.repeat.9.branch2.0.conv.weight
 (32, 320, 1, 1)" fillcolor=lightblue]
	140303204628128 -> 140303257348384
	140303257348384 [label=AccumulateGrad]
	140303257351648 -> 140303257351696
	140303204628208 [label="model.model.encoder.repeat.9.branch2.0.bn.weight
 (32)" fillcolor=lightblue]
	140303204628208 -> 140303257351648
	140303257351648 [label=AccumulateGrad]
	140303257352320 -> 140303257351696
	140303204628288 [label="model.model.encoder.repeat.9.branch2.0.bn.bias
 (32)" fillcolor=lightblue]
	140303204628288 -> 140303257352320
	140303257352320 [label=AccumulateGrad]
	140303257343200 -> 140303257353088
	140303204628768 [label="model.model.encoder.repeat.9.branch2.1.conv.weight
 (48, 32, 3, 3)" fillcolor=lightblue]
	140303204628768 -> 140303257343200
	140303257343200 [label=AccumulateGrad]
	140303257353232 -> 140303257353328
	140303204628848 [label="model.model.encoder.repeat.9.branch2.1.bn.weight
 (48)" fillcolor=lightblue]
	140303204628848 -> 140303257353232
	140303257353232 [label=AccumulateGrad]
	140303257353616 -> 140303257353328
	140303204628928 [label="model.model.encoder.repeat.9.branch2.1.bn.bias
 (48)" fillcolor=lightblue]
	140303204628928 -> 140303257353616
	140303257353616 [label=AccumulateGrad]
	140303257348528 -> 140303255854416
	140303204629408 [label="model.model.encoder.repeat.9.branch2.2.conv.weight
 (64, 48, 3, 3)" fillcolor=lightblue]
	140303204629408 -> 140303257348528
	140303257348528 [label=AccumulateGrad]
	140303257342576 -> 140303255770144
	140303204629488 [label="model.model.encoder.repeat.9.branch2.2.bn.weight
 (64)" fillcolor=lightblue]
	140303204629488 -> 140303257342576
	140303257342576 [label=AccumulateGrad]
	140303257345984 -> 140303255770144
	140303204629568 [label="model.model.encoder.repeat.9.branch2.2.bn.bias
 (64)" fillcolor=lightblue]
	140303204629568 -> 140303257345984
	140303257345984 [label=AccumulateGrad]
	140303255861568 -> 140303255862192
	140303204630048 [label="model.model.encoder.repeat.9.conv2d.weight
 (320, 128, 1, 1)" fillcolor=lightblue]
	140303204630048 -> 140303255861568
	140303255861568 [label=AccumulateGrad]
	140303255863248 -> 140303255862192
	140303204630128 [label="model.model.encoder.repeat.9.conv2d.bias
 (320)" fillcolor=lightblue]
	140303204630128 -> 140303255863248
	140303255863248 [label=AccumulateGrad]
	140303255858400 -> 140303255849568
	140303255861232 -> 140303255859072
	140303204630288 [label="model.model.encoder.mixed_6a.branch0.conv.weight
 (384, 320, 3, 3)" fillcolor=lightblue]
	140303204630288 -> 140303255861232
	140303255861232 [label=AccumulateGrad]
	140303255851392 -> 140303255861616
	140303204630368 [label="model.model.encoder.mixed_6a.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140303204630368 -> 140303255851392
	140303255851392 [label=AccumulateGrad]
	140303255858304 -> 140303255861616
	140303204630448 [label="model.model.encoder.mixed_6a.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140303204630448 -> 140303255858304
	140303255858304 [label=AccumulateGrad]
	140303255855808 -> 140303255855520
	140303255855808 [label=ReluBackward0]
	140303255853888 -> 140303255855808
	140303255853888 [label=CudnnBatchNormBackward0]
	140303255852304 -> 140303255853888
	140303255852304 [label=ConvolutionBackward0]
	140303255852112 -> 140303255852304
	140303255852112 [label=ReluBackward0]
	140303257352704 -> 140303255852112
	140303257352704 [label=CudnnBatchNormBackward0]
	140303257353376 -> 140303257352704
	140303257353376 [label=ConvolutionBackward0]
	140303257349392 -> 140303257353376
	140303257349392 [label=ReluBackward0]
	140303257350016 -> 140303257349392
	140303257350016 [label=CudnnBatchNormBackward0]
	140303257345936 -> 140303257350016
	140303257345936 [label=ConvolutionBackward0]
	140303202755840 -> 140303257345936
	140303257344352 -> 140303257345936
	140303203451344 [label="model.model.encoder.mixed_6a.branch1.0.conv.weight
 (256, 320, 1, 1)" fillcolor=lightblue]
	140303203451344 -> 140303257344352
	140303257344352 [label=AccumulateGrad]
	140303257347664 -> 140303257350016
	140303203451424 [label="model.model.encoder.mixed_6a.branch1.0.bn.weight
 (256)" fillcolor=lightblue]
	140303203451424 -> 140303257347664
	140303257347664 [label=AccumulateGrad]
	140303257349200 -> 140303257350016
	140303203451504 [label="model.model.encoder.mixed_6a.branch1.0.bn.bias
 (256)" fillcolor=lightblue]
	140303203451504 -> 140303257349200
	140303257349200 [label=AccumulateGrad]
	140303257352032 -> 140303257353376
	140303203451984 [label="model.model.encoder.mixed_6a.branch1.1.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140303203451984 -> 140303257352032
	140303257352032 [label=AccumulateGrad]
	140303257352944 -> 140303257352704
	140303203452064 [label="model.model.encoder.mixed_6a.branch1.1.bn.weight
 (256)" fillcolor=lightblue]
	140303203452064 -> 140303257352944
	140303257352944 [label=AccumulateGrad]
	140303257339168 -> 140303257352704
	140303203452144 [label="model.model.encoder.mixed_6a.branch1.1.bn.bias
 (256)" fillcolor=lightblue]
	140303203452144 -> 140303257339168
	140303257339168 [label=AccumulateGrad]
	140303255858208 -> 140303255852304
	140303203452624 [label="model.model.encoder.mixed_6a.branch1.2.conv.weight
 (384, 256, 3, 3)" fillcolor=lightblue]
	140303203452624 -> 140303255858208
	140303255858208 [label=AccumulateGrad]
	140303255862624 -> 140303255853888
	140303203452704 [label="model.model.encoder.mixed_6a.branch1.2.bn.weight
 (384)" fillcolor=lightblue]
	140303203452704 -> 140303255862624
	140303255862624 [label=AccumulateGrad]
	140303255862528 -> 140303255853888
	140303203452784 [label="model.model.encoder.mixed_6a.branch1.2.bn.bias
 (384)" fillcolor=lightblue]
	140303203452784 -> 140303255862528
	140303255862528 [label=AccumulateGrad]
	140303255860128 -> 140303255855520
	140303255860128 [label=MaxPool2DWithIndicesBackward0]
	140303202755840 -> 140303255860128
	140303255856144 -> 140303255862912
	140303203453184 [label="model.model.encoder.repeat_1.0.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203453184 -> 140303255856144
	140303255856144 [label=AccumulateGrad]
	140303255858880 -> 140303255852016
	140303203453104 [label="model.model.encoder.repeat_1.0.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203453104 -> 140303255858880
	140303255858880 [label=AccumulateGrad]
	140303255853264 -> 140303255852016
	140303203453264 [label="model.model.encoder.repeat_1.0.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203453264 -> 140303255853264
	140303255853264 [label=AccumulateGrad]
	140303255853360 -> 140303255850528
	140303255853360 [label=ReluBackward0]
	140303255847888 -> 140303255853360
	140303255847888 [label=CudnnBatchNormBackward0]
	140303255860512 -> 140303255847888
	140303255860512 [label=ConvolutionBackward0]
	140303255855088 -> 140303255860512
	140303255855088 [label=ReluBackward0]
	140303257346080 -> 140303255855088
	140303257346080 [label=CudnnBatchNormBackward0]
	140303257343872 -> 140303257346080
	140303257343872 [label=ConvolutionBackward0]
	140303257342720 -> 140303257343872
	140303257342720 [label=ReluBackward0]
	140303257347760 -> 140303257342720
	140303257347760 [label=CudnnBatchNormBackward0]
	140303257345840 -> 140303257347760
	140303257345840 [label=ConvolutionBackward0]
	140303255855520 -> 140303257345840
	140303257345744 -> 140303257345840
	140303203453744 [label="model.model.encoder.repeat_1.0.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203453744 -> 140303257345744
	140303257345744 [label=AccumulateGrad]
	140303257338544 -> 140303257347760
	140303203453824 [label="model.model.encoder.repeat_1.0.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203453824 -> 140303257338544
	140303257338544 [label=AccumulateGrad]
	140303257343104 -> 140303257347760
	140303203453904 [label="model.model.encoder.repeat_1.0.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203453904 -> 140303257343104
	140303257343104 [label=AccumulateGrad]
	140303257343248 -> 140303257343872
	140303203454384 [label="model.model.encoder.repeat_1.0.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203454384 -> 140303257343248
	140303257343248 [label=AccumulateGrad]
	140303257344400 -> 140303257346080
	140303203454464 [label="model.model.encoder.repeat_1.0.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203454464 -> 140303257344400
	140303257344400 [label=AccumulateGrad]
	140303257353808 -> 140303257346080
	140303203454544 [label="model.model.encoder.repeat_1.0.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203454544 -> 140303257353808
	140303257353808 [label=AccumulateGrad]
	140303257346464 -> 140303255860512
	140303203455024 [label="model.model.encoder.repeat_1.0.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203455024 -> 140303257346464
	140303257346464 [label=AccumulateGrad]
	140303255852352 -> 140303255847888
	140303203455104 [label="model.model.encoder.repeat_1.0.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203455104 -> 140303255852352
	140303255852352 [label=AccumulateGrad]
	140303255854080 -> 140303255847888
	140303203455184 [label="model.model.encoder.repeat_1.0.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203455184 -> 140303255854080
	140303255854080 [label=AccumulateGrad]
	140303255859264 -> 140303255848704
	140303203455664 [label="model.model.encoder.repeat_1.0.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203455664 -> 140303255859264
	140303255859264 [label=AccumulateGrad]
	140303255860752 -> 140303255848704
	140303203455744 [label="model.model.encoder.repeat_1.0.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203455744 -> 140303255860752
	140303255860752 [label=AccumulateGrad]
	140303255855520 -> 140303255851296
	140303255852592 -> 140302584750592
	140303203455904 [label="model.model.encoder.repeat_1.1.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203455904 -> 140303255852592
	140303255852592 [label=AccumulateGrad]
	140303255849472 -> 140303206983536
	140303203455984 [label="model.model.encoder.repeat_1.1.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203455984 -> 140303255849472
	140303255849472 [label=AccumulateGrad]
	140303255856960 -> 140303206983536
	140303203456064 [label="model.model.encoder.repeat_1.1.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203456064 -> 140303255856960
	140303255856960 [label=AccumulateGrad]
	140303255933888 -> 140303255934944
	140303255933888 [label=ReluBackward0]
	140303206983872 -> 140303255933888
	140303206983872 [label=CudnnBatchNormBackward0]
	140303255860992 -> 140303206983872
	140303255860992 [label=ConvolutionBackward0]
	140303255854464 -> 140303255860992
	140303255854464 [label=ReluBackward0]
	140303255861856 -> 140303255854464
	140303255861856 [label=CudnnBatchNormBackward0]
	140303257344736 -> 140303255861856
	140303257344736 [label=ConvolutionBackward0]
	140303257348816 -> 140303257344736
	140303257348816 [label=ReluBackward0]
	140303257343920 -> 140303257348816
	140303257343920 [label=CudnnBatchNormBackward0]
	140303257353472 -> 140303257343920
	140303257353472 [label=ConvolutionBackward0]
	140303255942096 -> 140303257353472
	140303257353904 -> 140303257353472
	140303203456544 [label="model.model.encoder.repeat_1.1.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203456544 -> 140303257353904
	140303257353904 [label=AccumulateGrad]
	140303257339360 -> 140303257343920
	140303203456624 [label="model.model.encoder.repeat_1.1.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203456624 -> 140303257339360
	140303257339360 [label=AccumulateGrad]
	140303257350304 -> 140303257343920
	140303203456704 [label="model.model.encoder.repeat_1.1.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203456704 -> 140303257350304
	140303257350304 [label=AccumulateGrad]
	140303257341136 -> 140303257344736
	140303203457184 [label="model.model.encoder.repeat_1.1.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203457184 -> 140303257341136
	140303257341136 [label=AccumulateGrad]
	140303257344208 -> 140303255861856
	140303203457264 [label="model.model.encoder.repeat_1.1.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203457264 -> 140303257344208
	140303257344208 [label=AccumulateGrad]
	140303257346656 -> 140303255861856
	140303203457344 [label="model.model.encoder.repeat_1.1.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203457344 -> 140303257346656
	140303257346656 [label=AccumulateGrad]
	140303255862384 -> 140303255860992
	140303203457824 [label="model.model.encoder.repeat_1.1.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203457824 -> 140303255862384
	140303255862384 [label=AccumulateGrad]
	140303255863200 -> 140303206983872
	140303203457904 [label="model.model.encoder.repeat_1.1.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203457904 -> 140303255863200
	140303255863200 [label=AccumulateGrad]
	140303255851584 -> 140303206983872
	140303203457984 [label="model.model.encoder.repeat_1.1.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203457984 -> 140303255851584
	140303255851584 [label=AccumulateGrad]
	140303255935568 -> 140303255936000
	140303203458304 [label="model.model.encoder.repeat_1.1.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203458304 -> 140303255935568
	140303255935568 [label=AccumulateGrad]
	140303255937248 -> 140303255936000
	140303203458384 [label="model.model.encoder.repeat_1.1.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203458384 -> 140303255937248
	140303255937248 [label=AccumulateGrad]
	140303255942096 -> 140303255939984
	140303255941040 -> 140303255944400
	140303203458544 [label="model.model.encoder.repeat_1.2.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203458544 -> 140303255941040
	140303255941040 [label=AccumulateGrad]
	140303255936384 -> 140303255945024
	140303203458624 [label="model.model.encoder.repeat_1.2.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203458624 -> 140303255936384
	140303255936384 [label=AccumulateGrad]
	140303255943344 -> 140303255945024
	140303203458704 [label="model.model.encoder.repeat_1.2.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203458704 -> 140303255943344
	140303255943344 [label=AccumulateGrad]
	140303255936144 -> 140303255937392
	140303255936144 [label=ReluBackward0]
	140303255941664 -> 140303255936144
	140303255941664 [label=CudnnBatchNormBackward0]
	140303255937680 -> 140303255941664
	140303255937680 [label=ConvolutionBackward0]
	140303206983680 -> 140303255937680
	140303206983680 [label=ReluBackward0]
	140303255848128 -> 140303206983680
	140303255848128 [label=CudnnBatchNormBackward0]
	140303257345264 -> 140303255848128
	140303257345264 [label=ConvolutionBackward0]
	140303257352848 -> 140303257345264
	140303257352848 [label=ReluBackward0]
	140303257352224 -> 140303257352848
	140303257352224 [label=CudnnBatchNormBackward0]
	140303257351168 -> 140303257352224
	140303257351168 [label=ConvolutionBackward0]
	140303255929472 -> 140303257351168
	140303257348864 -> 140303257351168
	140303203459184 [label="model.model.encoder.repeat_1.2.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203459184 -> 140303257348864
	140303257348864 [label=AccumulateGrad]
	140303257351792 -> 140303257352224
	140303203459264 [label="model.model.encoder.repeat_1.2.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203459264 -> 140303257351792
	140303257351792 [label=AccumulateGrad]
	140303257353280 -> 140303257352224
	140303203459344 [label="model.model.encoder.repeat_1.2.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203459344 -> 140303257353280
	140303257353280 [label=AccumulateGrad]
	140303257350736 -> 140303257345264
	140303203459824 [label="model.model.encoder.repeat_1.2.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203459824 -> 140303257350736
	140303257350736 [label=AccumulateGrad]
	140303257340128 -> 140303255848128
	140303203459904 [label="model.model.encoder.repeat_1.2.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203459904 -> 140303257340128
	140303257340128 [label=AccumulateGrad]
	140303257347280 -> 140303255848128
	140303203459984 [label="model.model.encoder.repeat_1.2.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203459984 -> 140303257347280
	140303257347280 [label=AccumulateGrad]
	140303255934320 -> 140303255937680
	140303203460464 [label="model.model.encoder.repeat_1.2.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203460464 -> 140303255934320
	140303255934320 [label=AccumulateGrad]
	140303255936624 -> 140303255941664
	140303203460544 [label="model.model.encoder.repeat_1.2.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203460544 -> 140303255936624
	140303255936624 [label=AccumulateGrad]
	140303255934032 -> 140303255941664
	140303203460624 [label="model.model.encoder.repeat_1.2.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203460624 -> 140303255934032
	140303255934032 [label=AccumulateGrad]
	140303255933648 -> 140303255939072
	140303203461024 [label="model.model.encoder.repeat_1.2.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203461024 -> 140303255933648
	140303255933648 [label=AccumulateGrad]
	140303255942240 -> 140303255939072
	140303203461104 [label="model.model.encoder.repeat_1.2.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203461104 -> 140303255942240
	140303255942240 [label=AccumulateGrad]
	140303255929472 -> 140303256043824
	140303256045072 -> 140303256048240
	140303203461264 [label="model.model.encoder.repeat_1.3.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203461264 -> 140303256045072
	140303256045072 [label=AccumulateGrad]
	140303256049920 -> 140303256048864
	140303203461344 [label="model.model.encoder.repeat_1.3.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203461344 -> 140303256049920
	140303256049920 [label=AccumulateGrad]
	140303256047184 -> 140303256048864
	140303203461424 [label="model.model.encoder.repeat_1.3.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203461424 -> 140303256047184
	140303256047184 [label=AccumulateGrad]
	140303256051168 -> 140303256052848
	140303256051168 [label=ReluBackward0]
	140303256045504 -> 140303256051168
	140303256045504 [label=CudnnBatchNormBackward0]
	140303256044448 -> 140303256045504
	140303256044448 [label=ConvolutionBackward0]
	140303255942720 -> 140303256044448
	140303255942720 [label=ReluBackward0]
	140303255852640 -> 140303255942720
	140303255852640 [label=CudnnBatchNormBackward0]
	140303255940608 -> 140303255852640
	140303255940608 [label=ConvolutionBackward0]
	140303257347808 -> 140303255940608
	140303257347808 [label=ReluBackward0]
	140303257347184 -> 140303257347808
	140303257347184 [label=CudnnBatchNormBackward0]
	140303257346128 -> 140303257347184
	140303257346128 [label=ConvolutionBackward0]
	140303256059376 -> 140303257346128
	140303257344016 -> 140303257346128
	140303203461904 [label="model.model.encoder.repeat_1.3.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203461904 -> 140303257344016
	140303257344016 [label=AccumulateGrad]
	140303257346752 -> 140303257347184
	140303203461984 [label="model.model.encoder.repeat_1.3.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203461984 -> 140303257346752
	140303257346752 [label=AccumulateGrad]
	140303257348432 -> 140303257347184
	140303203462064 [label="model.model.encoder.repeat_1.3.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203462064 -> 140303257348432
	140303257348432 [label=AccumulateGrad]
	140303257339888 -> 140303255940608
	140303203462544 [label="model.model.encoder.repeat_1.3.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203462544 -> 140303257339888
	140303257339888 [label=AccumulateGrad]
	140303257352752 -> 140303255852640
	140303203462624 [label="model.model.encoder.repeat_1.3.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203462624 -> 140303257352752
	140303257352752 [label=AccumulateGrad]
	140303257346800 -> 140303255852640
	140303203462704 [label="model.model.encoder.repeat_1.3.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203462704 -> 140303257346800
	140303257346800 [label=AccumulateGrad]
	140303255934704 -> 140303256044448
	140303203463104 [label="model.model.encoder.repeat_1.3.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203463104 -> 140303255934704
	140303255934704 [label=AccumulateGrad]
	140303256049488 -> 140303256045504
	140303203463184 [label="model.model.encoder.repeat_1.3.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203463184 -> 140303256049488
	140303256049488 [label=AccumulateGrad]
	140303255937824 -> 140303256045504
	140303203463264 [label="model.model.encoder.repeat_1.3.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203463264 -> 140303255937824
	140303255937824 [label=AccumulateGrad]
	140303256053280 -> 140303256053904
	140303203463744 [label="model.model.encoder.repeat_1.3.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203463744 -> 140303256053280
	140303256053280 [label=AccumulateGrad]
	140303256054960 -> 140303256053904
	140303203463824 [label="model.model.encoder.repeat_1.3.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203463824 -> 140303256054960
	140303256054960 [label=AccumulateGrad]
	140303256059376 -> 140303256057264
	140303256058320 -> 140303256054000
	140303203463984 [label="model.model.encoder.repeat_1.4.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203463984 -> 140303256058320
	140303256058320 [label=AccumulateGrad]
	140303256058464 -> 140303256044208
	140303203464064 [label="model.model.encoder.repeat_1.4.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203464064 -> 140303256058464
	140303256058464 [label=AccumulateGrad]
	140303256056784 -> 140303256044208
	140303203464144 [label="model.model.encoder.repeat_1.4.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203464144 -> 140303256056784
	140303256056784 [label=AccumulateGrad]
	140303256046464 -> 140303256043632
	140303256046464 [label=ReluBackward0]
	140303256058944 -> 140303256046464
	140303256058944 [label=CudnnBatchNormBackward0]
	140303256055584 -> 140303256058944
	140303256055584 [label=ConvolutionBackward0]
	140303256046752 -> 140303256055584
	140303256046752 [label=ReluBackward0]
	140303255858112 -> 140303256046752
	140303255858112 [label=CudnnBatchNormBackward0]
	140303255938688 -> 140303255858112
	140303255938688 [label=ConvolutionBackward0]
	140303257342768 -> 140303255938688
	140303257342768 [label=ReluBackward0]
	140303257342336 -> 140303257342768
	140303257342336 [label=CudnnBatchNormBackward0]
	140303257341088 -> 140303257342336
	140303257341088 [label=ConvolutionBackward0]
	140303256044688 -> 140303257341088
	140303257338976 -> 140303257341088
	140303203464544 [label="model.model.encoder.repeat_1.4.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203464544 -> 140303257338976
	140303257338976 [label=AccumulateGrad]
	140303257341712 -> 140303257342336
	140303203464624 [label="model.model.encoder.repeat_1.4.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203464624 -> 140303257341712
	140303257341712 [label=AccumulateGrad]
	140303257343392 -> 140303257342336
	140303203464704 [label="model.model.encoder.repeat_1.4.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203464704 -> 140303257343392
	140303257343392 [label=AccumulateGrad]
	140303257350112 -> 140303255938688
	140303203465104 [label="model.model.encoder.repeat_1.4.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203465104 -> 140303257350112
	140303257350112 [label=AccumulateGrad]
	140303257349488 -> 140303255858112
	140303203465184 [label="model.model.encoder.repeat_1.4.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203465184 -> 140303257349488
	140303257349488 [label=AccumulateGrad]
	140303257350544 -> 140303255858112
	140303203465264 [label="model.model.encoder.repeat_1.4.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203465264 -> 140303257350544
	140303257350544 [label=AccumulateGrad]
	140303256051600 -> 140303256055584
	140303203465744 [label="model.model.encoder.repeat_1.4.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203465744 -> 140303256051600
	140303256051600 [label=AccumulateGrad]
	140303256054528 -> 140303256058944
	140303203465824 [label="model.model.encoder.repeat_1.4.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203465824 -> 140303256054528
	140303256054528 [label=AccumulateGrad]
	140303256059232 -> 140303256058944
	140303203465904 [label="model.model.encoder.repeat_1.4.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203465904 -> 140303256059232
	140303256059232 [label=AccumulateGrad]
	140303256043680 -> 140303256043728
	140303203466304 [label="model.model.encoder.repeat_1.4.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203466304 -> 140303256043680
	140303256043680 [label=AccumulateGrad]
	140303256043872 -> 140303256043728
	140303203466384 [label="model.model.encoder.repeat_1.4.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203466384 -> 140303256043872
	140303256043872 [label=AccumulateGrad]
	140303256044688 -> 140303256044256
	140303256044352 -> 140303256044928
	140303203466544 [label="model.model.encoder.repeat_1.5.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203466544 -> 140303256044352
	140303256044352 [label=AccumulateGrad]
	140303256045120 -> 140303256044976
	140303203466624 [label="model.model.encoder.repeat_1.5.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203466624 -> 140303256045120
	140303256045120 [label=AccumulateGrad]
	140303256044784 -> 140303256044976
	140303203466704 [label="model.model.encoder.repeat_1.5.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203466704 -> 140303256044784
	140303256044784 [label=AccumulateGrad]
	140303256045312 -> 140303256045552
	140303256045312 [label=ReluBackward0]
	140303256044496 -> 140303256045312
	140303256044496 [label=CudnnBatchNormBackward0]
	140303256043968 -> 140303256044496
	140303256043968 [label=ConvolutionBackward0]
	140303256057408 -> 140303256043968
	140303256057408 [label=ReluBackward0]
	140303255932976 -> 140303256057408
	140303255932976 [label=CudnnBatchNormBackward0]
	140303256057696 -> 140303255932976
	140303256057696 [label=ConvolutionBackward0]
	140303257338352 -> 140303256057696
	140303257338352 [label=ReluBackward0]
	140303257340032 -> 140303257338352
	140303257340032 [label=CudnnBatchNormBackward0]
	140303257266272 -> 140303257340032
	140303257266272 [label=ConvolutionBackward0]
	140303256046560 -> 140303257266272
	140303257270496 -> 140303257266272
	140303203467104 [label="model.model.encoder.repeat_1.5.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203467104 -> 140303257270496
	140303257270496 [label=AccumulateGrad]
	140303257260368 -> 140303257340032
	140303203467184 [label="model.model.encoder.repeat_1.5.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203467184 -> 140303257260368
	140303257260368 [label=AccumulateGrad]
	140303257268288 -> 140303257340032
	140303203795008 [label="model.model.encoder.repeat_1.5.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203795008 -> 140303257268288
	140303257268288 [label=AccumulateGrad]
	140303257345072 -> 140303256057696
	140303203795488 [label="model.model.encoder.repeat_1.5.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203795488 -> 140303257345072
	140303257345072 [label=AccumulateGrad]
	140303257344448 -> 140303255932976
	140303203795568 [label="model.model.encoder.repeat_1.5.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203795568 -> 140303257344448
	140303257344448 [label=AccumulateGrad]
	140303257345504 -> 140303255932976
	140303203795648 [label="model.model.encoder.repeat_1.5.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203795648 -> 140303257345504
	140303257345504 [label=AccumulateGrad]
	140303256046224 -> 140303256043968
	140303203796048 [label="model.model.encoder.repeat_1.5.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203796048 -> 140303256046224
	140303256046224 [label=AccumulateGrad]
	140303256043776 -> 140303256044496
	140303203796128 [label="model.model.encoder.repeat_1.5.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203796128 -> 140303256043776
	140303256043776 [label=AccumulateGrad]
	140303256045024 -> 140303256044496
	140303203796208 [label="model.model.encoder.repeat_1.5.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203796208 -> 140303256045024
	140303256045024 [label=AccumulateGrad]
	140303256045600 -> 140303256045696
	140303203796688 [label="model.model.encoder.repeat_1.5.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203796688 -> 140303256045600
	140303256045600 [label=AccumulateGrad]
	140303256045792 -> 140303256045696
	140303203796768 [label="model.model.encoder.repeat_1.5.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203796768 -> 140303256045792
	140303256045792 [label=AccumulateGrad]
	140303256046560 -> 140303256046176
	140303256046368 -> 140303256046848
	140303203796928 [label="model.model.encoder.repeat_1.6.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203796928 -> 140303256046368
	140303256046368 [label=AccumulateGrad]
	140303256047136 -> 140303256046992
	140303203797008 [label="model.model.encoder.repeat_1.6.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203797008 -> 140303256047136
	140303256047136 [label=AccumulateGrad]
	140303256046704 -> 140303256046992
	140303203797088 [label="model.model.encoder.repeat_1.6.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203797088 -> 140303256046704
	140303256046704 [label=AccumulateGrad]
	140303256047376 -> 140303256047616
	140303256047376 [label=ReluBackward0]
	140303257340656 -> 140303256047376
	140303257340656 [label=CudnnBatchNormBackward0]
	140303256046416 -> 140303257340656
	140303256046416 [label=ConvolutionBackward0]
	140303256045456 -> 140303256046416
	140303256045456 [label=ReluBackward0]
	140303256044304 -> 140303256045456
	140303256044304 [label=CudnnBatchNormBackward0]
	140303256052224 -> 140303256044304
	140303256052224 [label=ConvolutionBackward0]
	140303257265792 -> 140303256052224
	140303257265792 [label=ReluBackward0]
	140303257263536 -> 140303257265792
	140303257263536 [label=CudnnBatchNormBackward0]
	140303257261712 -> 140303257263536
	140303257261712 [label=ConvolutionBackward0]
	140303256048720 -> 140303257261712
	140303257259744 -> 140303257261712
	140303203797568 [label="model.model.encoder.repeat_1.6.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203797568 -> 140303257259744
	140303257259744 [label=AccumulateGrad]
	140303257264400 -> 140303257263536
	140303203797648 [label="model.model.encoder.repeat_1.6.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203797648 -> 140303257264400
	140303257264400 [label=AccumulateGrad]
	140303257259456 -> 140303257263536
	140303203797728 [label="model.model.encoder.repeat_1.6.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203797728 -> 140303257259456
	140303257259456 [label=AccumulateGrad]
	140303257263968 -> 140303256052224
	140303203798208 [label="model.model.encoder.repeat_1.6.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203798208 -> 140303257263968
	140303257263968 [label=AccumulateGrad]
	140303256043584 -> 140303256044304
	140303203798288 [label="model.model.encoder.repeat_1.6.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203798288 -> 140303256043584
	140303256043584 [label=AccumulateGrad]
	140303256045408 -> 140303256044304
	140303203798368 [label="model.model.encoder.repeat_1.6.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203798368 -> 140303256045408
	140303256045408 [label=AccumulateGrad]
	140303256045744 -> 140303256046416
	140303203798848 [label="model.model.encoder.repeat_1.6.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203798848 -> 140303256045744
	140303256045744 [label=AccumulateGrad]
	140303256046656 -> 140303257340656
	140303203798928 [label="model.model.encoder.repeat_1.6.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203798928 -> 140303256046656
	140303256046656 [label=AccumulateGrad]
	140303256047088 -> 140303257340656
	140303203799008 [label="model.model.encoder.repeat_1.6.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203799008 -> 140303256047088
	140303256047088 [label=AccumulateGrad]
	140303256047712 -> 140303256047760
	140303203799488 [label="model.model.encoder.repeat_1.6.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203799488 -> 140303256047712
	140303256047712 [label=AccumulateGrad]
	140303256048048 -> 140303256047760
	140303203799568 [label="model.model.encoder.repeat_1.6.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203799568 -> 140303256048048
	140303256048048 [label=AccumulateGrad]
	140303256048720 -> 140303256048480
	140303256048576 -> 140303256049056
	140303203799728 [label="model.model.encoder.repeat_1.7.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203799728 -> 140303256048576
	140303256048576 [label=AccumulateGrad]
	140303256049296 -> 140303256049152
	140303203799808 [label="model.model.encoder.repeat_1.7.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203799808 -> 140303256049296
	140303256049296 [label=AccumulateGrad]
	140303256048912 -> 140303256049152
	140303203799888 [label="model.model.encoder.repeat_1.7.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203799888 -> 140303256048912
	140303256048912 [label=AccumulateGrad]
	140303256049392 -> 140303256049728
	140303256049392 [label=ReluBackward0]
	140303257339408 -> 140303256049392
	140303257339408 [label=CudnnBatchNormBackward0]
	140303256048144 -> 140303257339408
	140303256048144 [label=ConvolutionBackward0]
	140303256047472 -> 140303256048144
	140303256047472 [label=ReluBackward0]
	140303256044736 -> 140303256047472
	140303256044736 [label=CudnnBatchNormBackward0]
	140303256046320 -> 140303256044736
	140303256046320 [label=ConvolutionBackward0]
	140303257269584 -> 140303256046320
	140303257269584 [label=ReluBackward0]
	140303257256912 -> 140303257269584
	140303257256912 [label=CudnnBatchNormBackward0]
	140303257258592 -> 140303257256912
	140303257258592 [label=ConvolutionBackward0]
	140303256047424 -> 140303257258592
	140303257261808 -> 140303257258592
	140303203800368 [label="model.model.encoder.repeat_1.7.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203800368 -> 140303257261808
	140303257261808 [label=AccumulateGrad]
	140303257272176 -> 140303257256912
	140303203800448 [label="model.model.encoder.repeat_1.7.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203800448 -> 140303257272176
	140303257272176 [label=AccumulateGrad]
	140303257265168 -> 140303257256912
	140303203800528 [label="model.model.encoder.repeat_1.7.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203800528 -> 140303257265168
	140303257265168 [label=AccumulateGrad]
	140303257267232 -> 140303256046320
	140303203800928 [label="model.model.encoder.repeat_1.7.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203800928 -> 140303257267232
	140303257267232 [label=AccumulateGrad]
	140303257257392 -> 140303256044736
	140303203801008 [label="model.model.encoder.repeat_1.7.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203801008 -> 140303257257392
	140303257257392 [label=AccumulateGrad]
	140303257271264 -> 140303256044736
	140303203801088 [label="model.model.encoder.repeat_1.7.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203801088 -> 140303257271264
	140303257271264 [label=AccumulateGrad]
	140303256047520 -> 140303256048144
	140303203801568 [label="model.model.encoder.repeat_1.7.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203801568 -> 140303256047520
	140303256047520 [label=AccumulateGrad]
	140303256048672 -> 140303257339408
	140303203801648 [label="model.model.encoder.repeat_1.7.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203801648 -> 140303256048672
	140303256048672 [label=AccumulateGrad]
	140303256049200 -> 140303257339408
	140303203801728 [label="model.model.encoder.repeat_1.7.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203801728 -> 140303256049200
	140303256049200 [label=AccumulateGrad]
	140303256049824 -> 140303256049872
	140303203802048 [label="model.model.encoder.repeat_1.7.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203802048 -> 140303256049824
	140303256049824 [label=AccumulateGrad]
	140303256050016 -> 140303256049872
	140303203802128 [label="model.model.encoder.repeat_1.7.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203802128 -> 140303256050016
	140303256050016 [label=AccumulateGrad]
	140303256047424 -> 140303256050256
	140303256050400 -> 140303256054912
	140303203802288 [label="model.model.encoder.repeat_1.8.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203802288 -> 140303256050400
	140303256050400 [label=AccumulateGrad]
	140303256050880 -> 140303256050736
	140303203802368 [label="model.model.encoder.repeat_1.8.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203802368 -> 140303256050880
	140303256050880 [label=AccumulateGrad]
	140303256050640 -> 140303256050736
	140303203802448 [label="model.model.encoder.repeat_1.8.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203802448 -> 140303256050640
	140303256050640 [label=AccumulateGrad]
	140303256051072 -> 140303256051360
	140303256051072 [label=ReluBackward0]
	140303256050448 -> 140303256051072
	140303256050448 [label=CudnnBatchNormBackward0]
	140303256050112 -> 140303256050448
	140303256050112 [label=ConvolutionBackward0]
	140303256048816 -> 140303256050112
	140303256048816 [label=ReluBackward0]
	140303256045840 -> 140303256048816
	140303256045840 [label=CudnnBatchNormBackward0]
	140303256048528 -> 140303256045840
	140303256048528 [label=ConvolutionBackward0]
	140303257257440 -> 140303256048528
	140303257257440 [label=ReluBackward0]
	140303257270832 -> 140303257257440
	140303257270832 [label=CudnnBatchNormBackward0]
	140303257265216 -> 140303257270832
	140303257265216 [label=ConvolutionBackward0]
	140303256052080 -> 140303257265216
	140303257267616 -> 140303257265216
	140303203802928 [label="model.model.encoder.repeat_1.8.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203802928 -> 140303257267616
	140303257267616 [label=AccumulateGrad]
	140303257267664 -> 140303257270832
	140303203803008 [label="model.model.encoder.repeat_1.8.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203803008 -> 140303257267664
	140303257267664 [label=AccumulateGrad]
	140303257262288 -> 140303257270832
	140303203803088 [label="model.model.encoder.repeat_1.8.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203803088 -> 140303257262288
	140303257262288 [label=AccumulateGrad]
	140303257265408 -> 140303256048528
	140303203803568 [label="model.model.encoder.repeat_1.8.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203803568 -> 140303257265408
	140303257265408 [label=AccumulateGrad]
	140303257259360 -> 140303256045840
	140303203803648 [label="model.model.encoder.repeat_1.8.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203803648 -> 140303257259360
	140303257259360 [label=AccumulateGrad]
	140303257258448 -> 140303256045840
	140303203803728 [label="model.model.encoder.repeat_1.8.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203803728 -> 140303257258448
	140303257258448 [label=AccumulateGrad]
	140303256049536 -> 140303256050112
	140303203804208 [label="model.model.encoder.repeat_1.8.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203804208 -> 140303256049536
	140303256049536 [label=AccumulateGrad]
	140303256049968 -> 140303256050448
	140303203804288 [label="model.model.encoder.repeat_1.8.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203804288 -> 140303256049968
	140303256049968 [label=AccumulateGrad]
	140303256050832 -> 140303256050448
	140303203804368 [label="model.model.encoder.repeat_1.8.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203804368 -> 140303256050832
	140303256050832 [label=AccumulateGrad]
	140303256051408 -> 140303256051504
	140303203804848 [label="model.model.encoder.repeat_1.8.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203804848 -> 140303256051408
	140303256051408 [label=AccumulateGrad]
	140303256051648 -> 140303256051504
	140303203804928 [label="model.model.encoder.repeat_1.8.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203804928 -> 140303256051648
	140303256051648 [label=AccumulateGrad]
	140303256052080 -> 140303256056304
	140303256051936 -> 140303256052320
	140303203805088 [label="model.model.encoder.repeat_1.9.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203805088 -> 140303256051936
	140303256051936 [label=AccumulateGrad]
	140303256052560 -> 140303256052464
	140303203805168 [label="model.model.encoder.repeat_1.9.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203805168 -> 140303256052560
	140303256052560 [label=AccumulateGrad]
	140303256052176 -> 140303256052464
	140303203805248 [label="model.model.encoder.repeat_1.9.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203805248 -> 140303256052176
	140303256052176 [label=AccumulateGrad]
	140303256052752 -> 140303256052944
	140303256052752 [label=ReluBackward0]
	140303256047664 -> 140303256052752
	140303256047664 [label=CudnnBatchNormBackward0]
	140303256051696 -> 140303256047664
	140303256051696 [label=ConvolutionBackward0]
	140303256050592 -> 140303256051696
	140303256050592 [label=ReluBackward0]
	140303256047856 -> 140303256050592
	140303256047856 [label=CudnnBatchNormBackward0]
	140303256050352 -> 140303256047856
	140303256050352 [label=ConvolutionBackward0]
	140303257264784 -> 140303256050352
	140303257264784 [label=ReluBackward0]
	140303257270544 -> 140303257264784
	140303257270544 [label=CudnnBatchNormBackward0]
	140303257261952 -> 140303257270544
	140303257261952 [label=ConvolutionBackward0]
	140303256053808 -> 140303257261952
	140303257257728 -> 140303257261952
	140303203805728 [label="model.model.encoder.repeat_1.9.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203805728 -> 140303257257728
	140303257257728 [label=AccumulateGrad]
	140303257269440 -> 140303257270544
	140303203805808 [label="model.model.encoder.repeat_1.9.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203805808 -> 140303257269440
	140303257269440 [label=AccumulateGrad]
	140303257260656 -> 140303257270544
	140303203805888 [label="model.model.encoder.repeat_1.9.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203805888 -> 140303257260656
	140303257260656 [label=AccumulateGrad]
	140303257256768 -> 140303256050352
	140303203806288 [label="model.model.encoder.repeat_1.9.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203806288 -> 140303257256768
	140303257256768 [label=AccumulateGrad]
	140303257270112 -> 140303256047856
	140303203806368 [label="model.model.encoder.repeat_1.9.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203806368 -> 140303257270112
	140303257270112 [label=AccumulateGrad]
	140303257256816 -> 140303256047856
	140303203806448 [label="model.model.encoder.repeat_1.9.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203806448 -> 140303257256816
	140303257256816 [label=AccumulateGrad]
	140303256051120 -> 140303256051696
	140303203806928 [label="model.model.encoder.repeat_1.9.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203806928 -> 140303256051120
	140303256051120 [label=AccumulateGrad]
	140303256051552 -> 140303256047664
	140303203807008 [label="model.model.encoder.repeat_1.9.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203807008 -> 140303256051552
	140303256051552 [label=AccumulateGrad]
	140303256052512 -> 140303256047664
	140303203807088 [label="model.model.encoder.repeat_1.9.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203807088 -> 140303256052512
	140303256052512 [label=AccumulateGrad]
	140303256053040 -> 140303256053088
	140303203807568 [label="model.model.encoder.repeat_1.9.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203807568 -> 140303256053040
	140303256053040 [label=AccumulateGrad]
	140303256053328 -> 140303256053088
	140303203807648 [label="model.model.encoder.repeat_1.9.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203807648 -> 140303256053328
	140303256053328 [label=AccumulateGrad]
	140303256053808 -> 140303256053520
	140303256053712 -> 140303256054240
	140303203807808 [label="model.model.encoder.repeat_1.10.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203807808 -> 140303256053712
	140303256053712 [label=AccumulateGrad]
	140303256054480 -> 140303256054336
	140303203807888 [label="model.model.encoder.repeat_1.10.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203807888 -> 140303256054480
	140303256054480 [label=AccumulateGrad]
	140303256054096 -> 140303256054336
	140303203807968 [label="model.model.encoder.repeat_1.10.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203807968 -> 140303256054096
	140303256054096 [label=AccumulateGrad]
	140303256059328 -> 140303256055056
	140303256059328 [label=ReluBackward0]
	140303256053760 -> 140303256059328
	140303256053760 [label=CudnnBatchNormBackward0]
	140303256053376 -> 140303256053760
	140303256053376 [label=ConvolutionBackward0]
	140303256052128 -> 140303256053376
	140303256052128 [label=ReluBackward0]
	140303256049680 -> 140303256052128
	140303256049680 [label=CudnnBatchNormBackward0]
	140303256051888 -> 140303256049680
	140303256051888 [label=ConvolutionBackward0]
	140303257269344 -> 140303256051888
	140303257269344 [label=ReluBackward0]
	140303257268000 -> 140303257269344
	140303257268000 [label=CudnnBatchNormBackward0]
	140303257259120 -> 140303257268000
	140303257259120 [label=ConvolutionBackward0]
	140303256055872 -> 140303257259120
	140303257258832 -> 140303257259120
	140303203808448 [label="model.model.encoder.repeat_1.10.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203808448 -> 140303257258832
	140303257258832 [label=AccumulateGrad]
	140303257271168 -> 140303257268000
	140303203808528 [label="model.model.encoder.repeat_1.10.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203808528 -> 140303257271168
	140303257271168 [label=AccumulateGrad]
	140303257264016 -> 140303257268000
	140303203808608 [label="model.model.encoder.repeat_1.10.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303203808608 -> 140303257264016
	140303257264016 [label=AccumulateGrad]
	140303257266992 -> 140303256051888
	140303203809088 [label="model.model.encoder.repeat_1.10.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303203809088 -> 140303257266992
	140303257266992 [label=AccumulateGrad]
	140303257266704 -> 140303256049680
	140303203809168 [label="model.model.encoder.repeat_1.10.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303203809168 -> 140303257266704
	140303257266704 [label=AccumulateGrad]
	140303257261232 -> 140303256049680
	140303203809248 [label="model.model.encoder.repeat_1.10.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303203809248 -> 140303257261232
	140303257261232 [label=AccumulateGrad]
	140303256052800 -> 140303256053376
	140303203809648 [label="model.model.encoder.repeat_1.10.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303203809648 -> 140303256052800
	140303256052800 [label=AccumulateGrad]
	140303256053232 -> 140303256053760
	140303203809728 [label="model.model.encoder.repeat_1.10.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303203809728 -> 140303256053232
	140303256053232 [label=AccumulateGrad]
	140303256054432 -> 140303256053760
	140303203809808 [label="model.model.encoder.repeat_1.10.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303203809808 -> 140303256054432
	140303256054432 [label=AccumulateGrad]
	140303256055200 -> 140303256055248
	140303203810288 [label="model.model.encoder.repeat_1.10.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303203810288 -> 140303256055200
	140303256055200 [label=AccumulateGrad]
	140303256057888 -> 140303256055248
	140303203810368 [label="model.model.encoder.repeat_1.10.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303203810368 -> 140303256057888
	140303256057888 [label=AccumulateGrad]
	140303256055872 -> 140303256055536
	140303256055776 -> 140303256056112
	140303203810528 [label="model.model.encoder.repeat_1.11.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303203810528 -> 140303256055776
	140303256055776 [label=AccumulateGrad]
	140303256056256 -> 140303256056160
	140303203810608 [label="model.model.encoder.repeat_1.11.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303203810608 -> 140303256056256
	140303256056256 [label=AccumulateGrad]
	140303256055968 -> 140303256056160
	140303203810688 [label="model.model.encoder.repeat_1.11.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303203810688 -> 140303256055968
	140303256055968 [label=AccumulateGrad]
	140303256056400 -> 140303256056592
	140303256056400 [label=ReluBackward0]
	140303256055824 -> 140303256056400
	140303256055824 [label=CudnnBatchNormBackward0]
	140303256057504 -> 140303256055824
	140303256057504 [label=ConvolutionBackward0]
	140303256053952 -> 140303256057504
	140303256053952 [label=ReluBackward0]
	140303256051216 -> 140303256053952
	140303256051216 [label=CudnnBatchNormBackward0]
	140303256053616 -> 140303256051216
	140303256053616 [label=ConvolutionBackward0]
	140303257268192 -> 140303256053616
	140303257268192 [label=ReluBackward0]
	140303257257008 -> 140303257268192
	140303257257008 [label=CudnnBatchNormBackward0]
	140303257264592 -> 140303257257008
	140303257264592 [label=ConvolutionBackward0]
	140303256057744 -> 140303257264592
	140303257258496 -> 140303257264592
	140303203811168 [label="model.model.encoder.repeat_1.11.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303203811168 -> 140303257258496
	140303257258496 [label=AccumulateGrad]
	140303257263728 -> 140303257257008
	140303203811248 [label="model.model.encoder.repeat_1.11.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303203811248 -> 140303257263728
	140303257263728 [label=AccumulateGrad]
	140303257261040 -> 140303257257008
	140303202058304 [label="model.model.encoder.repeat_1.11.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202058304 -> 140303257261040
	140303257261040 [label=AccumulateGrad]
	140303257262048 -> 140303256053616
	140303202058704 [label="model.model.encoder.repeat_1.11.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202058704 -> 140303257262048
	140303257262048 [label=AccumulateGrad]
	140303257258160 -> 140303256051216
	140303202058784 [label="model.model.encoder.repeat_1.11.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202058784 -> 140303257258160
	140303257258160 [label=AccumulateGrad]
	140303257257104 -> 140303256051216
	140303202058864 [label="model.model.encoder.repeat_1.11.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202058864 -> 140303257257104
	140303257257104 [label=AccumulateGrad]
	140303256054768 -> 140303256057504
	140303202059344 [label="model.model.encoder.repeat_1.11.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202059344 -> 140303256054768
	140303256054768 [label=AccumulateGrad]
	140303256055296 -> 140303256055824
	140303202059424 [label="model.model.encoder.repeat_1.11.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202059424 -> 140303256055296
	140303256055296 [label=AccumulateGrad]
	140303256056208 -> 140303256055824
	140303202059504 [label="model.model.encoder.repeat_1.11.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202059504 -> 140303256056208
	140303256056208 [label=AccumulateGrad]
	140303256056832 -> 140303256056976
	140303202059904 [label="model.model.encoder.repeat_1.11.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202059904 -> 140303256056832
	140303256056832 [label=AccumulateGrad]
	140303256057120 -> 140303256056976
	140303202059984 [label="model.model.encoder.repeat_1.11.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202059984 -> 140303256057120
	140303256057120 [label=AccumulateGrad]
	140303256057744 -> 140303256057456
	140303256057600 -> 140303256058128
	140303202060144 [label="model.model.encoder.repeat_1.12.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202060144 -> 140303256057600
	140303256057600 [label=AccumulateGrad]
	140303256058368 -> 140303256058176
	140303202060224 [label="model.model.encoder.repeat_1.12.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202060224 -> 140303256058368
	140303256058368 [label=AccumulateGrad]
	140303256057936 -> 140303256058176
	140303202060304 [label="model.model.encoder.repeat_1.12.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202060304 -> 140303256057936
	140303256057936 [label=AccumulateGrad]
	140303256058512 -> 140303256058656
	140303256058512 [label=ReluBackward0]
	140303256057648 -> 140303256058512
	140303256057648 [label=CudnnBatchNormBackward0]
	140303256057216 -> 140303256057648
	140303256057216 [label=ConvolutionBackward0]
	140303256055920 -> 140303256057216
	140303256055920 [label=ReluBackward0]
	140303256052896 -> 140303256055920
	140303256052896 [label=CudnnBatchNormBackward0]
	140303256055632 -> 140303256052896
	140303256055632 [label=ConvolutionBackward0]
	140303257264688 -> 140303256055632
	140303257264688 [label=ReluBackward0]
	140303257260224 -> 140303257264688
	140303257260224 [label=CudnnBatchNormBackward0]
	140303257263392 -> 140303257260224
	140303257263392 [label=ConvolutionBackward0]
	140303256059712 -> 140303257263392
	140303257265840 -> 140303257263392
	140303202060704 [label="model.model.encoder.repeat_1.12.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202060704 -> 140303257265840
	140303257265840 [label=AccumulateGrad]
	140303257270208 -> 140303257260224
	140303202060784 [label="model.model.encoder.repeat_1.12.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202060784 -> 140303257270208
	140303257270208 [label=AccumulateGrad]
	140303257256096 -> 140303257260224
	140303202060864 [label="model.model.encoder.repeat_1.12.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202060864 -> 140303257256096
	140303257256096 [label=AccumulateGrad]
	140303257256240 -> 140303256055632
	140303202061344 [label="model.model.encoder.repeat_1.12.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202061344 -> 140303257256240
	140303257256240 [label=AccumulateGrad]
	140303257260512 -> 140303256052896
	140303202061424 [label="model.model.encoder.repeat_1.12.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202061424 -> 140303257260512
	140303257260512 [label=AccumulateGrad]
	140303257270352 -> 140303256052896
	140303202061504 [label="model.model.encoder.repeat_1.12.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202061504 -> 140303257270352
	140303257270352 [label=AccumulateGrad]
	140303256056448 -> 140303256057216
	140303202061984 [label="model.model.encoder.repeat_1.12.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202061984 -> 140303256056448
	140303256056448 [label=AccumulateGrad]
	140303256057072 -> 140303256057648
	140303202062064 [label="model.model.encoder.repeat_1.12.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202062064 -> 140303256057072
	140303256057072 [label=AccumulateGrad]
	140303256058272 -> 140303256057648
	140303202062144 [label="model.model.encoder.repeat_1.12.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202062144 -> 140303256058272
	140303256058272 [label=AccumulateGrad]
	140303256058752 -> 140303256058800
	140303202062624 [label="model.model.encoder.repeat_1.12.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202062624 -> 140303256058752
	140303256058752 [label=AccumulateGrad]
	140303256058896 -> 140303256058800
	140303202062704 [label="model.model.encoder.repeat_1.12.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202062704 -> 140303256058896
	140303256058896 [label=AccumulateGrad]
	140303256059712 -> 140303256059280
	140303256059568 -> 140303256059856
	140303202062864 [label="model.model.encoder.repeat_1.13.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202062864 -> 140303256059568
	140303256059568 [label=AccumulateGrad]
	140303256057024 -> 140303256053568
	140303202062944 [label="model.model.encoder.repeat_1.13.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202062944 -> 140303256057024
	140303256057024 [label=AccumulateGrad]
	140303256048960 -> 140303256053568
	140303202063024 [label="model.model.encoder.repeat_1.13.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202063024 -> 140303256048960
	140303256048960 [label=AccumulateGrad]
	140303256054144 -> 140303256054384
	140303256054144 [label=ReluBackward0]
	140303256059616 -> 140303256054144
	140303256059616 [label=CudnnBatchNormBackward0]
	140303256058992 -> 140303256059616
	140303256058992 [label=ConvolutionBackward0]
	140303256057792 -> 140303256058992
	140303256057792 [label=ReluBackward0]
	140303256055008 -> 140303256057792
	140303256055008 [label=CudnnBatchNormBackward0]
	140303256057552 -> 140303256055008
	140303256057552 [label=ConvolutionBackward0]
	140303257271552 -> 140303256057552
	140303257271552 [label=ReluBackward0]
	140303257262960 -> 140303257271552
	140303257262960 [label=CudnnBatchNormBackward0]
	140303257256384 -> 140303257262960
	140303257256384 [label=ConvolutionBackward0]
	140303256096624 -> 140303257256384
	140303257258976 -> 140303257256384
	140303202063504 [label="model.model.encoder.repeat_1.13.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202063504 -> 140303257258976
	140303257258976 [label=AccumulateGrad]
	140303257270304 -> 140303257262960
	140303202063584 [label="model.model.encoder.repeat_1.13.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202063584 -> 140303257270304
	140303257270304 [label=AccumulateGrad]
	140303257270064 -> 140303257262960
	140303202063664 [label="model.model.encoder.repeat_1.13.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202063664 -> 140303257270064
	140303257270064 [label=AccumulateGrad]
	140303257271120 -> 140303256057552
	140303202064144 [label="model.model.encoder.repeat_1.13.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202064144 -> 140303257271120
	140303257271120 [label=AccumulateGrad]
	140303257271744 -> 140303256055008
	140303202064224 [label="model.model.encoder.repeat_1.13.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202064224 -> 140303257271744
	140303257271744 [label=AccumulateGrad]
	140303257266224 -> 140303256055008
	140303202064304 [label="model.model.encoder.repeat_1.13.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202064304 -> 140303257266224
	140303257266224 [label=AccumulateGrad]
	140303256058560 -> 140303256058992
	140303202064704 [label="model.model.encoder.repeat_1.13.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202064704 -> 140303256058560
	140303256058560 [label=AccumulateGrad]
	140303256058848 -> 140303256059616
	140303202064784 [label="model.model.encoder.repeat_1.13.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202064784 -> 140303256058848
	140303256058848 [label=AccumulateGrad]
	140303256050784 -> 140303256059616
	140303202064864 [label="model.model.encoder.repeat_1.13.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202064864 -> 140303256050784
	140303256050784 [label=AccumulateGrad]
	140303256054624 -> 140303256055488
	140303202065344 [label="model.model.encoder.repeat_1.13.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202065344 -> 140303256054624
	140303256054624 [label=AccumulateGrad]
	140303256051264 -> 140303256055488
	140303202065424 [label="model.model.encoder.repeat_1.13.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202065424 -> 140303256051264
	140303256051264 [label=AccumulateGrad]
	140303256096624 -> 140303256094512
	140303256095568 -> 140303256098928
	140303202065584 [label="model.model.encoder.repeat_1.14.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202065584 -> 140303256095568
	140303256095568 [label=AccumulateGrad]
	140303256100608 -> 140303256099552
	140303202065664 [label="model.model.encoder.repeat_1.14.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202065664 -> 140303256100608
	140303256100608 [label=AccumulateGrad]
	140303256097872 -> 140303256099552
	140303202065744 [label="model.model.encoder.repeat_1.14.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202065744 -> 140303256097872
	140303256097872 [label=AccumulateGrad]
	140303256101664 -> 140303256103344
	140303256101664 [label=ReluBackward0]
	140303256096192 -> 140303256101664
	140303256096192 [label=CudnnBatchNormBackward0]
	140303256095136 -> 140303256096192
	140303256095136 [label=ConvolutionBackward0]
	140303256059760 -> 140303256095136
	140303256059760 [label=ReluBackward0]
	140303256056496 -> 140303256059760
	140303256056496 [label=CudnnBatchNormBackward0]
	140303256059472 -> 140303256056496
	140303256059472 [label=ConvolutionBackward0]
	140303257262432 -> 140303256059472
	140303257262432 [label=ReluBackward0]
	140303257259696 -> 140303257262432
	140303257259696 [label=CudnnBatchNormBackward0]
	140303257263488 -> 140303257259696
	140303257263488 [label=ConvolutionBackward0]
	140303256109008 -> 140303257263488
	140303257262096 -> 140303257263488
	140303202066144 [label="model.model.encoder.repeat_1.14.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202066144 -> 140303257262096
	140303257262096 [label=AccumulateGrad]
	140303257261664 -> 140303257259696
	140303202066224 [label="model.model.encoder.repeat_1.14.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202066224 -> 140303257261664
	140303257261664 [label=AccumulateGrad]
	140303257260992 -> 140303257259696
	140303202066304 [label="model.model.encoder.repeat_1.14.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202066304 -> 140303257260992
	140303257260992 [label=AccumulateGrad]
	140303257260128 -> 140303256059472
	140303202066704 [label="model.model.encoder.repeat_1.14.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202066704 -> 140303257260128
	140303257260128 [label=AccumulateGrad]
	140303257270736 -> 140303256056496
	140303202066784 [label="model.model.encoder.repeat_1.14.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202066784 -> 140303257270736
	140303257270736 [label=AccumulateGrad]
	140303257257776 -> 140303256056496
	140303202066864 [label="model.model.encoder.repeat_1.14.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202066864 -> 140303257257776
	140303257257776 [label=AccumulateGrad]
	140303256052704 -> 140303256095136
	140303202067264 [label="model.model.encoder.repeat_1.14.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202067264 -> 140303256052704
	140303256052704 [label=AccumulateGrad]
	140303256092832 -> 140303256096192
	140303202067344 [label="model.model.encoder.repeat_1.14.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202067344 -> 140303256092832
	140303256092832 [label=AccumulateGrad]
	140303256099984 -> 140303256096192
	140303202067424 [label="model.model.encoder.repeat_1.14.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202067424 -> 140303256099984
	140303256099984 [label=AccumulateGrad]
	140303256103968 -> 140303256104592
	140303202067824 [label="model.model.encoder.repeat_1.14.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202067824 -> 140303256103968
	140303256103968 [label=AccumulateGrad]
	140303256105648 -> 140303256104592
	140303202067904 [label="model.model.encoder.repeat_1.14.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202067904 -> 140303256105648
	140303256105648 [label=AccumulateGrad]
	140303256109008 -> 140303256107952
	140303256224384 -> 140303256227120
	140303202068064 [label="model.model.encoder.repeat_1.15.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202068064 -> 140303256224384
	140303256224384 [label=AccumulateGrad]
	140303256228800 -> 140303256227744
	140303202068144 [label="model.model.encoder.repeat_1.15.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202068144 -> 140303256228800
	140303256228800 [label=AccumulateGrad]
	140303256226064 -> 140303256227744
	140303202068224 [label="model.model.encoder.repeat_1.15.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202068224 -> 140303256226064
	140303256226064 [label=AccumulateGrad]
	140303256229856 -> 140303256237104
	140303256229856 [label=ReluBackward0]
	140303256224816 -> 140303256229856
	140303256224816 [label=CudnnBatchNormBackward0]
	140303256228176 -> 140303256224816
	140303256228176 [label=ConvolutionBackward0]
	140303256097248 -> 140303256228176
	140303256097248 [label=ReluBackward0]
	140303256058608 -> 140303256097248
	140303256058608 [label=CudnnBatchNormBackward0]
	140303256056544 -> 140303256058608
	140303256056544 [label=ConvolutionBackward0]
	140303257271600 -> 140303256056544
	140303257271600 [label=ReluBackward0]
	140303257262144 -> 140303257271600
	140303257262144 [label=CudnnBatchNormBackward0]
	140303257258688 -> 140303257262144
	140303257258688 [label=ConvolutionBackward0]
	140303249097488 -> 140303257258688
	140303257271360 -> 140303257258688
	140303202068704 [label="model.model.encoder.repeat_1.15.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202068704 -> 140303257271360
	140303257271360 [label=AccumulateGrad]
	140303257262912 -> 140303257262144
	140303202068784 [label="model.model.encoder.repeat_1.15.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202068784 -> 140303257262912
	140303257262912 [label=AccumulateGrad]
	140303257261376 -> 140303257262144
	140303202068864 [label="model.model.encoder.repeat_1.15.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202068864 -> 140303257261376
	140303257261376 [label=AccumulateGrad]
	140303257263776 -> 140303256056544
	140303202069264 [label="model.model.encoder.repeat_1.15.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202069264 -> 140303257263776
	140303257263776 [label=AccumulateGrad]
	140303257267472 -> 140303256058608
	140303202069344 [label="model.model.encoder.repeat_1.15.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202069344 -> 140303257267472
	140303257267472 [label=AccumulateGrad]
	140303257260176 -> 140303256058608
	140303202069424 [label="model.model.encoder.repeat_1.15.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202069424 -> 140303257260176
	140303257260176 [label=AccumulateGrad]
	140303256102288 -> 140303256228176
	140303202069904 [label="model.model.encoder.repeat_1.15.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202069904 -> 140303256102288
	140303256102288 [label=AccumulateGrad]
	140303256106272 -> 140303256224816
	140303202069984 [label="model.model.encoder.repeat_1.15.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202069984 -> 140303256106272
	140303256106272 [label=AccumulateGrad]
	140303256105024 -> 140303256224816
	140303202070064 [label="model.model.encoder.repeat_1.15.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202070064 -> 140303256105024
	140303256105024 [label=AccumulateGrad]
	140303256236960 -> 140303249100320
	140303202070544 [label="model.model.encoder.repeat_1.15.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202070544 -> 140303256236960
	140303256236960 [label=AccumulateGrad]
	140303256237632 -> 140303249100320
	140303202070624 [label="model.model.encoder.repeat_1.15.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202070624 -> 140303256237632
	140303256237632 [label=AccumulateGrad]
	140303249097488 -> 140303249097632
	140303249096816 -> 140303249097872
	140303202070784 [label="model.model.encoder.repeat_1.16.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202070784 -> 140303249096816
	140303249096816 [label=AccumulateGrad]
	140303249098160 -> 140303249097968
	140303202070864 [label="model.model.encoder.repeat_1.16.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202070864 -> 140303249098160
	140303249098160 [label=AccumulateGrad]
	140303249098016 -> 140303249097968
	140303202070944 [label="model.model.encoder.repeat_1.16.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202070944 -> 140303249098016
	140303249098016 [label=AccumulateGrad]
	140303249098592 -> 140303249098544
	140303249098592 [label=ReluBackward0]
	140303249096912 -> 140303249098592
	140303249096912 [label=CudnnBatchNormBackward0]
	140303249111936 -> 140303249096912
	140303249111936 [label=ConvolutionBackward0]
	140303256225440 -> 140303249111936
	140303256225440 [label=ReluBackward0]
	140303256059184 -> 140303256225440
	140303256059184 [label=CudnnBatchNormBackward0]
	140303256108384 -> 140303256059184
	140303256108384 [label=ConvolutionBackward0]
	140303257263056 -> 140303256108384
	140303257263056 [label=ReluBackward0]
	140303257269488 -> 140303257263056
	140303257269488 [label=CudnnBatchNormBackward0]
	140303257259072 -> 140303257269488
	140303257259072 [label=ConvolutionBackward0]
	140303249099792 -> 140303257259072
	140303257259888 -> 140303257259072
	140303202071424 [label="model.model.encoder.repeat_1.16.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202071424 -> 140303257259888
	140303257259888 [label=AccumulateGrad]
	140303257263632 -> 140303257269488
	140303202071504 [label="model.model.encoder.repeat_1.16.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202071504 -> 140303257263632
	140303257263632 [label=AccumulateGrad]
	140303257256624 -> 140303257269488
	140303202071584 [label="model.model.encoder.repeat_1.16.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202071584 -> 140303257256624
	140303257256624 [label=AccumulateGrad]
	140303257267136 -> 140303256108384
	140303202072064 [label="model.model.encoder.repeat_1.16.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202072064 -> 140303257267136
	140303257267136 [label=AccumulateGrad]
	140303257257632 -> 140303256059184
	140303202072144 [label="model.model.encoder.repeat_1.16.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202072144 -> 140303257257632
	140303257257632 [label=AccumulateGrad]
	140303257261568 -> 140303256059184
	140303202072224 [label="model.model.encoder.repeat_1.16.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202072224 -> 140303257261568
	140303257261568 [label=AccumulateGrad]
	140303256238352 -> 140303249111936
	140303202072704 [label="model.model.encoder.repeat_1.16.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202072704 -> 140303256238352
	140303256238352 [label=AccumulateGrad]
	140303249097344 -> 140303249096912
	140303202072784 [label="model.model.encoder.repeat_1.16.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202072784 -> 140303249097344
	140303249097344 [label=AccumulateGrad]
	140303249097824 -> 140303249096912
	140303202072864 [label="model.model.encoder.repeat_1.16.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202072864 -> 140303249097824
	140303249097824 [label=AccumulateGrad]
	140303249098400 -> 140303249098736
	140303202073264 [label="model.model.encoder.repeat_1.16.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202073264 -> 140303249098400
	140303249098400 [label=AccumulateGrad]
	140303249099168 -> 140303249098736
	140303202073344 [label="model.model.encoder.repeat_1.16.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202073344 -> 140303249099168
	140303249099168 [label=AccumulateGrad]
	140303249099792 -> 140303249098976
	140303249099840 -> 140303249099888
	140303202073504 [label="model.model.encoder.repeat_1.17.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202073504 -> 140303249099840
	140303249099840 [label=AccumulateGrad]
	140303249112800 -> 140303249097776
	140303202073584 [label="model.model.encoder.repeat_1.17.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202073584 -> 140303249112800
	140303249112800 [label=AccumulateGrad]
	140303249099696 -> 140303249097776
	140303202073664 [label="model.model.encoder.repeat_1.17.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202073664 -> 140303249099696
	140303249099696 [label=AccumulateGrad]
	140302949886240 -> 140302949877312
	140302949886240 [label=ReluBackward0]
	140303249099744 -> 140302949886240
	140303249099744 [label=CudnnBatchNormBackward0]
	140303249099216 -> 140303249099744
	140303249099216 [label=ConvolutionBackward0]
	140303249098112 -> 140303249099216
	140303249098112 [label=ReluBackward0]
	140303256102912 -> 140303249098112
	140303256102912 [label=CudnnBatchNormBackward0]
	140303249097248 -> 140303256102912
	140303249097248 [label=ConvolutionBackward0]
	140303257260848 -> 140303249097248
	140303257260848 [label=ReluBackward0]
	140303257271792 -> 140303257260848
	140303257271792 [label=CudnnBatchNormBackward0]
	140303257270976 -> 140303257271792
	140303257270976 [label=ConvolutionBackward0]
	140302949889984 -> 140303257270976
	140303257257920 -> 140303257270976
	140303202074064 [label="model.model.encoder.repeat_1.17.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202074064 -> 140303257257920
	140303257257920 [label=AccumulateGrad]
	140303257264832 -> 140303257271792
	140303202074144 [label="model.model.encoder.repeat_1.17.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202074144 -> 140303257264832
	140303257264832 [label=AccumulateGrad]
	140303257264256 -> 140303257271792
	140303202074224 [label="model.model.encoder.repeat_1.17.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202074224 -> 140303257264256
	140303257264256 [label=AccumulateGrad]
	140303257266608 -> 140303249097248
	140303202369680 [label="model.model.encoder.repeat_1.17.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202369680 -> 140303257266608
	140303257266608 [label=AccumulateGrad]
	140303257268864 -> 140303256102912
	140303202369760 [label="model.model.encoder.repeat_1.17.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202369760 -> 140303257268864
	140303257268864 [label=AccumulateGrad]
	140303257258784 -> 140303256102912
	140303202369840 [label="model.model.encoder.repeat_1.17.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202369840 -> 140303257258784
	140303257258784 [label=AccumulateGrad]
	140303249098640 -> 140303249099216
	140303202370320 [label="model.model.encoder.repeat_1.17.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202370320 -> 140303249098640
	140303249098640 [label=AccumulateGrad]
	140303249099264 -> 140303249099744
	140303202370400 [label="model.model.encoder.repeat_1.17.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202370400 -> 140303249099264
	140303249099264 [label=AccumulateGrad]
	140303249097296 -> 140303249099744
	140303202370480 [label="model.model.encoder.repeat_1.17.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202370480 -> 140303249097296
	140303249097296 [label=AccumulateGrad]
	140302949878848 -> 140302949891472
	140303202370960 [label="model.model.encoder.repeat_1.17.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202370960 -> 140302949878848
	140302949878848 [label=AccumulateGrad]
	140302949882976 -> 140302949891472
	140303202371040 [label="model.model.encoder.repeat_1.17.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202371040 -> 140302949882976
	140302949882976 [label=AccumulateGrad]
	140302949889984 -> 140302949891328
	140302949886048 -> 140302949888640
	140303202371200 [label="model.model.encoder.repeat_1.18.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202371200 -> 140302949886048
	140302949886048 [label=AccumulateGrad]
	140302949885280 -> 140302949876976
	140303202371280 [label="model.model.encoder.repeat_1.18.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202371280 -> 140302949885280
	140302949885280 [label=AccumulateGrad]
	140302949890320 -> 140302949876976
	140303202371360 [label="model.model.encoder.repeat_1.18.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202371360 -> 140302949890320
	140302949890320 [label=AccumulateGrad]
	140302949882064 -> 140302949878368
	140302949882064 [label=ReluBackward0]
	140302949883600 -> 140302949882064
	140302949883600 [label=CudnnBatchNormBackward0]
	140302949887632 -> 140302949883600
	140302949887632 [label=ConvolutionBackward0]
	140302949881824 -> 140302949887632
	140302949881824 [label=ReluBackward0]
	140303256227216 -> 140302949881824
	140303256227216 [label=CudnnBatchNormBackward0]
	140303249099312 -> 140303256227216
	140303249099312 [label=ConvolutionBackward0]
	140303257270448 -> 140303249099312
	140303257270448 [label=ReluBackward0]
	140303257261856 -> 140303257270448
	140303257261856 [label=CudnnBatchNormBackward0]
	140303257265072 -> 140303257261856
	140303257265072 [label=ConvolutionBackward0]
	140302949882544 -> 140303257265072
	140303257267904 -> 140303257265072
	140303202371840 [label="model.model.encoder.repeat_1.18.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202371840 -> 140303257267904
	140303257267904 [label=AccumulateGrad]
	140303257262528 -> 140303257261856
	140303202371920 [label="model.model.encoder.repeat_1.18.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202371920 -> 140303257262528
	140303257262528 [label=AccumulateGrad]
	140303257265936 -> 140303257261856
	140303202372000 [label="model.model.encoder.repeat_1.18.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202372000 -> 140303257265936
	140303257265936 [label=AccumulateGrad]
	140303257266080 -> 140303249099312
	140303202372480 [label="model.model.encoder.repeat_1.18.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202372480 -> 140303257266080
	140303257266080 [label=AccumulateGrad]
	140303257261136 -> 140303256227216
	140303202372560 [label="model.model.encoder.repeat_1.18.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202372560 -> 140303257261136
	140303257261136 [label=AccumulateGrad]
	140303257259840 -> 140303256227216
	140303202372640 [label="model.model.encoder.repeat_1.18.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202372640 -> 140303257259840
	140303257259840 [label=AccumulateGrad]
	140302949891664 -> 140302949887632
	140303202373120 [label="model.model.encoder.repeat_1.18.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202373120 -> 140302949891664
	140302949891664 [label=AccumulateGrad]
	140302949880864 -> 140302949883600
	140303202373200 [label="model.model.encoder.repeat_1.18.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202373200 -> 140302949880864
	140302949880864 [label=AccumulateGrad]
	140302949880336 -> 140302949883600
	140303202373280 [label="model.model.encoder.repeat_1.18.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202373280 -> 140302949880336
	140302949880336 [label=AccumulateGrad]
	140302949883888 -> 140302949879568
	140303202373760 [label="model.model.encoder.repeat_1.18.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202373760 -> 140302949883888
	140302949883888 [label=AccumulateGrad]
	140302949882352 -> 140302949879568
	140303202373840 [label="model.model.encoder.repeat_1.18.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202373840 -> 140302949882352
	140302949882352 [label=AccumulateGrad]
	140302949882544 -> 140302949886528
	140302949879520 -> 140302949886864
	140303202374000 [label="model.model.encoder.repeat_1.19.branch0.conv.weight
 (192, 1088, 1, 1)" fillcolor=lightblue]
	140303202374000 -> 140302949879520
	140302949879520 [label=AccumulateGrad]
	140302949891232 -> 140302949888976
	140303202374080 [label="model.model.encoder.repeat_1.19.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202374080 -> 140302949891232
	140302949891232 [label=AccumulateGrad]
	140302949880384 -> 140302949888976
	140303202374160 [label="model.model.encoder.repeat_1.19.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202374160 -> 140302949880384
	140302949880384 [label=AccumulateGrad]
	140302949884800 -> 140302949891712
	140302949884800 [label=ReluBackward0]
	140302949880816 -> 140302949884800
	140302949880816 [label=CudnnBatchNormBackward0]
	140302949876832 -> 140302949880816
	140302949876832 [label=ConvolutionBackward0]
	140302949876928 -> 140302949876832
	140302949876928 [label=ReluBackward0]
	140303249098448 -> 140302949876928
	140303249098448 [label=CudnnBatchNormBackward0]
	140302949878800 -> 140303249098448
	140302949878800 [label=ConvolutionBackward0]
	140303257256192 -> 140302949878800
	140303257256192 [label=ReluBackward0]
	140303257263824 -> 140303257256192
	140303257263824 [label=CudnnBatchNormBackward0]
	140303257262816 -> 140303257263824
	140303257262816 [label=ConvolutionBackward0]
	140302006123440 -> 140303257262816
	140303257268816 -> 140303257262816
	140303202374560 [label="model.model.encoder.repeat_1.19.branch1.0.conv.weight
 (128, 1088, 1, 1)" fillcolor=lightblue]
	140303202374560 -> 140303257268816
	140303257268816 [label=AccumulateGrad]
	140303257265312 -> 140303257263824
	140303202374640 [label="model.model.encoder.repeat_1.19.branch1.0.bn.weight
 (128)" fillcolor=lightblue]
	140303202374640 -> 140303257265312
	140303257265312 [label=AccumulateGrad]
	140303257258064 -> 140303257263824
	140303202374720 [label="model.model.encoder.repeat_1.19.branch1.0.bn.bias
 (128)" fillcolor=lightblue]
	140303202374720 -> 140303257258064
	140303257258064 [label=AccumulateGrad]
	140303257265504 -> 140302949878800
	140303202375120 [label="model.model.encoder.repeat_1.19.branch1.1.conv.weight
 (160, 128, 1, 7)" fillcolor=lightblue]
	140303202375120 -> 140303257265504
	140303257265504 [label=AccumulateGrad]
	140303257259312 -> 140303249098448
	140303202375200 [label="model.model.encoder.repeat_1.19.branch1.1.bn.weight
 (160)" fillcolor=lightblue]
	140303202375200 -> 140303257259312
	140303257259312 [label=AccumulateGrad]
	140303257257296 -> 140303249098448
	140303202375280 [label="model.model.encoder.repeat_1.19.branch1.1.bn.bias
 (160)" fillcolor=lightblue]
	140303202375280 -> 140303257257296
	140303257257296 [label=AccumulateGrad]
	140302949886144 -> 140302949876832
	140303202375760 [label="model.model.encoder.repeat_1.19.branch1.2.conv.weight
 (192, 160, 7, 1)" fillcolor=lightblue]
	140303202375760 -> 140302949886144
	140302949886144 [label=AccumulateGrad]
	140302949891568 -> 140302949880816
	140303202375840 [label="model.model.encoder.repeat_1.19.branch1.2.bn.weight
 (192)" fillcolor=lightblue]
	140303202375840 -> 140302949891568
	140302949891568 [label=AccumulateGrad]
	140302949888496 -> 140302949880816
	140303202375920 [label="model.model.encoder.repeat_1.19.branch1.2.bn.bias
 (192)" fillcolor=lightblue]
	140303202375920 -> 140302949888496
	140302949888496 [label=AccumulateGrad]
	140302949890944 -> 140302949884320
	140303202376400 [label="model.model.encoder.repeat_1.19.conv2d.weight
 (1088, 384, 1, 1)" fillcolor=lightblue]
	140303202376400 -> 140302949890944
	140302949890944 [label=AccumulateGrad]
	140302949887104 -> 140302949884320
	140303202376480 [label="model.model.encoder.repeat_1.19.conv2d.bias
 (1088)" fillcolor=lightblue]
	140303202376480 -> 140302949887104
	140302949887104 [label=AccumulateGrad]
	140302006123440 -> 140302006123680
	140302062695568 -> 140302954554576
	140303202376560 [label="model.model.encoder.mixed_7a.branch0.0.conv.weight
 (256, 1088, 1, 1)" fillcolor=lightblue]
	140303202376560 -> 140302062695568
	140302062695568 [label=AccumulateGrad]
	140302100150832 -> 140302954560048
	140303202376640 [label="model.model.encoder.mixed_7a.branch0.0.bn.weight
 (256)" fillcolor=lightblue]
	140303202376640 -> 140302100150832
	140302100150832 [label=AccumulateGrad]
	140302100151072 -> 140302954560048
	140303202376720 [label="model.model.encoder.mixed_7a.branch0.0.bn.bias
 (256)" fillcolor=lightblue]
	140303202376720 -> 140302100151072
	140302100151072 [label=AccumulateGrad]
	140303252589296 -> 140303252589680
	140303202377200 [label="model.model.encoder.mixed_7a.branch0.1.conv.weight
 (384, 256, 3, 3)" fillcolor=lightblue]
	140303202377200 -> 140303252589296
	140303252589296 [label=AccumulateGrad]
	140303252589776 -> 140303252589632
	140303202377280 [label="model.model.encoder.mixed_7a.branch0.1.bn.weight
 (384)" fillcolor=lightblue]
	140303202377280 -> 140303252589776
	140303252589776 [label=AccumulateGrad]
	140303252590064 -> 140303252589632
	140303202377360 [label="model.model.encoder.mixed_7a.branch0.1.bn.bias
 (384)" fillcolor=lightblue]
	140303202377360 -> 140303252590064
	140303252590064 [label=AccumulateGrad]
	140303252589872 -> 140303207186976
	140303252589872 [label=ReluBackward0]
	140302062685392 -> 140303252589872
	140302062685392 [label=CudnnBatchNormBackward0]
	140302460353696 -> 140302062685392
	140302460353696 [label=ConvolutionBackward0]
	140302006123536 -> 140302460353696
	140302006123536 [label=ReluBackward0]
	140302949885328 -> 140302006123536
	140302949885328 [label=CudnnBatchNormBackward0]
	140302949877888 -> 140302949885328
	140302949877888 [label=ConvolutionBackward0]
	140303257686784 -> 140302949877888
	140303257260608 -> 140302949877888
	140303202377760 [label="model.model.encoder.mixed_7a.branch1.0.conv.weight
 (256, 1088, 1, 1)" fillcolor=lightblue]
	140303202377760 -> 140303257260608
	140303257260608 [label=AccumulateGrad]
	140302949888688 -> 140302949885328
	140303202377840 [label="model.model.encoder.mixed_7a.branch1.0.bn.weight
 (256)" fillcolor=lightblue]
	140303202377840 -> 140302949888688
	140302949888688 [label=AccumulateGrad]
	140302949887872 -> 140302949885328
	140303202377920 [label="model.model.encoder.mixed_7a.branch1.0.bn.bias
 (256)" fillcolor=lightblue]
	140303202377920 -> 140302949887872
	140302949887872 [label=AccumulateGrad]
	140302949885136 -> 140302460353696
	140303202378400 [label="model.model.encoder.mixed_7a.branch1.1.conv.weight
 (288, 256, 3, 3)" fillcolor=lightblue]
	140303202378400 -> 140302949885136
	140302949885136 [label=AccumulateGrad]
	140303252590016 -> 140302062685392
	140303202378480 [label="model.model.encoder.mixed_7a.branch1.1.bn.weight
 (288)" fillcolor=lightblue]
	140303202378480 -> 140303252590016
	140303252590016 [label=AccumulateGrad]
	140302954559808 -> 140302062685392
	140303202378560 [label="model.model.encoder.mixed_7a.branch1.1.bn.bias
 (288)" fillcolor=lightblue]
	140303202378560 -> 140302954559808
	140302954559808 [label=AccumulateGrad]
	140303252590352 -> 140303207186976
	140303252590352 [label=ReluBackward0]
	140303249099600 -> 140303252590352
	140303249099600 [label=CudnnBatchNormBackward0]
	140302949883072 -> 140303249099600
	140302949883072 [label=ConvolutionBackward0]
	140303257262720 -> 140302949883072
	140303257262720 [label=ReluBackward0]
	140303257269824 -> 140303257262720
	140303257269824 [label=CudnnBatchNormBackward0]
	140303257262336 -> 140303257269824
	140303257262336 [label=ConvolutionBackward0]
	140303257266464 -> 140303257262336
	140303257266464 [label=ReluBackward0]
	140303257272032 -> 140303257266464
	140303257272032 [label=CudnnBatchNormBackward0]
	140303257264928 -> 140303257272032
	140303257264928 [label=ConvolutionBackward0]
	140303257686784 -> 140303257264928
	140303257257056 -> 140303257264928
	140303202378960 [label="model.model.encoder.mixed_7a.branch2.0.conv.weight
 (256, 1088, 1, 1)" fillcolor=lightblue]
	140303202378960 -> 140303257257056
	140303257257056 [label=AccumulateGrad]
	140303257260416 -> 140303257272032
	140303202379040 [label="model.model.encoder.mixed_7a.branch2.0.bn.weight
 (256)" fillcolor=lightblue]
	140303202379040 -> 140303257260416
	140303257260416 [label=AccumulateGrad]
	140303257265696 -> 140303257272032
	140303202379120 [label="model.model.encoder.mixed_7a.branch2.0.bn.bias
 (256)" fillcolor=lightblue]
	140303202379120 -> 140303257265696
	140303257265696 [label=AccumulateGrad]
	140303257268432 -> 140303257262336
	140303202379600 [label="model.model.encoder.mixed_7a.branch2.1.conv.weight
 (288, 256, 3, 3)" fillcolor=lightblue]
	140303202379600 -> 140303257268432
	140303257268432 [label=AccumulateGrad]
	140303257256528 -> 140303257269824
	140303202379680 [label="model.model.encoder.mixed_7a.branch2.1.bn.weight
 (288)" fillcolor=lightblue]
	140303202379680 -> 140303257256528
	140303257256528 [label=AccumulateGrad]
	140303257265552 -> 140303257269824
	140303202379760 [label="model.model.encoder.mixed_7a.branch2.1.bn.bias
 (288)" fillcolor=lightblue]
	140303202379760 -> 140303257265552
	140303257265552 [label=AccumulateGrad]
	140303257268768 -> 140302949883072
	140303202380240 [label="model.model.encoder.mixed_7a.branch2.2.conv.weight
 (320, 288, 3, 3)" fillcolor=lightblue]
	140303202380240 -> 140303257268768
	140303257268768 [label=AccumulateGrad]
	140302949883648 -> 140303249099600
	140303202380320 [label="model.model.encoder.mixed_7a.branch2.2.bn.weight
 (320)" fillcolor=lightblue]
	140303202380320 -> 140302949883648
	140302949883648 [label=AccumulateGrad]
	140303252590208 -> 140303249099600
	140303202380400 [label="model.model.encoder.mixed_7a.branch2.2.bn.bias
 (320)" fillcolor=lightblue]
	140303202380400 -> 140303252590208
	140303252590208 [label=AccumulateGrad]
	140303252589536 -> 140303207186976
	140303252589536 [label=MaxPool2DWithIndicesBackward0]
	140303257686784 -> 140303252589536
	140303252590256 -> 140303252375344
	140303202373440 [label="model.model.encoder.repeat_2.0.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202373440 -> 140303252590256
	140303252590256 [label=AccumulateGrad]
	140303252375200 -> 140303252375296
	140303202380640 [label="model.model.encoder.repeat_2.0.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202380640 -> 140303252375200
	140303252375200 [label=AccumulateGrad]
	140303252375440 -> 140303252375296
	140303202380720 [label="model.model.encoder.repeat_2.0.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202380720 -> 140303252375440
	140303252375440 [label=AccumulateGrad]
	140303252375104 -> 140303252374960
	140303252375104 [label=ReluBackward0]
	140302954550688 -> 140303252375104
	140302954550688 [label=CudnnBatchNormBackward0]
	140303252589728 -> 140302954550688
	140303252589728 [label=ConvolutionBackward0]
	140303257269872 -> 140303252589728
	140303257269872 [label=ReluBackward0]
	140303257266320 -> 140303257269872
	140303257266320 [label=CudnnBatchNormBackward0]
	140303257259600 -> 140303257266320
	140303257259600 [label=ConvolutionBackward0]
	140303257263872 -> 140303257259600
	140303257263872 [label=ReluBackward0]
	140303257258304 -> 140303257263872
	140303257258304 [label=CudnnBatchNormBackward0]
	140303257261904 -> 140303257258304
	140303257261904 [label=ConvolutionBackward0]
	140303207186976 -> 140303257261904
	140303257269680 -> 140303257261904
	140303202381120 [label="model.model.encoder.repeat_2.0.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202381120 -> 140303257269680
	140303257269680 [label=AccumulateGrad]
	140303257260272 -> 140303257258304
	140303202381200 [label="model.model.encoder.repeat_2.0.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202381200 -> 140303257260272
	140303257260272 [label=AccumulateGrad]
	140303257259552 -> 140303257258304
	140303202381280 [label="model.model.encoder.repeat_2.0.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202381280 -> 140303257259552
	140303257259552 [label=AccumulateGrad]
	140303257259408 -> 140303257259600
	140303202381760 [label="model.model.encoder.repeat_2.0.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202381760 -> 140303257259408
	140303257259408 [label=AccumulateGrad]
	140303257264544 -> 140303257266320
	140303202381840 [label="model.model.encoder.repeat_2.0.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202381840 -> 140303257264544
	140303257264544 [label=AccumulateGrad]
	140303257258544 -> 140303257266320
	140303202381920 [label="model.model.encoder.repeat_2.0.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202381920 -> 140303257258544
	140303257258544 [label=AccumulateGrad]
	140303257258928 -> 140303252589728
	140303202382320 [label="model.model.encoder.repeat_2.0.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202382320 -> 140303257258928
	140303257258928 [label=AccumulateGrad]
	140303252589968 -> 140302954550688
	140303202382400 [label="model.model.encoder.repeat_2.0.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202382400 -> 140303252589968
	140303252589968 [label=AccumulateGrad]
	140303252375248 -> 140302954550688
	140303202382480 [label="model.model.encoder.repeat_2.0.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202382480 -> 140303252375248
	140303252375248 [label=AccumulateGrad]
	140303252374912 -> 140303207202528
	140303202382960 [label="model.model.encoder.repeat_2.0.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202382960 -> 140303252374912
	140303252374912 [label=AccumulateGrad]
	140303252374816 -> 140303207202528
	140303202383040 [label="model.model.encoder.repeat_2.0.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202383040 -> 140303252374816
	140303252374816 [label=AccumulateGrad]
	140303207186976 -> 140303207186592
	140303207186784 -> 140303207187648
	140303202383200 [label="model.model.encoder.repeat_2.1.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202383200 -> 140303207186784
	140303207186784 [label=AccumulateGrad]
	140303207187984 -> 140303207187792
	140303202383280 [label="model.model.encoder.repeat_2.1.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202383280 -> 140303207187984
	140303207187984 [label=AccumulateGrad]
	140303207187360 -> 140303207187792
	140303202383360 [label="model.model.encoder.repeat_2.1.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202383360 -> 140303207187360
	140303207187360 [label=AccumulateGrad]
	140303207188176 -> 140303207188608
	140303207188176 [label=ReluBackward0]
	140303207186928 -> 140303207188176
	140303207186928 [label=CudnnBatchNormBackward0]
	140303207186736 -> 140303207186928
	140303207186736 [label=ConvolutionBackward0]
	140303252375488 -> 140303207186736
	140303252375488 [label=ReluBackward0]
	140303257264640 -> 140303252375488
	140303257264640 [label=CudnnBatchNormBackward0]
	140303257265648 -> 140303257264640
	140303257265648 [label=ConvolutionBackward0]
	140303257263584 -> 140303257265648
	140303257263584 [label=ReluBackward0]
	140303257266848 -> 140303257263584
	140303257266848 [label=CudnnBatchNormBackward0]
	140303257260896 -> 140303257266848
	140303257260896 [label=ConvolutionBackward0]
	140303207189952 -> 140303257260896
	140303257269968 -> 140303257260896
	140303202383760 [label="model.model.encoder.repeat_2.1.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202383760 -> 140303257269968
	140303257269968 [label=AccumulateGrad]
	140303257267184 -> 140303257266848
	140303202383840 [label="model.model.encoder.repeat_2.1.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202383840 -> 140303257267184
	140303257267184 [label=AccumulateGrad]
	140303257257536 -> 140303257266848
	140303202383920 [label="model.model.encoder.repeat_2.1.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202383920 -> 140303257257536
	140303257257536 [label=AccumulateGrad]
	140303257259168 -> 140303257265648
	140303202384320 [label="model.model.encoder.repeat_2.1.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202384320 -> 140303257259168
	140303257259168 [label=AccumulateGrad]
	140303257271408 -> 140303257264640
	140303202384400 [label="model.model.encoder.repeat_2.1.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202384400 -> 140303257271408
	140303257271408 [label=AccumulateGrad]
	140303257266512 -> 140303257264640
	140303202384480 [label="model.model.encoder.repeat_2.1.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202384480 -> 140303257266512
	140303257266512 [label=AccumulateGrad]
	140303252375056 -> 140303207186736
	140303202384880 [label="model.model.encoder.repeat_2.1.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202384880 -> 140303252375056
	140303252375056 [label=AccumulateGrad]
	140303207202096 -> 140303207186928
	140303202384960 [label="model.model.encoder.repeat_2.1.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202384960 -> 140303207202096
	140303207202096 [label=AccumulateGrad]
	140303207187840 -> 140303207186928
	140303202385040 [label="model.model.encoder.repeat_2.1.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202385040 -> 140303207187840
	140303207187840 [label=AccumulateGrad]
	140303207188752 -> 140303207188800
	140303202385520 [label="model.model.encoder.repeat_2.1.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202385520 -> 140303207188752
	140303207188752 [label=AccumulateGrad]
	140303207188992 -> 140303207188800
	140303202385600 [label="model.model.encoder.repeat_2.1.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202385600 -> 140303207188992
	140303207188992 [label=AccumulateGrad]
	140303207189952 -> 140303207189568
	140303207189760 -> 140303207190528
	140303202385440 [label="model.model.encoder.repeat_2.2.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202385440 -> 140303207189760
	140303207189760 [label=AccumulateGrad]
	140303207190864 -> 140303207190672
	140303202385680 [label="model.model.encoder.repeat_2.2.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202385680 -> 140303207190864
	140303207190864 [label=AccumulateGrad]
	140303207190144 -> 140303207190672
	140303202385760 [label="model.model.encoder.repeat_2.2.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202385760 -> 140303207190144
	140303207190144 [label=AccumulateGrad]
	140303207191056 -> 140303207191488
	140303207191056 [label=ReluBackward0]
	140303207189904 -> 140303207191056
	140303207189904 [label=CudnnBatchNormBackward0]
	140303207189136 -> 140303207189904
	140303207189136 [label=ConvolutionBackward0]
	140303207187312 -> 140303207189136
	140303207187312 [label=ReluBackward0]
	140303252375008 -> 140303207187312
	140303252375008 [label=CudnnBatchNormBackward0]
	140303257260752 -> 140303252375008
	140303257260752 [label=ConvolutionBackward0]
	140303257263248 -> 140303257260752
	140303257263248 [label=ReluBackward0]
	140303257258016 -> 140303257263248
	140303257258016 [label=CudnnBatchNormBackward0]
	140303257260032 -> 140303257258016
	140303257260032 [label=ConvolutionBackward0]
	140303207192928 -> 140303257260032
	140303257270880 -> 140303257260032
	140303202713984 [label="model.model.encoder.repeat_2.2.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202713984 -> 140303257270880
	140303257270880 [label=AccumulateGrad]
	140303257267520 -> 140303257258016
	140303202714064 [label="model.model.encoder.repeat_2.2.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202714064 -> 140303257267520
	140303257267520 [label=AccumulateGrad]
	140303257267328 -> 140303257258016
	140303202714144 [label="model.model.encoder.repeat_2.2.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202714144 -> 140303257267328
	140303257267328 [label=AccumulateGrad]
	140303257263104 -> 140303257260752
	140303202714624 [label="model.model.encoder.repeat_2.2.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202714624 -> 140303257263104
	140303257263104 [label=AccumulateGrad]
	140303257265264 -> 140303252375008
	140303202714704 [label="model.model.encoder.repeat_2.2.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202714704 -> 140303257265264
	140303257265264 [label=AccumulateGrad]
	140303257271024 -> 140303252375008
	140303202714784 [label="model.model.encoder.repeat_2.2.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202714784 -> 140303257271024
	140303257271024 [label=AccumulateGrad]
	140303207188224 -> 140303207189136
	140303202715264 [label="model.model.encoder.repeat_2.2.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202715264 -> 140303207188224
	140303207188224 [label=AccumulateGrad]
	140303207188944 -> 140303207189904
	140303202715344 [label="model.model.encoder.repeat_2.2.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202715344 -> 140303207188944
	140303207188944 [label=AccumulateGrad]
	140303207190720 -> 140303207189904
	140303202715424 [label="model.model.encoder.repeat_2.2.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202715424 -> 140303207190720
	140303207190720 [label=AccumulateGrad]
	140303207191728 -> 140303207191776
	140303202715904 [label="model.model.encoder.repeat_2.2.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202715904 -> 140303207191728
	140303207191728 [label=AccumulateGrad]
	140303207191968 -> 140303207191776
	140303202715984 [label="model.model.encoder.repeat_2.2.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202715984 -> 140303207191968
	140303207191968 [label=AccumulateGrad]
	140303207192928 -> 140303207192352
	140303207192736 -> 140303207193312
	140303202716144 [label="model.model.encoder.repeat_2.3.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202716144 -> 140303207192736
	140303207192736 [label=AccumulateGrad]
	140303207193840 -> 140303207193648
	140303202716224 [label="model.model.encoder.repeat_2.3.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202716224 -> 140303207193840
	140303207193840 [label=AccumulateGrad]
	140303207193120 -> 140303207193648
	140303202716304 [label="model.model.encoder.repeat_2.3.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202716304 -> 140303207193120
	140303207193120 [label=AccumulateGrad]
	140303207194032 -> 140303207194272
	140303207194032 [label=ReluBackward0]
	140303207192880 -> 140303207194032
	140303207192880 [label=CudnnBatchNormBackward0]
	140303207192112 -> 140303207192880
	140303207192112 [label=ConvolutionBackward0]
	140303207190096 -> 140303207192112
	140303207190096 [label=ReluBackward0]
	140303252374864 -> 140303207190096
	140303252374864 [label=CudnnBatchNormBackward0]
	140303207189712 -> 140303252374864
	140303207189712 [label=ConvolutionBackward0]
	140303257256048 -> 140303207189712
	140303257256048 [label=ReluBackward0]
	140303257269920 -> 140303257256048
	140303257269920 [label=CudnnBatchNormBackward0]
	140303257262672 -> 140303257269920
	140303257262672 [label=ConvolutionBackward0]
	140303207195040 -> 140303257262672
	140303257271216 -> 140303257262672
	140303202716704 [label="model.model.encoder.repeat_2.3.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202716704 -> 140303257271216
	140303257271216 [label=AccumulateGrad]
	140303257269200 -> 140303257269920
	140303202716784 [label="model.model.encoder.repeat_2.3.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202716784 -> 140303257269200
	140303257269200 [label=AccumulateGrad]
	140303257266944 -> 140303257269920
	140303202716864 [label="model.model.encoder.repeat_2.3.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202716864 -> 140303257266944
	140303257266944 [label=AccumulateGrad]
	140303257260464 -> 140303207189712
	140303202717264 [label="model.model.encoder.repeat_2.3.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202717264 -> 140303257260464
	140303257260464 [label=AccumulateGrad]
	140303257266896 -> 140303252374864
	140303202717344 [label="model.model.encoder.repeat_2.3.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202717344 -> 140303257266896
	140303257266896 [label=AccumulateGrad]
	140303257270688 -> 140303252374864
	140303202717424 [label="model.model.encoder.repeat_2.3.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202717424 -> 140303257270688
	140303257270688 [label=AccumulateGrad]
	140303207191104 -> 140303207192112
	140303202717904 [label="model.model.encoder.repeat_2.3.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202717904 -> 140303207191104
	140303207191104 [label=AccumulateGrad]
	140303207191920 -> 140303207192880
	140303202717984 [label="model.model.encoder.repeat_2.3.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202717984 -> 140303207191920
	140303207191920 [label=AccumulateGrad]
	140303207193696 -> 140303207192880
	140303202718064 [label="model.model.encoder.repeat_2.3.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202718064 -> 140303207193696
	140303207193696 [label=AccumulateGrad]
	140303207194608 -> 140303207194656
	140303202718544 [label="model.model.encoder.repeat_2.3.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202718544 -> 140303207194608
	140303207194608 [label=AccumulateGrad]
	140303207194848 -> 140303207194656
	140303202718624 [label="model.model.encoder.repeat_2.3.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202718624 -> 140303207194848
	140303207194848 [label=AccumulateGrad]
	140303207195040 -> 140303207195184
	140303207195568 -> 140303207196048
	140303202718784 [label="model.model.encoder.repeat_2.4.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202718784 -> 140303207195568
	140303207195568 [label=AccumulateGrad]
	140303207196096 -> 140303207196240
	140303202718864 [label="model.model.encoder.repeat_2.4.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202718864 -> 140303207196096
	140303207196096 [label=AccumulateGrad]
	140303207196432 -> 140303207196240
	140303202718944 [label="model.model.encoder.repeat_2.4.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202718944 -> 140303207196432
	140303207196432 [label=AccumulateGrad]
	140303207196816 -> 140303207197056
	140303207196816 [label=ReluBackward0]
	140303207195616 -> 140303207196816
	140303207195616 [label=CudnnBatchNormBackward0]
	140303207195856 -> 140303207195616
	140303207195856 [label=ConvolutionBackward0]
	140303207193072 -> 140303207195856
	140303207193072 [label=ReluBackward0]
	140303207188560 -> 140303207193072
	140303207188560 [label=CudnnBatchNormBackward0]
	140303207192688 -> 140303207188560
	140303207192688 [label=ConvolutionBackward0]
	140303257271840 -> 140303207192688
	140303257271840 [label=ReluBackward0]
	140303257262624 -> 140303257271840
	140303257262624 [label=CudnnBatchNormBackward0]
	140303257264208 -> 140303257262624
	140303257264208 [label=ConvolutionBackward0]
	140303207197824 -> 140303257264208
	140303257268576 -> 140303257264208
	140303202719424 [label="model.model.encoder.repeat_2.4.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202719424 -> 140303257268576
	140303257268576 [label=AccumulateGrad]
	140303257257584 -> 140303257262624
	140303202719504 [label="model.model.encoder.repeat_2.4.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202719504 -> 140303257257584
	140303257257584 [label=AccumulateGrad]
	140303257257488 -> 140303257262624
	140303202719584 [label="model.model.encoder.repeat_2.4.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202719584 -> 140303257257488
	140303257257488 [label=AccumulateGrad]
	140303257258736 -> 140303207192688
	140303202720064 [label="model.model.encoder.repeat_2.4.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202720064 -> 140303257258736
	140303257258736 [label=AccumulateGrad]
	140303257272080 -> 140303207188560
	140303202720144 [label="model.model.encoder.repeat_2.4.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202720144 -> 140303257272080
	140303257272080 [label=AccumulateGrad]
	140303257259216 -> 140303207188560
	140303202720224 [label="model.model.encoder.repeat_2.4.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202720224 -> 140303257259216
	140303257259216 [label=AccumulateGrad]
	140303207194080 -> 140303207195856
	140303202720624 [label="model.model.encoder.repeat_2.4.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202720624 -> 140303207194080
	140303207194080 [label=AccumulateGrad]
	140303207194800 -> 140303207195616
	140303202720704 [label="model.model.encoder.repeat_2.4.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202720704 -> 140303207194800
	140303207194800 [label=AccumulateGrad]
	140303207196288 -> 140303207195616
	140303202720784 [label="model.model.encoder.repeat_2.4.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202720784 -> 140303207196288
	140303207196288 [label=AccumulateGrad]
	140303207197200 -> 140303207197248
	140303202721264 [label="model.model.encoder.repeat_2.4.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202721264 -> 140303207197200
	140303207197200 [label=AccumulateGrad]
	140303207197440 -> 140303207197248
	140303202721344 [label="model.model.encoder.repeat_2.4.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202721344 -> 140303207197440
	140303207197440 [label=AccumulateGrad]
	140303207197824 -> 140303207197968
	140303207198160 -> 140303207198736
	140303202721504 [label="model.model.encoder.repeat_2.5.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202721504 -> 140303207198160
	140303207198160 [label=AccumulateGrad]
	140303207198784 -> 140303207198928
	140303202721584 [label="model.model.encoder.repeat_2.5.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202721584 -> 140303207198784
	140303207198784 [label=AccumulateGrad]
	140303207199120 -> 140303207198928
	140303202721664 [label="model.model.encoder.repeat_2.5.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202721664 -> 140303207199120
	140303207199120 [label=AccumulateGrad]
	140303207199312 -> 140303207199744
	140303207199312 [label=ReluBackward0]
	140303207198208 -> 140303207199312
	140303207198208 [label=CudnnBatchNormBackward0]
	140303207198352 -> 140303207198208
	140303207198352 [label=ConvolutionBackward0]
	140303207195904 -> 140303207198352
	140303207195904 [label=ReluBackward0]
	140303207191440 -> 140303207195904
	140303207191440 [label=CudnnBatchNormBackward0]
	140303207195232 -> 140303207191440
	140303207195232 [label=ConvolutionBackward0]
	140303257272128 -> 140303207195232
	140303257272128 [label=ReluBackward0]
	140303257271696 -> 140303257272128
	140303257271696 [label=CudnnBatchNormBackward0]
	140303257270640 -> 140303257271696
	140303257270640 [label=ConvolutionBackward0]
	140303207200320 -> 140303257270640
	140303257268336 -> 140303257270640
	140303202722064 [label="model.model.encoder.repeat_2.5.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202722064 -> 140303257268336
	140303257268336 [label=AccumulateGrad]
	140303257271072 -> 140303257271696
	140303202722144 [label="model.model.encoder.repeat_2.5.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202722144 -> 140303257271072
	140303257271072 [label=AccumulateGrad]
	140303257271648 -> 140303257271696
	140303202722224 [label="model.model.encoder.repeat_2.5.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202722224 -> 140303257271648
	140303257271648 [label=AccumulateGrad]
	140303257268144 -> 140303207195232
	140303202722624 [label="model.model.encoder.repeat_2.5.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202722624 -> 140303257268144
	140303257268144 [label=AccumulateGrad]
	140303257267952 -> 140303207191440
	140303202722704 [label="model.model.encoder.repeat_2.5.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202722704 -> 140303257267952
	140303257267952 [label=AccumulateGrad]
	140303257257680 -> 140303207191440
	140303202722784 [label="model.model.encoder.repeat_2.5.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202722784 -> 140303257257680
	140303257257680 [label=AccumulateGrad]
	140303207196864 -> 140303207198352
	140303202723184 [label="model.model.encoder.repeat_2.5.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202723184 -> 140303207196864
	140303207196864 [label=AccumulateGrad]
	140303207197392 -> 140303207198208
	140303202723264 [label="model.model.encoder.repeat_2.5.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202723264 -> 140303207197392
	140303207197392 [label=AccumulateGrad]
	140303207198976 -> 140303207198208
	140303202723344 [label="model.model.encoder.repeat_2.5.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202723344 -> 140303207198976
	140303207198976 [label=AccumulateGrad]
	140303207199888 -> 140303207199936
	140303202723744 [label="model.model.encoder.repeat_2.5.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202723744 -> 140303207199888
	140303207199888 [label=AccumulateGrad]
	140303207200128 -> 140303207199936
	140303202723824 [label="model.model.encoder.repeat_2.5.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202723824 -> 140303207200128
	140303207200128 [label=AccumulateGrad]
	140303207200320 -> 140303207200656
	140303207200848 -> 140303207201232
	140303202723984 [label="model.model.encoder.repeat_2.6.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202723984 -> 140303207200848
	140303207200848 [label=AccumulateGrad]
	140303207201280 -> 140303207201616
	140303202724064 [label="model.model.encoder.repeat_2.6.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202724064 -> 140303207201280
	140303207201280 [label=AccumulateGrad]
	140303207201808 -> 140303207201616
	140303202724144 [label="model.model.encoder.repeat_2.6.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202724144 -> 140303207201808
	140303207201808 [label=AccumulateGrad]
	140303207202000 -> 140303207202240
	140303207202000 [label=ReluBackward0]
	140303207200896 -> 140303207202000
	140303207200896 [label=CudnnBatchNormBackward0]
	140303207201040 -> 140303207200896
	140303207201040 [label=ConvolutionBackward0]
	140303207198400 -> 140303207201040
	140303207198400 [label=ReluBackward0]
	140303207194224 -> 140303207198400
	140303207194224 [label=CudnnBatchNormBackward0]
	140303207198016 -> 140303207194224
	140303207198016 [label=ConvolutionBackward0]
	140303257267280 -> 140303207198016
	140303257267280 [label=ReluBackward0]
	140303257266656 -> 140303257267280
	140303257266656 [label=CudnnBatchNormBackward0]
	140303257265600 -> 140303257266656
	140303257265600 [label=ConvolutionBackward0]
	140303251390080 -> 140303257265600
	140303257263296 -> 140303257265600
	140303202724624 [label="model.model.encoder.repeat_2.6.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202724624 -> 140303257263296
	140303257263296 [label=AccumulateGrad]
	140303257266032 -> 140303257266656
	140303202724704 [label="model.model.encoder.repeat_2.6.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202724704 -> 140303257266032
	140303257266032 [label=AccumulateGrad]
	140303257267712 -> 140303257266656
	140303202724784 [label="model.model.encoder.repeat_2.6.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202724784 -> 140303257267712
	140303257267712 [label=AccumulateGrad]
	140303257267088 -> 140303207198016
	140303202725184 [label="model.model.encoder.repeat_2.6.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202725184 -> 140303257267088
	140303257267088 [label=AccumulateGrad]
	140303257260080 -> 140303207194224
	140303202725264 [label="model.model.encoder.repeat_2.6.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202725264 -> 140303257260080
	140303257260080 [label=AccumulateGrad]
	140303257265120 -> 140303207194224
	140303202725344 [label="model.model.encoder.repeat_2.6.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202725344 -> 140303257265120
	140303257265120 [label=AccumulateGrad]
	140303207199360 -> 140303207201040
	140303202725824 [label="model.model.encoder.repeat_2.6.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202725824 -> 140303207199360
	140303207199360 [label=AccumulateGrad]
	140303207200080 -> 140303207200896
	140303202725904 [label="model.model.encoder.repeat_2.6.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202725904 -> 140303207200080
	140303207200080 [label=AccumulateGrad]
	140303207201664 -> 140303207200896
	140303202725984 [label="model.model.encoder.repeat_2.6.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202725984 -> 140303207201664
	140303207201664 [label=AccumulateGrad]
	140303207202576 -> 140303251390272
	140303202726464 [label="model.model.encoder.repeat_2.6.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202726464 -> 140303207202576
	140303207202576 [label=AccumulateGrad]
	140303207202768 -> 140303251390272
	140303202726544 [label="model.model.encoder.repeat_2.6.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202726544 -> 140303207202768
	140303207202768 [label=AccumulateGrad]
	140303251390080 -> 140303207094144
	140303207096736 -> 140303207097408
	140303202726704 [label="model.model.encoder.repeat_2.7.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202726704 -> 140303207096736
	140303207096736 [label=AccumulateGrad]
	140303207097552 -> 140303207097600
	140303202726784 [label="model.model.encoder.repeat_2.7.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202726784 -> 140303207097552
	140303207097552 [label=AccumulateGrad]
	140303207097792 -> 140303207097600
	140303202726864 [label="model.model.encoder.repeat_2.7.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202726864 -> 140303207097792
	140303207097792 [label=AccumulateGrad]
	140303207097984 -> 140303207098512
	140303207097984 [label=ReluBackward0]
	140303251390416 -> 140303207097984
	140303251390416 [label=CudnnBatchNormBackward0]
	140303207094192 -> 140303251390416
	140303207094192 [label=ConvolutionBackward0]
	140303207201088 -> 140303207094192
	140303207201088 [label=ReluBackward0]
	140303207197008 -> 140303207201088
	140303207197008 [label=CudnnBatchNormBackward0]
	140303207200704 -> 140303207197008
	140303207200704 [label=ConvolutionBackward0]
	140303257262240 -> 140303207200704
	140303257262240 [label=ReluBackward0]
	140303257261616 -> 140303257262240
	140303257261616 [label=CudnnBatchNormBackward0]
	140303257260560 -> 140303257261616
	140303257260560 [label=ConvolutionBackward0]
	140303207099280 -> 140303257260560
	140303257258256 -> 140303257260560
	140303202727264 [label="model.model.encoder.repeat_2.7.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202727264 -> 140303257258256
	140303257258256 [label=AccumulateGrad]
	140303257261184 -> 140303257261616
	140303202727344 [label="model.model.encoder.repeat_2.7.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303202727344 -> 140303257261184
	140303257261184 [label=AccumulateGrad]
	140303257262864 -> 140303257261616
	140303202727424 [label="model.model.encoder.repeat_2.7.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303202727424 -> 140303257262864
	140303257262864 [label=AccumulateGrad]
	140303257269392 -> 140303207200704
	140303202727824 [label="model.model.encoder.repeat_2.7.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303202727824 -> 140303257269392
	140303257269392 [label=AccumulateGrad]
	140303257268960 -> 140303207197008
	140303202727904 [label="model.model.encoder.repeat_2.7.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303202727904 -> 140303257268960
	140303257268960 [label=AccumulateGrad]
	140303257270016 -> 140303207197008
	140303202727984 [label="model.model.encoder.repeat_2.7.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303202727984 -> 140303257270016
	140303257270016 [label=AccumulateGrad]
	140303207202048 -> 140303207094192
	140303202728384 [label="model.model.encoder.repeat_2.7.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303202728384 -> 140303207202048
	140303207202048 [label=AccumulateGrad]
	140303207097072 -> 140303251390416
	140303202728464 [label="model.model.encoder.repeat_2.7.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303202728464 -> 140303207097072
	140303207097072 [label=AccumulateGrad]
	140303207097744 -> 140303251390416
	140303202728544 [label="model.model.encoder.repeat_2.7.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303202728544 -> 140303207097744
	140303207097744 [label=AccumulateGrad]
	140303207098560 -> 140303207098704
	140303202729024 [label="model.model.encoder.repeat_2.7.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303202729024 -> 140303207098560
	140303207098560 [label=AccumulateGrad]
	140303207098896 -> 140303207098704
	140303202729104 [label="model.model.encoder.repeat_2.7.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303202729104 -> 140303207098896
	140303207098896 [label=AccumulateGrad]
	140303207099280 -> 140303207099328
	140303207099520 -> 140303207099904
	140303202729264 [label="model.model.encoder.repeat_2.8.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202729264 -> 140303207099520
	140303207099520 [label=AccumulateGrad]
	140303207100240 -> 140303207100288
	140303202729344 [label="model.model.encoder.repeat_2.8.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303202729344 -> 140303207100240
	140303207100240 [label=AccumulateGrad]
	140303207100480 -> 140303207100288
	140303202729424 [label="model.model.encoder.repeat_2.8.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303202729424 -> 140303207100480
	140303207100480 [label=AccumulateGrad]
	140303207100672 -> 140303207101200
	140303207100672 [label=ReluBackward0]
	140303207099664 -> 140303207100672
	140303207099664 [label=CudnnBatchNormBackward0]
	140303207099712 -> 140303207099664
	140303207099712 [label=ConvolutionBackward0]
	140303207097360 -> 140303207099712
	140303207097360 [label=ReluBackward0]
	140303207199696 -> 140303207097360
	140303207199696 [label=CudnnBatchNormBackward0]
	140303207202624 -> 140303207199696
	140303207202624 [label=ConvolutionBackward0]
	140303257257200 -> 140303207202624
	140303257257200 [label=ReluBackward0]
	140303257256576 -> 140303257257200
	140303257256576 [label=CudnnBatchNormBackward0]
	140303257256144 -> 140303257256576
	140303257256144 [label=ConvolutionBackward0]
	140303207101872 -> 140303257256144
	140303257187808 -> 140303257256144
	140303202729904 [label="model.model.encoder.repeat_2.8.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303202729904 -> 140303257187808
	140303257187808 [label=AccumulateGrad]
	140303257257824 -> 140303257256576
	140303200976960 [label="model.model.encoder.repeat_2.8.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303200976960 -> 140303257257824
	140303257257824 [label=AccumulateGrad]
	140303257189920 -> 140303257256576
	140303200977040 [label="model.model.encoder.repeat_2.8.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303200977040 -> 140303257189920
	140303257189920 [label=AccumulateGrad]
	140303257264352 -> 140303207202624
	140303200977520 [label="model.model.encoder.repeat_2.8.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303200977520 -> 140303257264352
	140303257264352 [label=AccumulateGrad]
	140303257263920 -> 140303207199696
	140303200977600 [label="model.model.encoder.repeat_2.8.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303200977600 -> 140303257263920
	140303257263920 [label=AccumulateGrad]
	140303257264976 -> 140303207199696
	140303200977680 [label="model.model.encoder.repeat_2.8.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303200977680 -> 140303257264976
	140303257264976 [label=AccumulateGrad]
	140303207098320 -> 140303207099712
	140303200978160 [label="model.model.encoder.repeat_2.8.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303200978160 -> 140303207098320
	140303207098320 [label=AccumulateGrad]
	140303207098752 -> 140303207099664
	140303200978240 [label="model.model.encoder.repeat_2.8.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303200978240 -> 140303207098752
	140303207098752 [label=AccumulateGrad]
	140303207100432 -> 140303207099664
	140303200978320 [label="model.model.encoder.repeat_2.8.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303200978320 -> 140303207100432
	140303207100432 [label=AccumulateGrad]
	140303207101248 -> 140303207101488
	140303200978720 [label="model.model.encoder.repeat_2.8.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303200978720 -> 140303207101248
	140303207101248 [label=AccumulateGrad]
	140303207101680 -> 140303207101488
	140303200978800 [label="model.model.encoder.repeat_2.8.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303200978800 -> 140303207101680
	140303207101680 [label=AccumulateGrad]
	140303207101872 -> 140303207101920
	140303207102112 -> 140303207102688
	140303200978960 [label="model.model.encoder.block8.branch0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303200978960 -> 140303207102112
	140303207102112 [label=AccumulateGrad]
	140303207102832 -> 140303207102880
	140303200979040 [label="model.model.encoder.block8.branch0.bn.weight
 (192)" fillcolor=lightblue]
	140303200979040 -> 140303207102832
	140303207102832 [label=AccumulateGrad]
	140303207103072 -> 140303207102880
	140303200979120 [label="model.model.encoder.block8.branch0.bn.bias
 (192)" fillcolor=lightblue]
	140303200979120 -> 140303207103072
	140303207103072 [label=AccumulateGrad]
	140303207103456 -> 140303207103792
	140303207103456 [label=ReluBackward0]
	140303207102448 -> 140303207103456
	140303207102448 [label=CudnnBatchNormBackward0]
	140303207102496 -> 140303207102448
	140303207102496 [label=ConvolutionBackward0]
	140303207099856 -> 140303207102496
	140303207099856 [label=ReluBackward0]
	140303207202192 -> 140303207099856
	140303207202192 [label=CudnnBatchNormBackward0]
	140303207099472 -> 140303207202192
	140303207099472 [label=ConvolutionBackward0]
	140303257186560 -> 140303207099472
	140303257186560 [label=ReluBackward0]
	140303257186128 -> 140303257186560
	140303257186128 [label=CudnnBatchNormBackward0]
	140303257184880 -> 140303257186128
	140303257184880 [label=ConvolutionBackward0]
	140303207104416 -> 140303257184880
	140303257182768 -> 140303257184880
	140303200979520 [label="model.model.encoder.block8.branch1.0.conv.weight
 (192, 2080, 1, 1)" fillcolor=lightblue]
	140303200979520 -> 140303257182768
	140303257182768 [label=AccumulateGrad]
	140303257185504 -> 140303257186128
	140303200979600 [label="model.model.encoder.block8.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140303200979600 -> 140303257185504
	140303257185504 [label=AccumulateGrad]
	140303257187184 -> 140303257186128
	140303200979680 [label="model.model.encoder.block8.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140303200979680 -> 140303257187184
	140303257187184 [label=AccumulateGrad]
	140303257189488 -> 140303207099472
	140303200980080 [label="model.model.encoder.block8.branch1.1.conv.weight
 (224, 192, 1, 3)" fillcolor=lightblue]
	140303200980080 -> 140303257189488
	140303257189488 [label=AccumulateGrad]
	140303257258880 -> 140303207202192
	140303200980160 [label="model.model.encoder.block8.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140303200980160 -> 140303257258880
	140303257258880 [label=AccumulateGrad]
	140303257259936 -> 140303207202192
	140303200980240 [label="model.model.encoder.block8.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140303200980240 -> 140303257259936
	140303257259936 [label=AccumulateGrad]
	140303207100816 -> 140303207102496
	140303200980720 [label="model.model.encoder.block8.branch1.2.conv.weight
 (256, 224, 3, 1)" fillcolor=lightblue]
	140303200980720 -> 140303207100816
	140303207100816 [label=AccumulateGrad]
	140303207101536 -> 140303207102448
	140303200980800 [label="model.model.encoder.block8.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140303200980800 -> 140303207101536
	140303207101536 [label=AccumulateGrad]
	140303207103024 -> 140303207102448
	140303200980880 [label="model.model.encoder.block8.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140303200980880 -> 140303207103024
	140303207103024 [label=AccumulateGrad]
	140303207103840 -> 140303207103984
	140303200981280 [label="model.model.encoder.block8.conv2d.weight
 (2080, 448, 1, 1)" fillcolor=lightblue]
	140303200981280 -> 140303207103840
	140303207103840 [label=AccumulateGrad]
	140303207104368 -> 140303207103984
	140303200981360 [label="model.model.encoder.block8.conv2d.bias
 (2080)" fillcolor=lightblue]
	140303200981360 -> 140303207104368
	140303207104368 [label=AccumulateGrad]
	140303207104416 -> 140303257683136
	140303257683184 -> 140303257682944
	140303200981520 [label="model.model.encoder.conv2d_7b.conv.weight
 (1536, 2080, 1, 1)" fillcolor=lightblue]
	140303200981520 -> 140303257683184
	140303257683184 [label=AccumulateGrad]
	140303257682992 -> 140303257682848
	140303200981600 [label="model.model.encoder.conv2d_7b.bn.weight
 (1536)" fillcolor=lightblue]
	140303200981600 -> 140303257682992
	140303257682992 [label=AccumulateGrad]
	140303257688416 -> 140303257682848
	140303200981680 [label="model.model.encoder.conv2d_7b.bn.bias
 (1536)" fillcolor=lightblue]
	140303200981680 -> 140303257688416
	140303257688416 [label=AccumulateGrad]
	140303257686784 -> 140303205680272
	140303206458528 -> 140303206458384
	140303248085120 [label="model.model.decoder.blocks.0.conv1.0.weight
 (256, 2624, 3, 3)" fillcolor=lightblue]
	140303248085120 -> 140303206458528
	140303206458528 [label=AccumulateGrad]
	140303206458336 -> 140303206458288
	140303201648000 [label="model.model.decoder.blocks.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	140303201648000 -> 140303206458336
	140303206458336 [label=AccumulateGrad]
	140303206458192 -> 140303206458288
	140303201642720 [label="model.model.decoder.blocks.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	140303201642720 -> 140303206458192
	140303206458192 [label=AccumulateGrad]
	140303206458096 -> 140303202753632
	140303201633680 [label="model.model.decoder.blocks.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140303201633680 -> 140303206458096
	140303206458096 [label=AccumulateGrad]
	140303202754976 -> 140303202756512
	140303201646320 [label="model.model.decoder.blocks.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	140303201646320 -> 140303202754976
	140303202754976 [label=AccumulateGrad]
	140303206457952 -> 140303202756512
	140303201646080 [label="model.model.decoder.blocks.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	140303201646080 -> 140303206457952
	140303206457952 [label=AccumulateGrad]
	140303202755840 -> 140303202756704
	140303202756416 -> 140303202755552
	140303201634560 [label="model.model.decoder.blocks.1.conv1.0.weight
 (128, 576, 3, 3)" fillcolor=lightblue]
	140303201634560 -> 140303202756416
	140303202756416 [label=AccumulateGrad]
	140303202755360 -> 140303202755408
	140303201634240 [label="model.model.decoder.blocks.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	140303201634240 -> 140303202755360
	140303202755360 [label=AccumulateGrad]
	140303202755264 -> 140303202755408
	140303201634000 [label="model.model.decoder.blocks.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	140303201634000 -> 140303202755264
	140303202755264 [label=AccumulateGrad]
	140303202755120 -> 140303202754640
	140303201648400 [label="model.model.decoder.blocks.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140303201648400 -> 140303202755120
	140303202755120 [label=AccumulateGrad]
	140303202754688 -> 140303202754496
	140303201648160 [label="model.model.decoder.blocks.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	140303201648160 -> 140303202754688
	140303202754688 [label=AccumulateGrad]
	140303202754208 -> 140303202754496
	140303201647920 [label="model.model.decoder.blocks.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	140303201647920 -> 140303202754208
	140303202754208 [label=AccumulateGrad]
	140303202754064 -> 140303202754112
	140303202753392 -> 140303202753344
	140303201646960 [label="model.model.decoder.blocks.2.conv1.0.weight
 (64, 320, 3, 3)" fillcolor=lightblue]
	140303201646960 -> 140303202753392
	140303202753392 [label=AccumulateGrad]
	140303202753680 -> 140303202756560
	140303201646720 [label="model.model.decoder.blocks.2.conv1.1.weight
 (64)" fillcolor=lightblue]
	140303201646720 -> 140303202753680
	140303202753680 [label=AccumulateGrad]
	140303202756128 -> 140303202756560
	140303201646480 [label="model.model.decoder.blocks.2.conv1.1.bias
 (64)" fillcolor=lightblue]
	140303201646480 -> 140303202756128
	140303202756128 [label=AccumulateGrad]
	140303202756272 -> 140303202762512
	140303201645040 [label="model.model.decoder.blocks.2.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140303201645040 -> 140303202756272
	140303202756272 [label=AccumulateGrad]
	140303202761552 -> 140303202761696
	140303201645280 [label="model.model.decoder.blocks.2.conv2.1.weight
 (64)" fillcolor=lightblue]
	140303201645280 -> 140303202761552
	140303202761552 [label=AccumulateGrad]
	140303202761024 -> 140303202761696
	140303201644800 [label="model.model.decoder.blocks.2.conv2.1.bias
 (64)" fillcolor=lightblue]
	140303201644800 -> 140303202761024
	140303202761024 [label=AccumulateGrad]
	140303202760592 -> 140303202760256
	140303202760016 -> 140303202759584
	140303201643520 [label="model.model.decoder.blocks.3.conv1.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	140303201643520 -> 140303202760016
	140303202760016 [label=AccumulateGrad]
	140303202759104 -> 140303202759152
	140303201643440 [label="model.model.decoder.blocks.3.conv1.1.weight
 (32)" fillcolor=lightblue]
	140303201643440 -> 140303202759104
	140303202759104 [label=AccumulateGrad]
	140303202758672 -> 140303202759152
	140303201643280 [label="model.model.decoder.blocks.3.conv1.1.bias
 (32)" fillcolor=lightblue]
	140303201643280 -> 140303202758672
	140303202758672 [label=AccumulateGrad]
	140303202758240 -> 140303202757520
	140303201642080 [label="model.model.decoder.blocks.3.conv2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140303201642080 -> 140303202758240
	140303202758240 [label=AccumulateGrad]
	140303202757568 -> 140303253257904
	140303201642000 [label="model.model.decoder.blocks.3.conv2.1.weight
 (32)" fillcolor=lightblue]
	140303201642000 -> 140303202757568
	140303202757568 [label=AccumulateGrad]
	140303202756368 -> 140303253257904
	140303201641600 [label="model.model.decoder.blocks.3.conv2.1.bias
 (32)" fillcolor=lightblue]
	140303201641600 -> 140303202756368
	140303202756368 [label=AccumulateGrad]
	140302990950512 -> 140303207284800
	140303201640720 [label="model.model.decoder.blocks.4.conv1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	140303201640720 -> 140302990950512
	140302990950512 [label=AccumulateGrad]
	140303207285136 -> 140303207284944
	140303201640480 [label="model.model.decoder.blocks.4.conv1.1.weight
 (16)" fillcolor=lightblue]
	140303201640480 -> 140303207285136
	140303207285136 [label=AccumulateGrad]
	140302990954304 -> 140303207284944
	140303201640240 [label="model.model.decoder.blocks.4.conv1.1.bias
 (16)" fillcolor=lightblue]
	140303201640240 -> 140302990954304
	140302990954304 [label=AccumulateGrad]
	140303207285520 -> 140303207285760
	140303201638800 [label="model.model.decoder.blocks.4.conv2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140303201638800 -> 140303207285520
	140303207285520 [label=AccumulateGrad]
	140303207285904 -> 140303207286672
	140303201638720 [label="model.model.decoder.blocks.4.conv2.1.weight
 (16)" fillcolor=lightblue]
	140303201638720 -> 140303207285904
	140303207285904 [label=AccumulateGrad]
	140303207286528 -> 140303207286672
	140303201638480 [label="model.model.decoder.blocks.4.conv2.1.bias
 (16)" fillcolor=lightblue]
	140303201638480 -> 140303207286528
	140303207286528 [label=AccumulateGrad]
	140303207286480 -> 140303207286864
	140303201637440 [label="model.model.segmentation_head.0.weight
 (1, 16, 3, 3)" fillcolor=lightblue]
	140303201637440 -> 140303207286480
	140303207286480 [label=AccumulateGrad]
	140303207286144 -> 140303207286864
	140303201637360 [label="model.model.segmentation_head.0.bias
 (1)" fillcolor=lightblue]
	140303201637360 -> 140303207286144
	140303207286144 [label=AccumulateGrad]
	140303207286864 -> 140303204616288
}
