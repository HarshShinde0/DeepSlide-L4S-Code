digraph {
	graph [size="455.4,455.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140384419991440 [label="
 (1, 1, 128, 128)" fillcolor=darkolivegreen1]
	140384425699520 [label=ConvolutionBackward0]
	140384425697936 -> 140384425699520
	140384425697936 [label=ReluBackward0]
	140384425700192 -> 140384425697936
	140384425700192 [label=CudnnBatchNormBackward0]
	140384425698368 -> 140384425700192
	140384425698368 [label=ConvolutionBackward0]
	140384425696208 -> 140384425698368
	140384425696208 [label=ReluBackward0]
	140384425690400 -> 140384425696208
	140384425690400 [label=CudnnBatchNormBackward0]
	140384425703984 -> 140384425690400
	140384425703984 [label=ConvolutionBackward0]
	140384420896896 -> 140384425703984
	140384420896896 [label=UpsampleNearest2DBackward0]
	140383267777040 -> 140384420896896
	140383267777040 [label=ReluBackward0]
	140383267776896 -> 140383267777040
	140383267776896 [label=CudnnBatchNormBackward0]
	140383267776608 -> 140383267776896
	140383267776608 [label=ConvolutionBackward0]
	140383267776032 -> 140383267776608
	140383267776032 [label=ReluBackward0]
	140383267775696 -> 140383267776032
	140383267775696 [label=CudnnBatchNormBackward0]
	140383267775552 -> 140383267775696
	140383267775552 [label=ConvolutionBackward0]
	140383267775120 -> 140383267775552
	140383267775120 [label=CatBackward0]
	140383267774592 -> 140383267775120
	140383267774592 [label=UpsampleNearest2DBackward0]
	140383267774256 -> 140383267774592
	140383267774256 [label=ReluBackward0]
	140383267774112 -> 140383267774256
	140383267774112 [label=CudnnBatchNormBackward0]
	140383267773920 -> 140383267774112
	140383267773920 [label=ConvolutionBackward0]
	140383267773344 -> 140383267773920
	140383267773344 [label=ReluBackward0]
	140383267772864 -> 140383267773344
	140383267772864 [label=CudnnBatchNormBackward0]
	140383267772720 -> 140383267772864
	140383267772720 [label=ConvolutionBackward0]
	140383267772288 -> 140383267772720
	140383267772288 [label=CatBackward0]
	140383267771952 -> 140383267772288
	140383267771952 [label=UpsampleNearest2DBackward0]
	140383267771424 -> 140383267771952
	140383267771424 [label=ReluBackward0]
	140383267771280 -> 140383267771424
	140383267771280 [label=CudnnBatchNormBackward0]
	140383267771136 -> 140383267771280
	140383267771136 [label=ConvolutionBackward0]
	140383267770704 -> 140383267771136
	140383267770704 [label=ReluBackward0]
	140383267770368 -> 140383267770704
	140383267770368 [label=CudnnBatchNormBackward0]
	140383267777664 -> 140383267770368
	140383267777664 [label=ConvolutionBackward0]
	140383267769840 -> 140383267777664
	140383267769840 [label=CatBackward0]
	140383267769936 -> 140383267769840
	140383267769936 [label=UpsampleNearest2DBackward0]
	140383267770272 -> 140383267769936
	140383267770272 [label=ReluBackward0]
	140383267777856 -> 140383267770272
	140383267777856 [label=CudnnBatchNormBackward0]
	140383267778000 -> 140383267777856
	140383267778000 [label=ConvolutionBackward0]
	140383267778288 -> 140383267778000
	140383267778288 [label=ReluBackward0]
	140383267778384 -> 140383267778288
	140383267778384 [label=CudnnBatchNormBackward0]
	140383267778528 -> 140383267778384
	140383267778528 [label=ConvolutionBackward0]
	140383267778816 -> 140383267778528
	140383267778816 [label=CatBackward0]
	140383267779152 -> 140383267778816
	140383267779152 [label=UpsampleNearest2DBackward0]
	140383267779248 -> 140383267779152
	140383267779248 [label=CatBackward0]
	140383267779392 -> 140383267779248
	140383267779392 [label=ReluBackward0]
	140383267779872 -> 140383267779392
	140383267779872 [label=CudnnBatchNormBackward0]
	140383267780016 -> 140383267779872
	140383267780016 [label=ConvolutionBackward0]
	140383267780304 -> 140383267780016
	140383267780304 [label=CatBackward0]
	140383267780400 -> 140383267780304
	140383267780400 [label=ReluBackward0]
	140383267780880 -> 140383267780400
	140383267780880 [label=CudnnBatchNormBackward0]
	140383267781024 -> 140383267780880
	140383267781024 [label=ConvolutionBackward0]
	140383267781312 -> 140383267781024
	140383267781312 [label=CatBackward0]
	140383267781408 -> 140383267781312
	140383267781408 [label=ReluBackward0]
	140383267781888 -> 140383267781408
	140383267781888 [label=CudnnBatchNormBackward0]
	140383267782032 -> 140383267781888
	140383267782032 [label=ConvolutionBackward0]
	140383267782320 -> 140383267782032
	140383267782320 [label=CatBackward0]
	140383267782416 -> 140383267782320
	140383267782416 [label=ReluBackward0]
	140383267777376 -> 140383267782416
	140383267777376 [label=CudnnBatchNormBackward0]
	140383267777088 -> 140383267777376
	140383267777088 [label=ConvolutionBackward0]
	140383267776512 -> 140383267777088
	140383267776512 [label=ReluBackward0]
	140383267776080 -> 140383267776512
	140383267776080 [label=CudnnBatchNormBackward0]
	140383267775792 -> 140383267776080
	140383267775792 [label=ConvolutionBackward0]
	140383267775216 -> 140383267775792
	140383267775216 [label=CatBackward0]
	140383267774640 -> 140383267775216
	140383267774640 [label=ReluBackward0]
	140383267774064 -> 140383267774640
	140383267774064 [label=CudnnBatchNormBackward0]
	140383267773776 -> 140383267774064
	140383267773776 [label=ConvolutionBackward0]
	140383267773200 -> 140383267773776
	140383267773200 [label=CatBackward0]
	140383267772768 -> 140383267773200
	140383267772768 [label=ReluBackward0]
	140383267772048 -> 140383267772768
	140383267772048 [label=CudnnBatchNormBackward0]
	140383267771760 -> 140383267772048
	140383267771760 [label=ConvolutionBackward0]
	140383267771184 -> 140383267771760
	140383267771184 [label=CatBackward0]
	140383267770752 -> 140383267771184
	140383267770752 [label=ReluBackward0]
	140383267769744 -> 140383267770752
	140383267769744 [label=CudnnBatchNormBackward0]
	140383267770032 -> 140383267769744
	140383267770032 [label=ConvolutionBackward0]
	140383267778960 -> 140383267770032
	140383267778960 [label=CatBackward0]
	140383267778336 -> 140383267778960
	140383267778336 [label=ReluBackward0]
	140383267779056 -> 140383267778336
	140383267779056 [label=CudnnBatchNormBackward0]
	140383267779344 -> 140383267779056
	140383267779344 [label=ConvolutionBackward0]
	140383267779920 -> 140383267779344
	140383267779920 [label=CatBackward0]
	140383267780352 -> 140383267779920
	140383267780352 [label=ReluBackward0]
	140383267781072 -> 140383267780352
	140383267781072 [label=CudnnBatchNormBackward0]
	140383267781360 -> 140383267781072
	140383267781360 [label=ConvolutionBackward0]
	140383267781936 -> 140383267781360
	140383267781936 [label=CatBackward0]
	140383267782368 -> 140383267781936
	140383267782368 [label=ReluBackward0]
	140384036338464 -> 140383267782368
	140384036338464 [label=CudnnBatchNormBackward0]
	140384036338032 -> 140384036338464
	140384036338032 [label=ConvolutionBackward0]
	140384036338080 -> 140384036338032
	140384036338080 [label=CatBackward0]
	140384036338128 -> 140384036338080
	140384036338128 [label=ReluBackward0]
	140384036338176 -> 140384036338128
	140384036338176 [label=CudnnBatchNormBackward0]
	140384036337936 -> 140384036338176
	140384036337936 [label=ConvolutionBackward0]
	140384036338224 -> 140384036337936
	140384036338224 [label=CatBackward0]
	140384036339472 -> 140384036338224
	140384036339472 [label=ReluBackward0]
	140384036334576 -> 140384036339472
	140384036334576 [label=CudnnBatchNormBackward0]
	140384036339424 -> 140384036334576
	140384036339424 [label=ConvolutionBackward0]
	140384036339232 -> 140384036339424
	140384036339232 [label=CatBackward0]
	140384412431552 -> 140384036339232
	140384412431552 [label=ReluBackward0]
	140384412425072 -> 140384412431552
	140384412425072 [label=CudnnBatchNormBackward0]
	140384412422048 -> 140384412425072
	140384412422048 [label=ConvolutionBackward0]
	140383267769984 -> 140384412422048
	140383267769984 [label=CatBackward0]
	140384412429968 -> 140383267769984
	140384412429968 [label=ReluBackward0]
	140384412424928 -> 140384412429968
	140384412424928 [label=CudnnBatchNormBackward0]
	140384412421616 -> 140384412424928
	140384412421616 [label=ConvolutionBackward0]
	140384412474128 -> 140384412421616
	140384412474128 [label=CatBackward0]
	140384412473552 -> 140384412474128
	140384412473552 [label=ReluBackward0]
	140384412469712 -> 140384412473552
	140384412469712 [label=CudnnBatchNormBackward0]
	140384412469424 -> 140384412469712
	140384412469424 [label=ConvolutionBackward0]
	140384412469184 -> 140384412469424
	140384412469184 [label=CatBackward0]
	140384412482048 -> 140384412469184
	140384412482048 [label=ReluBackward0]
	140384412472688 -> 140384412482048
	140384412472688 [label=CudnnBatchNormBackward0]
	140384412475616 -> 140384412472688
	140384412475616 [label=ConvolutionBackward0]
	140384412470384 -> 140384412475616
	140384412470384 [label=CatBackward0]
	140384412481664 -> 140384412470384
	140384412481664 [label=ReluBackward0]
	140384412476576 -> 140384412481664
	140384412476576 [label=CudnnBatchNormBackward0]
	140384412468896 -> 140384412476576
	140384412468896 [label=ConvolutionBackward0]
	140383267772000 -> 140384412468896
	140383267772000 [label=CatBackward0]
	140384412472832 -> 140383267772000
	140384412472832 [label=ReluBackward0]
	140384412480080 -> 140384412472832
	140384412480080 [label=CudnnBatchNormBackward0]
	140384412469376 -> 140384412480080
	140384412469376 [label=ConvolutionBackward0]
	140384412471344 -> 140384412469376
	140384412471344 [label=ReluBackward0]
	140384412471440 -> 140384412471344
	140384412471440 [label=CudnnBatchNormBackward0]
	140384412472784 -> 140384412471440
	140384412472784 [label=ConvolutionBackward0]
	140384412472304 -> 140384412472784
	140384412472304 [label=CatBackward0]
	140384412476528 -> 140384412472304
	140384412476528 [label=MaxPool2DWithIndicesBackward0]
	140383267774832 -> 140384412476528
	140383267774832 [label=ReluBackward0]
	140384412473744 -> 140383267774832
	140384412473744 [label=CudnnBatchNormBackward0]
	140384412470624 -> 140384412473744
	140384412470624 [label=ConvolutionBackward0]
	140384412472880 -> 140384412470624
	140384412472880 [label=ReluBackward0]
	140384412480128 -> 140384412472880
	140384412480128 [label=CudnnBatchNormBackward0]
	140384412478352 -> 140384412480128
	140384412478352 [label=ConvolutionBackward0]
	140384412471008 -> 140384412478352
	140384412471008 [label=ReluBackward0]
	140384412467600 -> 140384412471008
	140384412467600 [label=CudnnBatchNormBackward0]
	140384412481760 -> 140384412467600
	140384412481760 [label=ConvolutionBackward0]
	140384412468848 -> 140384412481760
	140384418299664 [label="model.model.encoder.features.0.conv.weight
 (32, 14, 3, 3)" fillcolor=lightblue]
	140384418299664 -> 140384412468848
	140384412468848 [label=AccumulateGrad]
	140384412471152 -> 140384412467600
	140384412386224 [label="model.model.encoder.features.0.bn.weight
 (32)" fillcolor=lightblue]
	140384412386224 -> 140384412471152
	140384412471152 [label=AccumulateGrad]
	140384412480896 -> 140384412467600
	140384412672992 [label="model.model.encoder.features.0.bn.bias
 (32)" fillcolor=lightblue]
	140384412672992 -> 140384412480896
	140384412480896 [label=AccumulateGrad]
	140384412475856 -> 140384412478352
	140383268748992 [label="model.model.encoder.features.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140383268748992 -> 140384412475856
	140384412475856 [label=AccumulateGrad]
	140384412482624 -> 140384412480128
	140383268733152 [label="model.model.encoder.features.1.bn.weight
 (32)" fillcolor=lightblue]
	140383268733152 -> 140384412482624
	140384412482624 [label=AccumulateGrad]
	140384412479360 -> 140384412480128
	140383268734752 [label="model.model.encoder.features.1.bn.bias
 (32)" fillcolor=lightblue]
	140383268734752 -> 140384412479360
	140384412479360 [label=AccumulateGrad]
	140384412471920 -> 140384412470624
	140384422208160 [label="model.model.encoder.features.2.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140384422208160 -> 140384412471920
	140384412471920 [label=AccumulateGrad]
	140384412470912 -> 140384412473744
	140384415513744 [label="model.model.encoder.features.2.bn.weight
 (64)" fillcolor=lightblue]
	140384415513744 -> 140384412470912
	140384412470912 [label=AccumulateGrad]
	140384412475184 -> 140384412473744
	140384415504304 [label="model.model.encoder.features.2.bn.bias
 (64)" fillcolor=lightblue]
	140384415504304 -> 140384412475184
	140384412475184 [label=AccumulateGrad]
	140384412476288 -> 140384412472304
	140384412476288 [label=ReluBackward0]
	140384412472976 -> 140384412476288
	140384412472976 [label=CudnnBatchNormBackward0]
	140384412474272 -> 140384412472976
	140384412474272 [label=ConvolutionBackward0]
	140383267774832 -> 140384412474272
	140384412476912 -> 140384412474272
	140384412166368 [label="model.model.encoder.features.3.conv.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412166368 -> 140384412476912
	140384412476912 [label=AccumulateGrad]
	140384412471968 -> 140384412472976
	140384415509424 [label="model.model.encoder.features.3.conv.bn.weight
 (96)" fillcolor=lightblue]
	140384415509424 -> 140384412471968
	140384412471968 [label=AccumulateGrad]
	140384412470528 -> 140384412472976
	140384412668432 [label="model.model.encoder.features.3.conv.bn.bias
 (96)" fillcolor=lightblue]
	140384412668432 -> 140384412470528
	140384412470528 [label=AccumulateGrad]
	140384412475088 -> 140384412472784
	140384427104256 [label="model.model.encoder.features.4.branch0.0.conv.weight
 (64, 160, 1, 1)" fillcolor=lightblue]
	140384427104256 -> 140384412475088
	140384412475088 [label=AccumulateGrad]
	140384412467312 -> 140384412471440
	140384427105616 [label="model.model.encoder.features.4.branch0.0.bn.weight
 (64)" fillcolor=lightblue]
	140384427105616 -> 140384412467312
	140384412467312 [label=AccumulateGrad]
	140384412472016 -> 140384412471440
	140384427104096 [label="model.model.encoder.features.4.branch0.0.bn.bias
 (64)" fillcolor=lightblue]
	140384427104096 -> 140384412472016
	140384412472016 [label=AccumulateGrad]
	140384412469472 -> 140384412469376
	140384427104736 [label="model.model.encoder.features.4.branch0.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384427104736 -> 140384412469472
	140384412469472 [label=AccumulateGrad]
	140384412470288 -> 140384412480080
	140384412217440 [label="model.model.encoder.features.4.branch0.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412217440 -> 140384412470288
	140384412470288 [label=AccumulateGrad]
	140384412478928 -> 140384412480080
	140384412217760 [label="model.model.encoder.features.4.branch0.1.bn.bias
 (96)" fillcolor=lightblue]
	140384412217760 -> 140384412478928
	140384412478928 [label=AccumulateGrad]
	140384412470816 -> 140383267772000
	140384412470816 [label=ReluBackward0]
	140384412470240 -> 140384412470816
	140384412470240 [label=CudnnBatchNormBackward0]
	140384412467792 -> 140384412470240
	140384412467792 [label=ConvolutionBackward0]
	140384412477248 -> 140384412467792
	140384412477248 [label=ReluBackward0]
	140384412474080 -> 140384412477248
	140384412474080 [label=CudnnBatchNormBackward0]
	140384412469280 -> 140384412474080
	140384412469280 [label=ConvolutionBackward0]
	140384412471584 -> 140384412469280
	140384412471584 [label=ReluBackward0]
	140384412476336 -> 140384412471584
	140384412476336 [label=CudnnBatchNormBackward0]
	140384412472448 -> 140384412476336
	140384412472448 [label=ConvolutionBackward0]
	140384412029696 -> 140384412472448
	140384412029696 [label=ReluBackward0]
	140384412026864 -> 140384412029696
	140384412026864 [label=CudnnBatchNormBackward0]
	140384412027632 -> 140384412026864
	140384412027632 [label=ConvolutionBackward0]
	140384412472304 -> 140384412027632
	140384412026768 -> 140384412027632
	140384423103600 [label="model.model.encoder.features.4.branch1.0.conv.weight
 (64, 160, 1, 1)" fillcolor=lightblue]
	140384423103600 -> 140384412026768
	140384412026768 [label=AccumulateGrad]
	140384412028496 -> 140384412026864
	140384412217840 [label="model.model.encoder.features.4.branch1.0.bn.weight
 (64)" fillcolor=lightblue]
	140384412217840 -> 140384412028496
	140384412028496 [label=AccumulateGrad]
	140384412026576 -> 140384412026864
	140384412217920 [label="model.model.encoder.features.4.branch1.0.bn.bias
 (64)" fillcolor=lightblue]
	140384412217920 -> 140384412026576
	140384412026576 [label=AccumulateGrad]
	140384412037904 -> 140384412472448
	140384412218240 [label="model.model.encoder.features.4.branch1.1.conv.weight
 (64, 64, 1, 7)" fillcolor=lightblue]
	140384412218240 -> 140384412037904
	140384412037904 [label=AccumulateGrad]
	140384412037808 -> 140384412476336
	140384412218960 [label="model.model.encoder.features.4.branch1.1.bn.weight
 (64)" fillcolor=lightblue]
	140384412218960 -> 140384412037808
	140384412037808 [label=AccumulateGrad]
	140384412039248 -> 140384412476336
	140384412219440 [label="model.model.encoder.features.4.branch1.1.bn.bias
 (64)" fillcolor=lightblue]
	140384412219440 -> 140384412039248
	140384412039248 [label=AccumulateGrad]
	140384412471296 -> 140384412469280
	140384412221200 [label="model.model.encoder.features.4.branch1.2.conv.weight
 (64, 64, 7, 1)" fillcolor=lightblue]
	140384412221200 -> 140384412471296
	140384412471296 [label=AccumulateGrad]
	140384412471728 -> 140384412474080
	140384412214560 [label="model.model.encoder.features.4.branch1.2.bn.weight
 (64)" fillcolor=lightblue]
	140384412214560 -> 140384412471728
	140384412471728 [label=AccumulateGrad]
	140384412468320 -> 140384412474080
	140384412212880 [label="model.model.encoder.features.4.branch1.2.bn.bias
 (64)" fillcolor=lightblue]
	140384412212880 -> 140384412468320
	140384412468320 [label=AccumulateGrad]
	140384412473312 -> 140384412467792
	140384412220400 [label="model.model.encoder.features.4.branch1.3.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412220400 -> 140384412473312
	140384412473312 [label=AccumulateGrad]
	140384412475376 -> 140384412470240
	140384412683456 [label="model.model.encoder.features.4.branch1.3.bn.weight
 (96)" fillcolor=lightblue]
	140384412683456 -> 140384412475376
	140384412475376 [label=AccumulateGrad]
	140384412468608 -> 140384412470240
	140384412683616 [label="model.model.encoder.features.4.branch1.3.bn.bias
 (96)" fillcolor=lightblue]
	140384412683616 -> 140384412468608
	140384412468608 [label=AccumulateGrad]
	140384412468224 -> 140384412468896
	140384425796736 [label="model.model.encoder.features.5.conv.conv.weight
 (192, 192, 3, 3)" fillcolor=lightblue]
	140384425796736 -> 140384412468224
	140384412468224 [label=AccumulateGrad]
	140384412475232 -> 140384412476576
	140384421858256 [label="model.model.encoder.features.5.conv.bn.weight
 (192)" fillcolor=lightblue]
	140384421858256 -> 140384412475232
	140384412475232 [label=AccumulateGrad]
	140384412468944 -> 140384412476576
	140384415540512 [label="model.model.encoder.features.5.conv.bn.bias
 (192)" fillcolor=lightblue]
	140384415540512 -> 140384412468944
	140384412468944 [label=AccumulateGrad]
	140384412478640 -> 140384412470384
	140384412478640 [label=MaxPool2DWithIndicesBackward0]
	140383267772000 -> 140384412478640
	140384412469760 -> 140384412475616
	140383249410752 [label="model.model.encoder.features.6.branch0.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140383249410752 -> 140384412469760
	140384412469760 [label=AccumulateGrad]
	140384412476240 -> 140384412472688
	140383249412672 [label="model.model.encoder.features.6.branch0.bn.weight
 (96)" fillcolor=lightblue]
	140383249412672 -> 140384412476240
	140384412476240 [label=AccumulateGrad]
	140384412473456 -> 140384412472688
	140383249414112 [label="model.model.encoder.features.6.branch0.bn.bias
 (96)" fillcolor=lightblue]
	140383249414112 -> 140384412473456
	140384412473456 [label=AccumulateGrad]
	140384412480176 -> 140384412469184
	140384412480176 [label=ReluBackward0]
	140384412474752 -> 140384412480176
	140384412474752 [label=CudnnBatchNormBackward0]
	140384412468272 -> 140384412474752
	140384412468272 [label=ConvolutionBackward0]
	140384412471248 -> 140384412468272
	140384412471248 [label=ReluBackward0]
	140384412472256 -> 140384412471248
	140384412472256 [label=CudnnBatchNormBackward0]
	140384412475664 -> 140384412472256
	140384412475664 [label=ConvolutionBackward0]
	140384412470384 -> 140384412475664
	140384412027008 -> 140384412475664
	140383249409312 [label="model.model.encoder.features.6.branch1.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140383249409312 -> 140384412027008
	140384412027008 [label=AccumulateGrad]
	140384412481616 -> 140384412472256
	140383249408832 [label="model.model.encoder.features.6.branch1.0.bn.weight
 (64)" fillcolor=lightblue]
	140383249408832 -> 140384412481616
	140384412481616 [label=AccumulateGrad]
	140384412482288 -> 140384412472256
	140383249404672 [label="model.model.encoder.features.6.branch1.0.bn.bias
 (64)" fillcolor=lightblue]
	140383249404672 -> 140384412482288
	140384412482288 [label=AccumulateGrad]
	140384412472064 -> 140384412468272
	140383249400992 [label="model.model.encoder.features.6.branch1.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140383249400992 -> 140384412472064
	140384412472064 [label=AccumulateGrad]
	140384412471056 -> 140384412474752
	140383249400832 [label="model.model.encoder.features.6.branch1.1.bn.weight
 (96)" fillcolor=lightblue]
	140383249400832 -> 140384412471056
	140384412471056 [label=AccumulateGrad]
	140384412473264 -> 140384412474752
	140383249411312 [label="model.model.encoder.features.6.branch1.1.bn.bias
 (96)" fillcolor=lightblue]
	140383249411312 -> 140384412473264
	140384412473264 [label=AccumulateGrad]
	140384412481904 -> 140384412469184
	140384412481904 [label=ReluBackward0]
	140384412472352 -> 140384412481904
	140384412472352 [label=CudnnBatchNormBackward0]
	140384412477008 -> 140384412472352
	140384412477008 [label=ConvolutionBackward0]
	140384412036704 -> 140384412477008
	140384412036704 [label=ReluBackward0]
	140384412027872 -> 140384412036704
	140384412027872 [label=CudnnBatchNormBackward0]
	140384412035552 -> 140384412027872
	140384412035552 [label=ConvolutionBackward0]
	140384412026096 -> 140384412035552
	140384412026096 [label=ReluBackward0]
	140384412033344 -> 140384412026096
	140384412033344 [label=CudnnBatchNormBackward0]
	140384412038816 -> 140384412033344
	140384412038816 [label=ConvolutionBackward0]
	140384412470384 -> 140384412038816
	140384412027152 -> 140384412038816
	140383249413552 [label="model.model.encoder.features.6.branch2.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140383249413552 -> 140384412027152
	140384412027152 [label=AccumulateGrad]
	140384412030080 -> 140384412033344
	140383249413712 [label="model.model.encoder.features.6.branch2.0.bn.weight
 (64)" fillcolor=lightblue]
	140383249413712 -> 140384412030080
	140384412030080 [label=AccumulateGrad]
	140384412037712 -> 140384412033344
	140383249415072 [label="model.model.encoder.features.6.branch2.0.bn.bias
 (64)" fillcolor=lightblue]
	140383249415072 -> 140384412037712
	140384412037712 [label=AccumulateGrad]
	140384412033584 -> 140384412035552
	140383249404032 [label="model.model.encoder.features.6.branch2.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140383249404032 -> 140384412033584
	140384412033584 [label=AccumulateGrad]
	140384412033296 -> 140384412027872
	140383249403792 [label="model.model.encoder.features.6.branch2.1.bn.weight
 (96)" fillcolor=lightblue]
	140383249403792 -> 140384412033296
	140384412033296 [label=AccumulateGrad]
	140384412032768 -> 140384412027872
	140383249403472 [label="model.model.encoder.features.6.branch2.1.bn.bias
 (96)" fillcolor=lightblue]
	140383249403472 -> 140384412032768
	140384412032768 [label=AccumulateGrad]
	140384412028544 -> 140384412477008
	140383249407632 [label="model.model.encoder.features.6.branch2.2.conv.weight
 (96, 96, 3, 3)" fillcolor=lightblue]
	140383249407632 -> 140384412028544
	140384412028544 [label=AccumulateGrad]
	140384412471776 -> 140384412472352
	140383249406992 [label="model.model.encoder.features.6.branch2.2.bn.weight
 (96)" fillcolor=lightblue]
	140383249406992 -> 140384412471776
	140384412471776 [label=AccumulateGrad]
	140384412025520 -> 140384412472352
	140383249403232 [label="model.model.encoder.features.6.branch2.2.bn.bias
 (96)" fillcolor=lightblue]
	140383249403232 -> 140384412025520
	140384412025520 [label=AccumulateGrad]
	140384412477056 -> 140384412469184
	140384412477056 [label=ReluBackward0]
	140384412468032 -> 140384412477056
	140384412468032 [label=CudnnBatchNormBackward0]
	140384412035408 -> 140384412468032
	140384412035408 [label=ConvolutionBackward0]
	140384412036848 -> 140384412035408
	140384412036848 [label=AvgPool2DBackward0]
	140384412470384 -> 140384412036848
	140384412028016 -> 140384412035408
	140383249408592 [label="model.model.encoder.features.6.branch3.1.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140383249408592 -> 140384412028016
	140384412028016 [label=AccumulateGrad]
	140384412027824 -> 140384412468032
	140383249404992 [label="model.model.encoder.features.6.branch3.1.bn.weight
 (96)" fillcolor=lightblue]
	140383249404992 -> 140384412027824
	140384412027824 [label=AccumulateGrad]
	140384412033248 -> 140384412468032
	140383249415152 [label="model.model.encoder.features.6.branch3.1.bn.bias
 (96)" fillcolor=lightblue]
	140383249415152 -> 140384412033248
	140384412033248 [label=AccumulateGrad]
	140384412471632 -> 140384412469424
	140383249406752 [label="model.model.encoder.features.7.branch0.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140383249406752 -> 140384412471632
	140384412471632 [label=AccumulateGrad]
	140384412473936 -> 140384412469712
	140383249415712 [label="model.model.encoder.features.7.branch0.bn.weight
 (96)" fillcolor=lightblue]
	140383249415712 -> 140384412473936
	140384412473936 [label=AccumulateGrad]
	140384412469040 -> 140384412469712
	140383249402752 [label="model.model.encoder.features.7.branch0.bn.bias
 (96)" fillcolor=lightblue]
	140383249402752 -> 140384412469040
	140384412469040 [label=AccumulateGrad]
	140384412474512 -> 140384412474128
	140384412474512 [label=ReluBackward0]
	140384412476720 -> 140384412474512
	140384412476720 [label=CudnnBatchNormBackward0]
	140384412483152 -> 140384412476720
	140384412483152 [label=ConvolutionBackward0]
	140384412035360 -> 140384412483152
	140384412035360 [label=ReluBackward0]
	140384412028256 -> 140384412035360
	140384412028256 [label=CudnnBatchNormBackward0]
	140384412028208 -> 140384412028256
	140384412028208 [label=ConvolutionBackward0]
	140384412469184 -> 140384412028208
	140384412036992 -> 140384412028208
	140383249407952 [label="model.model.encoder.features.7.branch1.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140383249407952 -> 140384412036992
	140384412036992 [label=AccumulateGrad]
	140384412033680 -> 140384412028256
	140383249406432 [label="model.model.encoder.features.7.branch1.0.bn.weight
 (64)" fillcolor=lightblue]
	140383249406432 -> 140384412033680
	140384412033680 [label=AccumulateGrad]
	140384412040448 -> 140384412028256
	140383249412832 [label="model.model.encoder.features.7.branch1.0.bn.bias
 (64)" fillcolor=lightblue]
	140383249412832 -> 140384412040448
	140384412040448 [label=AccumulateGrad]
	140384412028400 -> 140384412483152
	140383249412032 [label="model.model.encoder.features.7.branch1.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140383249412032 -> 140384412028400
	140384412028400 [label=AccumulateGrad]
	140384412477200 -> 140384412476720
	140383249413472 [label="model.model.encoder.features.7.branch1.1.bn.weight
 (96)" fillcolor=lightblue]
	140383249413472 -> 140384412477200
	140384412477200 [label=AccumulateGrad]
	140384412034448 -> 140384412476720
	140383249414752 [label="model.model.encoder.features.7.branch1.1.bn.bias
 (96)" fillcolor=lightblue]
	140383249414752 -> 140384412034448
	140384412034448 [label=AccumulateGrad]
	140384412472592 -> 140384412474128
	140384412472592 [label=ReluBackward0]
	140384412476048 -> 140384412472592
	140384412476048 [label=CudnnBatchNormBackward0]
	140384412036896 -> 140384412476048
	140384412036896 [label=ConvolutionBackward0]
	140384412027296 -> 140384412036896
	140384412027296 [label=ReluBackward0]
	140384412028976 -> 140384412027296
	140384412028976 [label=CudnnBatchNormBackward0]
	140384412028304 -> 140384412028976
	140384412028304 [label=ConvolutionBackward0]
	140384412033104 -> 140384412028304
	140384412033104 [label=ReluBackward0]
	140384412036560 -> 140384412033104
	140384412036560 [label=CudnnBatchNormBackward0]
	140384412033056 -> 140384412036560
	140384412033056 [label=ConvolutionBackward0]
	140384412469184 -> 140384412033056
	140384412026816 -> 140384412033056
	140383249407792 [label="model.model.encoder.features.7.branch2.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140383249407792 -> 140384412026816
	140384412026816 [label=AccumulateGrad]
	140384412041120 -> 140384412036560
	140383249403632 [label="model.model.encoder.features.7.branch2.0.bn.weight
 (64)" fillcolor=lightblue]
	140383249403632 -> 140384412041120
	140384412041120 [label=AccumulateGrad]
	140384412026624 -> 140384412036560
	140383249403552 [label="model.model.encoder.features.7.branch2.0.bn.bias
 (64)" fillcolor=lightblue]
	140383249403552 -> 140384412026624
	140384412026624 [label=AccumulateGrad]
	140384412029024 -> 140384412028304
	140383249403072 [label="model.model.encoder.features.7.branch2.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140383249403072 -> 140384412029024
	140384412029024 [label=AccumulateGrad]
	140384412030416 -> 140384412028976
	140383249402592 [label="model.model.encoder.features.7.branch2.1.bn.weight
 (96)" fillcolor=lightblue]
	140383249402592 -> 140384412030416
	140384412030416 [label=AccumulateGrad]
	140384412033200 -> 140384412028976
	140383249402512 [label="model.model.encoder.features.7.branch2.1.bn.bias
 (96)" fillcolor=lightblue]
	140383249402512 -> 140384412033200
	140384412033200 [label=AccumulateGrad]
	140384412038672 -> 140384412036896
	140384412167728 [label="model.model.encoder.features.7.branch2.2.conv.weight
 (96, 96, 3, 3)" fillcolor=lightblue]
	140384412167728 -> 140384412038672
	140384412038672 [label=AccumulateGrad]
	140384412039968 -> 140384412476048
	140384412160448 [label="model.model.encoder.features.7.branch2.2.bn.weight
 (96)" fillcolor=lightblue]
	140384412160448 -> 140384412039968
	140384412039968 [label=AccumulateGrad]
	140384412037952 -> 140384412476048
	140383624728784 [label="model.model.encoder.features.7.branch2.2.bn.bias
 (96)" fillcolor=lightblue]
	140383624728784 -> 140384412037952
	140384412037952 [label=AccumulateGrad]
	140384412469520 -> 140384412474128
	140384412469520 [label=ReluBackward0]
	140384412028880 -> 140384412469520
	140384412028880 [label=CudnnBatchNormBackward0]
	140384412028448 -> 140384412028880
	140384412028448 [label=ConvolutionBackward0]
	140384412027584 -> 140384412028448
	140384412027584 [label=AvgPool2DBackward0]
	140384412469184 -> 140384412027584
	140384412039296 -> 140384412028448
	140384426384000 [label="model.model.encoder.features.7.branch3.1.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140384426384000 -> 140384412039296
	140384412039296 [label=AccumulateGrad]
	140384412037328 -> 140384412028880
	140384426388960 [label="model.model.encoder.features.7.branch3.1.bn.weight
 (96)" fillcolor=lightblue]
	140384426388960 -> 140384412037328
	140384412037328 [label=AccumulateGrad]
	140384412036416 -> 140384412028880
	140384426381120 [label="model.model.encoder.features.7.branch3.1.bn.bias
 (96)" fillcolor=lightblue]
	140384426381120 -> 140384412036416
	140384412036416 [label=AccumulateGrad]
	140384412472640 -> 140384412421616
	140384412297600 [label="model.model.encoder.features.8.branch0.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140384412297600 -> 140384412472640
	140384412472640 [label=AccumulateGrad]
	140384412475040 -> 140384412424928
	140384412294400 [label="model.model.encoder.features.8.branch0.bn.weight
 (96)" fillcolor=lightblue]
	140384412294400 -> 140384412475040
	140384412475040 [label=AccumulateGrad]
	140384412467552 -> 140384412424928
	140384412291520 [label="model.model.encoder.features.8.branch0.bn.bias
 (96)" fillcolor=lightblue]
	140384412291520 -> 140384412467552
	140384412467552 [label=AccumulateGrad]
	140384412427232 -> 140383267769984
	140384412427232 [label=ReluBackward0]
	140384412421472 -> 140384412427232
	140384412421472 [label=CudnnBatchNormBackward0]
	140384412474320 -> 140384412421472
	140384412474320 [label=ConvolutionBackward0]
	140384412039200 -> 140384412474320
	140384412039200 [label=ReluBackward0]
	140384412031616 -> 140384412039200
	140384412031616 [label=CudnnBatchNormBackward0]
	140384412038240 -> 140384412031616
	140384412038240 [label=ConvolutionBackward0]
	140384412474128 -> 140384412038240
	140384412036368 -> 140384412038240
	140384412288880 [label="model.model.encoder.features.8.branch1.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140384412288880 -> 140384412036368
	140384412036368 [label=AccumulateGrad]
	140384412037376 -> 140384412031616
	140384412288800 [label="model.model.encoder.features.8.branch1.0.bn.weight
 (64)" fillcolor=lightblue]
	140384412288800 -> 140384412037376
	140384412037376 [label=AccumulateGrad]
	140384412025616 -> 140384412031616
	140384412288560 [label="model.model.encoder.features.8.branch1.0.bn.bias
 (64)" fillcolor=lightblue]
	140384412288560 -> 140384412025616
	140384412025616 [label=AccumulateGrad]
	140384412040544 -> 140384412474320
	140384412303120 [label="model.model.encoder.features.8.branch1.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412303120 -> 140384412040544
	140384412040544 [label=AccumulateGrad]
	140384412474176 -> 140384412421472
	140384412292000 [label="model.model.encoder.features.8.branch1.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412292000 -> 140384412474176
	140384412474176 [label=AccumulateGrad]
	140384412036656 -> 140384412421472
	140384412289040 [label="model.model.encoder.features.8.branch1.1.bn.bias
 (96)" fillcolor=lightblue]
	140384412289040 -> 140384412036656
	140384412036656 [label=AccumulateGrad]
	140384412422336 -> 140383267769984
	140384412422336 [label=ReluBackward0]
	140384412471200 -> 140384412422336
	140384412471200 [label=CudnnBatchNormBackward0]
	140384412036512 -> 140384412471200
	140384412036512 [label=ConvolutionBackward0]
	140384412035984 -> 140384412036512
	140384412035984 [label=ReluBackward0]
	140384412038432 -> 140384412035984
	140384412038432 [label=CudnnBatchNormBackward0]
	140384412040976 -> 140384412038432
	140384412040976 [label=ConvolutionBackward0]
	140384412034064 -> 140384412040976
	140384412034064 [label=ReluBackward0]
	140384412036128 -> 140384412034064
	140384412036128 [label=CudnnBatchNormBackward0]
	140384412040640 -> 140384412036128
	140384412040640 [label=ConvolutionBackward0]
	140384412474128 -> 140384412040640
	140384412037184 -> 140384412040640
	140384412294000 [label="model.model.encoder.features.8.branch2.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140384412294000 -> 140384412037184
	140384412037184 [label=AccumulateGrad]
	140384412040304 -> 140384412036128
	140384412296160 [label="model.model.encoder.features.8.branch2.0.bn.weight
 (64)" fillcolor=lightblue]
	140384412296160 -> 140384412040304
	140384412040304 [label=AccumulateGrad]
	140384412033440 -> 140384412036128
	140384412293920 [label="model.model.encoder.features.8.branch2.0.bn.bias
 (64)" fillcolor=lightblue]
	140384412293920 -> 140384412033440
	140384412033440 [label=AccumulateGrad]
	140384412034784 -> 140384412040976
	140384412297680 [label="model.model.encoder.features.8.branch2.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412297680 -> 140384412034784
	140384412034784 [label=AccumulateGrad]
	140384412031040 -> 140384412038432
	140384412296320 [label="model.model.encoder.features.8.branch2.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412296320 -> 140384412031040
	140384412031040 [label=AccumulateGrad]
	140384412035168 -> 140384412038432
	140384412300160 [label="model.model.encoder.features.8.branch2.1.bn.bias
 (96)" fillcolor=lightblue]
	140384412300160 -> 140384412035168
	140384412035168 [label=AccumulateGrad]
	140384412039872 -> 140384412036512
	140384412302880 [label="model.model.encoder.features.8.branch2.2.conv.weight
 (96, 96, 3, 3)" fillcolor=lightblue]
	140384412302880 -> 140384412039872
	140384412039872 [label=AccumulateGrad]
	140384412032240 -> 140384412471200
	140384412289120 [label="model.model.encoder.features.8.branch2.2.bn.weight
 (96)" fillcolor=lightblue]
	140384412289120 -> 140384412032240
	140384412032240 [label=AccumulateGrad]
	140384412035216 -> 140384412471200
	140384412302080 [label="model.model.encoder.features.8.branch2.2.bn.bias
 (96)" fillcolor=lightblue]
	140384412302080 -> 140384412035216
	140384412035216 [label=AccumulateGrad]
	140384412426512 -> 140383267769984
	140384412426512 [label=ReluBackward0]
	140384412035744 -> 140384412426512
	140384412035744 [label=CudnnBatchNormBackward0]
	140384412035264 -> 140384412035744
	140384412035264 [label=ConvolutionBackward0]
	140384412033488 -> 140384412035264
	140384412033488 [label=AvgPool2DBackward0]
	140384412474128 -> 140384412033488
	140384412031856 -> 140384412035264
	140384412297920 [label="model.model.encoder.features.8.branch3.1.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140384412297920 -> 140384412031856
	140384412031856 [label=AccumulateGrad]
	140384412039680 -> 140384412035744
	140384412299360 [label="model.model.encoder.features.8.branch3.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412299360 -> 140384412039680
	140384412039680 [label=AccumulateGrad]
	140384412024896 -> 140384412035744
	140384412299440 [label="model.model.encoder.features.8.branch3.1.bn.bias
 (96)" fillcolor=lightblue]
	140384412299440 -> 140384412024896
	140384412024896 [label=AccumulateGrad]
	140384412422960 -> 140384412422048
	140384412288240 [label="model.model.encoder.features.9.branch0.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140384412288240 -> 140384412422960
	140384412422960 [label=AccumulateGrad]
	140384412428432 -> 140384412425072
	140384412287440 [label="model.model.encoder.features.9.branch0.bn.weight
 (96)" fillcolor=lightblue]
	140384412287440 -> 140384412428432
	140384412428432 [label=AccumulateGrad]
	140384412431168 -> 140384412425072
	140384412289200 [label="model.model.encoder.features.9.branch0.bn.bias
 (96)" fillcolor=lightblue]
	140384412289200 -> 140384412431168
	140384412431168 [label=AccumulateGrad]
	140384412433232 -> 140384036339232
	140384412433232 [label=ReluBackward0]
	140384412425600 -> 140384412433232
	140384412425600 [label=CudnnBatchNormBackward0]
	140384412422192 -> 140384412425600
	140384412422192 [label=ConvolutionBackward0]
	140384412032528 -> 140384412422192
	140384412032528 [label=ReluBackward0]
	140384412035120 -> 140384412032528
	140384412035120 [label=CudnnBatchNormBackward0]
	140384412034976 -> 140384412035120
	140384412034976 [label=ConvolutionBackward0]
	140383267769984 -> 140384412034976
	140384412032720 -> 140384412034976
	140384412290800 [label="model.model.encoder.features.9.branch1.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140384412290800 -> 140384412032720
	140384412032720 [label=AccumulateGrad]
	140384412027776 -> 140384412035120
	140384412290560 [label="model.model.encoder.features.9.branch1.0.bn.weight
 (64)" fillcolor=lightblue]
	140384412290560 -> 140384412027776
	140384412027776 [label=AccumulateGrad]
	140384412039728 -> 140384412035120
	140384412290160 [label="model.model.encoder.features.9.branch1.0.bn.bias
 (64)" fillcolor=lightblue]
	140384412290160 -> 140384412039728
	140384412039728 [label=AccumulateGrad]
	140384412035696 -> 140384412422192
	140384412292080 [label="model.model.encoder.features.9.branch1.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412292080 -> 140384412035696
	140384412035696 [label=AccumulateGrad]
	140384412433088 -> 140384412425600
	140384412290480 [label="model.model.encoder.features.9.branch1.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412290480 -> 140384412433088
	140384412433088 [label=AccumulateGrad]
	140384412035936 -> 140384412425600
	140384412293840 [label="model.model.encoder.features.9.branch1.1.bn.bias
 (96)" fillcolor=lightblue]
	140384412293840 -> 140384412035936
	140384412035936 [label=AccumulateGrad]
	140384412421232 -> 140384036339232
	140384412421232 [label=ReluBackward0]
	140384412422000 -> 140384412421232
	140384412422000 [label=CudnnBatchNormBackward0]
	140384412030176 -> 140384412422000
	140384412030176 [label=ConvolutionBackward0]
	140384412030368 -> 140384412030176
	140384412030368 [label=ReluBackward0]
	140384412035072 -> 140384412030368
	140384412035072 [label=CudnnBatchNormBackward0]
	140384412026048 -> 140384412035072
	140384412026048 [label=ConvolutionBackward0]
	140384412025184 -> 140384412026048
	140384412025184 [label=ReluBackward0]
	140384412032960 -> 140384412025184
	140384412032960 [label=CudnnBatchNormBackward0]
	140384412031472 -> 140384412032960
	140384412031472 [label=ConvolutionBackward0]
	140383267769984 -> 140384412031472
	140384412036608 -> 140384412031472
	140384412289280 [label="model.model.encoder.features.9.branch2.0.conv.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140384412289280 -> 140384412036608
	140384412036608 [label=AccumulateGrad]
	140384412026480 -> 140384412032960
	140384412287360 [label="model.model.encoder.features.9.branch2.0.bn.weight
 (64)" fillcolor=lightblue]
	140384412287360 -> 140384412026480
	140384412026480 [label=AccumulateGrad]
	140384412025280 -> 140384412032960
	140384412300400 [label="model.model.encoder.features.9.branch2.0.bn.bias
 (64)" fillcolor=lightblue]
	140384412300400 -> 140384412025280
	140384412025280 [label=AccumulateGrad]
	140384412025952 -> 140384412026048
	140384412294720 [label="model.model.encoder.features.9.branch2.1.conv.weight
 (96, 64, 3, 3)" fillcolor=lightblue]
	140384412294720 -> 140384412025952
	140384412025952 [label=AccumulateGrad]
	140384412031808 -> 140384412035072
	140384412294480 [label="model.model.encoder.features.9.branch2.1.bn.weight
 (96)" fillcolor=lightblue]
	140384412294480 -> 140384412031808
	140384412031808 [label=AccumulateGrad]
	140384412037664 -> 140384412035072
	140384427103776 [label="model.model.encoder.features.9.branch2.1.bn.bias
 (96)" fillcolor=lightblue]
	140384427103776 -> 140384412037664
	140384412037664 [label=AccumulateGrad]
	140384412037520 -> 140384412030176
	140384427105056 [label="model.model.encoder.features.9.branch2.2.conv.weight
 (96, 96, 3, 3)" fillcolor=lightblue]
	140384427105056 -> 140384412037520
	140384412037520 [label=AccumulateGrad]
	140384412029840 -> 140384412422000
	140384427105696 [label="model.model.encoder.features.9.branch2.2.bn.weight
 (96)" fillcolor=lightblue]
	140384427105696 -> 140384412029840
	140384412029840 [label=AccumulateGrad]
	140384412033152 -> 140384412422000
	140384427104976 [label="model.model.encoder.features.9.branch2.2.bn.bias
 (96)" fillcolor=lightblue]
	140384427104976 -> 140384412033152
	140384412033152 [label=AccumulateGrad]
	140384412433616 -> 140384036339232
	140384412433616 [label=ReluBackward0]
	140384412027728 -> 140384412433616
	140384412027728 [label=CudnnBatchNormBackward0]
	140384412028592 -> 140384412027728
	140384412028592 [label=ConvolutionBackward0]
	140384412028784 -> 140384412028592
	140384412028784 [label=AvgPool2DBackward0]
	140383267769984 -> 140384412028784
	140384412038336 -> 140384412028592
	140384427104496 [label="model.model.encoder.features.9.branch3.1.conv.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140384427104496 -> 140384412038336
	140384412038336 [label=AccumulateGrad]
	140384412025904 -> 140384412027728
	140384427107616 [label="model.model.encoder.features.9.branch3.1.bn.weight
 (96)" fillcolor=lightblue]
	140384427107616 -> 140384412025904
	140384412025904 [label=AccumulateGrad]
	140384412036464 -> 140384412027728
	140384427107456 [label="model.model.encoder.features.9.branch3.1.bn.bias
 (96)" fillcolor=lightblue]
	140384427107456 -> 140384412036464
	140384412036464 [label=AccumulateGrad]
	140384036338752 -> 140384036339424
	140384427106656 [label="model.model.encoder.features.10.branch0.conv.weight
 (384, 384, 3, 3)" fillcolor=lightblue]
	140384427106656 -> 140384036338752
	140384036338752 [label=AccumulateGrad]
	140384036338704 -> 140384036334576
	140384427106816 [label="model.model.encoder.features.10.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140384427106816 -> 140384036338704
	140384036338704 [label=AccumulateGrad]
	140384036334384 -> 140384036334576
	140384427106416 [label="model.model.encoder.features.10.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384427106416 -> 140384036334384
	140384036334384 [label=AccumulateGrad]
	140384036334048 -> 140384036338224
	140384036334048 [label=ReluBackward0]
	140384036334864 -> 140384036334048
	140384036334864 [label=CudnnBatchNormBackward0]
	140384412433664 -> 140384036334864
	140384412433664 [label=ConvolutionBackward0]
	140384412034352 -> 140384412433664
	140384412034352 [label=ReluBackward0]
	140384412039632 -> 140384412034352
	140384412039632 [label=CudnnBatchNormBackward0]
	140384412038624 -> 140384412039632
	140384412038624 [label=ConvolutionBackward0]
	140384412025088 -> 140384412038624
	140384412025088 [label=ReluBackward0]
	140384412028160 -> 140384412025088
	140384412028160 [label=CudnnBatchNormBackward0]
	140384412029264 -> 140384412028160
	140384412029264 [label=ConvolutionBackward0]
	140384036339232 -> 140384412029264
	140384412030128 -> 140384412029264
	140384427108896 [label="model.model.encoder.features.10.branch1.0.conv.weight
 (192, 384, 1, 1)" fillcolor=lightblue]
	140384427108896 -> 140384412030128
	140384412030128 [label=AccumulateGrad]
	140384412026672 -> 140384412028160
	140384427108576 [label="model.model.encoder.features.10.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384427108576 -> 140384412026672
	140384412026672 [label=AccumulateGrad]
	140384412028112 -> 140384412028160
	140384427108336 [label="model.model.encoder.features.10.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384427108336 -> 140384412028112
	140384412028112 [label=AccumulateGrad]
	140384412027248 -> 140384412038624
	140384427109536 [label="model.model.encoder.features.10.branch1.1.conv.weight
 (224, 192, 3, 3)" fillcolor=lightblue]
	140384427109536 -> 140384412027248
	140384412027248 [label=AccumulateGrad]
	140384412034256 -> 140384412039632
	140384427109616 [label="model.model.encoder.features.10.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384427109616 -> 140384412034256
	140384412034256 [label=AccumulateGrad]
	140384412029168 -> 140384412039632
	140384427109856 [label="model.model.encoder.features.10.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384427109856 -> 140384412029168
	140384412029168 [label=AccumulateGrad]
	140384412040208 -> 140384412433664
	140384427110576 [label="model.model.encoder.features.10.branch1.2.conv.weight
 (256, 224, 3, 3)" fillcolor=lightblue]
	140384427110576 -> 140384412040208
	140384412040208 [label=AccumulateGrad]
	140384036334816 -> 140384036334864
	140384427107696 [label="model.model.encoder.features.10.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384427107696 -> 140384036334816
	140384036334816 [label=AccumulateGrad]
	140384412031280 -> 140384036334864
	140384427107536 [label="model.model.encoder.features.10.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384427107536 -> 140384412031280
	140384412031280 [label=AccumulateGrad]
	140384036339184 -> 140384036338224
	140384036339184 [label=MaxPool2DWithIndicesBackward0]
	140384036339232 -> 140384036339184
	140384036335200 -> 140384036337936
	140383249404352 [label="model.model.encoder.features.11.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140383249404352 -> 140384036335200
	140384036335200 [label=AccumulateGrad]
	140384036334480 -> 140384036338176
	140383249404272 [label="model.model.encoder.features.11.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140383249404272 -> 140384036334480
	140384036334480 [label=AccumulateGrad]
	140384036336928 -> 140384036338176
	140384427109456 [label="model.model.encoder.features.11.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384427109456 -> 140384036336928
	140384036336928 [label=AccumulateGrad]
	140384036338560 -> 140384036338080
	140384036338560 [label=ReluBackward0]
	140384036334144 -> 140384036338560
	140384036334144 [label=CudnnBatchNormBackward0]
	140384036335008 -> 140384036334144
	140384036335008 [label=ConvolutionBackward0]
	140384412034592 -> 140384036335008
	140384412034592 [label=ReluBackward0]
	140384412024944 -> 140384412034592
	140384412024944 [label=CudnnBatchNormBackward0]
	140384412034496 -> 140384412024944
	140384412034496 [label=ConvolutionBackward0]
	140384412040160 -> 140384412034496
	140384412040160 [label=ReluBackward0]
	140384412036944 -> 140384412040160
	140384412036944 [label=CudnnBatchNormBackward0]
	140384412031136 -> 140384412036944
	140384412031136 [label=ConvolutionBackward0]
	140384036338224 -> 140384412031136
	140384412031424 -> 140384412031136
	140384427111856 [label="model.model.encoder.features.11.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384427111856 -> 140384412031424
	140384412031424 [label=AccumulateGrad]
	140384412036080 -> 140384412036944
	140384427111776 [label="model.model.encoder.features.11.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384427111776 -> 140384412036080
	140384412036080 [label=AccumulateGrad]
	140384412037568 -> 140384412036944
	140384427111536 [label="model.model.encoder.features.11.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384427111536 -> 140384412037568
	140384412037568 [label=AccumulateGrad]
	140384412039440 -> 140384412034496
	140384427111376 [label="model.model.encoder.features.11.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384427111376 -> 140384412039440
	140384412039440 [label=AccumulateGrad]
	140384412026960 -> 140384412024944
	140384427112816 [label="model.model.encoder.features.11.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384427112816 -> 140384412026960
	140384412026960 [label=AccumulateGrad]
	140384412037040 -> 140384412024944
	140384427112656 [label="model.model.encoder.features.11.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384427112656 -> 140384412037040
	140384412037040 [label=AccumulateGrad]
	140384412038144 -> 140384036335008
	140384427112176 [label="model.model.encoder.features.11.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140384427112176 -> 140384412038144
	140384412038144 [label=AccumulateGrad]
	140384036334720 -> 140384036334144
	140384427113856 [label="model.model.encoder.features.11.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384427113856 -> 140384036334720
	140384036334720 [label=AccumulateGrad]
	140384412037136 -> 140384036334144
	140384427113376 [label="model.model.encoder.features.11.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384427113376 -> 140384412037136
	140384412037136 [label=AccumulateGrad]
	140384036336352 -> 140384036338080
	140384036336352 [label=ReluBackward0]
	140384036333664 -> 140384036336352
	140384036333664 [label=CudnnBatchNormBackward0]
	140384412032144 -> 140384036333664
	140384412032144 [label=ConvolutionBackward0]
	140384412040400 -> 140384412032144
	140384412040400 [label=ReluBackward0]
	140384412034640 -> 140384412040400
	140384412034640 [label=CudnnBatchNormBackward0]
	140384412038192 -> 140384412034640
	140384412038192 [label=ConvolutionBackward0]
	140384412039536 -> 140384412038192
	140384412039536 [label=ReluBackward0]
	140384412030608 -> 140384412039536
	140384412030608 [label=CudnnBatchNormBackward0]
	140384412027344 -> 140384412030608
	140384412027344 [label=ConvolutionBackward0]
	140384412025328 -> 140384412027344
	140384412025328 [label=ReluBackward0]
	140384038058448 -> 140384412025328
	140384038058448 [label=CudnnBatchNormBackward0]
	140384412621776 -> 140384038058448
	140384412621776 [label=ConvolutionBackward0]
	140384412616352 -> 140384412621776
	140384412616352 [label=ReluBackward0]
	140384412623696 -> 140384412616352
	140384412623696 [label=CudnnBatchNormBackward0]
	140384412620288 -> 140384412623696
	140384412620288 [label=ConvolutionBackward0]
	140384036338224 -> 140384412620288
	140384412626960 -> 140384412620288
	140384427114176 [label="model.model.encoder.features.11.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384427114176 -> 140384412626960
	140384412626960 [label=AccumulateGrad]
	140384412624320 -> 140384412623696
	140384427113216 [label="model.model.encoder.features.11.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140384427113216 -> 140384412624320
	140384412624320 [label=AccumulateGrad]
	140384412616448 -> 140384412623696
	140384427114336 [label="model.model.encoder.features.11.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140384427114336 -> 140384412616448
	140384412616448 [label=AccumulateGrad]
	140384412618176 -> 140384412621776
	140384427103296 [label="model.model.encoder.features.11.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140384427103296 -> 140384412618176
	140384412618176 [label=AccumulateGrad]
	140384412618656 -> 140384038058448
	140384427113696 [label="model.model.encoder.features.11.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140384427113696 -> 140384412618656
	140384412618656 [label=AccumulateGrad]
	140384412619568 -> 140384038058448
	140384427104656 [label="model.model.encoder.features.11.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140384427104656 -> 140384412619568
	140384412619568 [label=AccumulateGrad]
	140384412025472 -> 140384412027344
	140384427112016 [label="model.model.encoder.features.11.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384427112016 -> 140384412025472
	140384412025472 [label=AccumulateGrad]
	140384412027104 -> 140384412030608
	140384427111296 [label="model.model.encoder.features.11.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140384427111296 -> 140384412027104
	140384412027104 [label=AccumulateGrad]
	140384412033008 -> 140384412030608
	140384427102096 [label="model.model.encoder.features.11.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140384427102096 -> 140384412033008
	140384412033008 [label=AccumulateGrad]
	140384412031520 -> 140384412038192
	140384427098896 [label="model.model.encoder.features.11.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140384427098896 -> 140384412031520
	140384412031520 [label=AccumulateGrad]
	140384412040112 -> 140384412034640
	140384427107776 [label="model.model.encoder.features.11.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140384427107776 -> 140384412040112
	140384412040112 [label=AccumulateGrad]
	140384412039584 -> 140384412034640
	140384427100096 [label="model.model.encoder.features.11.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140384427100096 -> 140384412039584
	140384412039584 [label=AccumulateGrad]
	140384412035792 -> 140384412032144
	140384427110416 [label="model.model.encoder.features.11.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140384427110416 -> 140384412035792
	140384412035792 [label=AccumulateGrad]
	140384412032336 -> 140384036333664
	140384427109696 [label="model.model.encoder.features.11.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140384427109696 -> 140384412032336
	140384412032336 [label=AccumulateGrad]
	140384412034928 -> 140384036333664
	140384427109056 [label="model.model.encoder.features.11.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140384427109056 -> 140384412034928
	140384412034928 [label=AccumulateGrad]
	140384036334336 -> 140384036338080
	140384036334336 [label=ReluBackward0]
	140384038057488 -> 140384036334336
	140384038057488 [label=CudnnBatchNormBackward0]
	140384412037856 -> 140384038057488
	140384412037856 [label=ConvolutionBackward0]
	140384412032432 -> 140384412037856
	140384412032432 [label=AvgPool2DBackward0]
	140384036338224 -> 140384412032432
	140384412025856 -> 140384412037856
	140384427110336 [label="model.model.encoder.features.11.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140384427110336 -> 140384412025856
	140384412025856 [label=AccumulateGrad]
	140384412035024 -> 140384038057488
	140384427104016 [label="model.model.encoder.features.11.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140384427104016 -> 140384412035024
	140384412035024 [label=AccumulateGrad]
	140384412026384 -> 140384038057488
	140384427108416 [label="model.model.encoder.features.11.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140384427108416 -> 140384412026384
	140384412026384 [label=AccumulateGrad]
	140384036339568 -> 140384036338032
	140384427103376 [label="model.model.encoder.features.12.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140384427103376 -> 140384036339568
	140384036339568 [label=AccumulateGrad]
	140384036337888 -> 140384036338464
	140384427102736 [label="model.model.encoder.features.12.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140384427102736 -> 140384036337888
	140384036337888 [label=AccumulateGrad]
	140384036338368 -> 140384036338464
	140384427102016 [label="model.model.encoder.features.12.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384427102016 -> 140384036338368
	140384036338368 [label=AccumulateGrad]
	140383267782224 -> 140383267781936
	140383267782224 [label=ReluBackward0]
	140384036336208 -> 140383267782224
	140384036336208 [label=CudnnBatchNormBackward0]
	140384036339616 -> 140384036336208
	140384036339616 [label=ConvolutionBackward0]
	140384412036032 -> 140384036339616
	140384412036032 [label=ReluBackward0]
	140384412626576 -> 140384412036032
	140384412626576 [label=CudnnBatchNormBackward0]
	140384412614816 -> 140384412626576
	140384412614816 [label=ConvolutionBackward0]
	140384412629792 -> 140384412614816
	140384412629792 [label=ReluBackward0]
	140384412628496 -> 140384412629792
	140384412628496 [label=CudnnBatchNormBackward0]
	140384412619424 -> 140384412628496
	140384412619424 [label=ConvolutionBackward0]
	140384036338080 -> 140384412619424
	140384412625376 -> 140384412619424
	140384427099456 [label="model.model.encoder.features.12.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384427099456 -> 140384412625376
	140384412625376 [label=AccumulateGrad]
	140384412615008 -> 140384412628496
	140384427100736 [label="model.model.encoder.features.12.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384427100736 -> 140384412615008
	140384412615008 [label=AccumulateGrad]
	140384412628064 -> 140384412628496
	140384427098816 [label="model.model.encoder.features.12.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384427098816 -> 140384412628064
	140384412628064 [label=AccumulateGrad]
	140384412622736 -> 140384412614816
	140384427099616 [label="model.model.encoder.features.12.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384427099616 -> 140384412622736
	140384412622736 [label=AccumulateGrad]
	140384412617936 -> 140384412626576
	140384427101216 [label="model.model.encoder.features.12.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384427101216 -> 140384412617936
	140384412617936 [label=AccumulateGrad]
	140384412624464 -> 140384412626576
	140384427101296 [label="model.model.encoder.features.12.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384427101296 -> 140384412624464
	140384412624464 [label=AccumulateGrad]
	140384412615920 -> 140384036339616
	140384427103616 [label="model.model.encoder.features.12.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140384427103616 -> 140384412615920
	140384412615920 [label=AccumulateGrad]
	140384036334528 -> 140384036336208
	140384427103536 [label="model.model.encoder.features.12.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384427103536 -> 140384036334528
	140384036334528 [label=AccumulateGrad]
	140384412033968 -> 140384036336208
	140384427102976 [label="model.model.encoder.features.12.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384427102976 -> 140384412033968
	140384412033968 [label=AccumulateGrad]
	140383267782080 -> 140383267781936
	140383267782080 [label=ReluBackward0]
	140384412031664 -> 140383267782080
	140384412031664 [label=CudnnBatchNormBackward0]
	140384412627632 -> 140384412031664
	140384412627632 [label=ConvolutionBackward0]
	140384412626768 -> 140384412627632
	140384412626768 [label=ReluBackward0]
	140384412614768 -> 140384412626768
	140384412614768 [label=CudnnBatchNormBackward0]
	140384412621056 -> 140384412614768
	140384412621056 [label=ConvolutionBackward0]
	140384412624752 -> 140384412621056
	140384412624752 [label=ReluBackward0]
	140384412622496 -> 140384412624752
	140384412622496 [label=CudnnBatchNormBackward0]
	140384412630320 -> 140384412622496
	140384412630320 [label=ConvolutionBackward0]
	140384412617408 -> 140384412630320
	140384412617408 [label=ReluBackward0]
	140384412626192 -> 140384412617408
	140384412626192 [label=CudnnBatchNormBackward0]
	140384412624272 -> 140384412626192
	140384412624272 [label=ConvolutionBackward0]
	140384412615200 -> 140384412624272
	140384412615200 [label=ReluBackward0]
	140384412624800 -> 140384412615200
	140384412624800 [label=CudnnBatchNormBackward0]
	140384412621200 -> 140384412624800
	140384412621200 [label=ConvolutionBackward0]
	140384036338080 -> 140384412621200
	140384038355632 -> 140384412621200
	140384427101776 [label="model.model.encoder.features.12.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384427101776 -> 140384038355632
	140384038355632 [label=AccumulateGrad]
	140384412623648 -> 140384412624800
	140384427102336 [label="model.model.encoder.features.12.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140384427102336 -> 140384412623648
	140384412623648 [label=AccumulateGrad]
	140384412629312 -> 140384412624800
	140384427101616 [label="model.model.encoder.features.12.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140384427101616 -> 140384412629312
	140384412629312 [label=AccumulateGrad]
	140384412622304 -> 140384412624272
	140384427100336 [label="model.model.encoder.features.12.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140384427100336 -> 140384412622304
	140384412622304 [label=AccumulateGrad]
	140384412617360 -> 140384412626192
	140384427100976 [label="model.model.encoder.features.12.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140384427100976 -> 140384412617360
	140384412617360 [label=AccumulateGrad]
	140384412618128 -> 140384412626192
	140384427099776 [label="model.model.encoder.features.12.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140384427099776 -> 140384412618128
	140384412618128 [label=AccumulateGrad]
	140384412617264 -> 140384412630320
	140384427098496 [label="model.model.encoder.features.12.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384427098496 -> 140384412617264
	140384412617264 [label=AccumulateGrad]
	140384412622064 -> 140384412622496
	140384427099856 [label="model.model.encoder.features.12.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140384427099856 -> 140384412622064
	140384412622064 [label=AccumulateGrad]
	140384412627008 -> 140384412622496
	140384427098416 [label="model.model.encoder.features.12.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140384427098416 -> 140384412627008
	140384412627008 [label=AccumulateGrad]
	140384412614720 -> 140384412621056
	140384427100656 [label="model.model.encoder.features.12.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140384427100656 -> 140384412614720
	140384412614720 [label=AccumulateGrad]
	140384412618560 -> 140384412614768
	140384427100576 [label="model.model.encoder.features.12.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140384427100576 -> 140384412618560
	140384412618560 [label=AccumulateGrad]
	140384412628208 -> 140384412614768
	140384427101936 [label="model.model.encoder.features.12.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140384427101936 -> 140384412628208
	140384412628208 [label=AccumulateGrad]
	140384412617888 -> 140384412627632
	140384424981136 [label="model.model.encoder.features.12.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140384424981136 -> 140384412617888
	140384412617888 [label=AccumulateGrad]
	140384412621680 -> 140384412031664
	140384424981376 [label="model.model.encoder.features.12.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140384424981376 -> 140384412621680
	140384412621680 [label=AccumulateGrad]
	140384412629360 -> 140384412031664
	140384424980736 [label="model.model.encoder.features.12.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140384424980736 -> 140384412629360
	140384412629360 [label=AccumulateGrad]
	140383267782512 -> 140383267781936
	140383267782512 [label=ReluBackward0]
	140384038356304 -> 140383267782512
	140384038356304 [label=CudnnBatchNormBackward0]
	140384412621728 -> 140384038356304
	140384412621728 [label=ConvolutionBackward0]
	140384412623168 -> 140384412621728
	140384412623168 [label=AvgPool2DBackward0]
	140384036338080 -> 140384412623168
	140384412620144 -> 140384412621728
	140384424972576 [label="model.model.encoder.features.12.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140384424972576 -> 140384412620144
	140384412620144 [label=AccumulateGrad]
	140384412626144 -> 140384038356304
	140384424970176 [label="model.model.encoder.features.12.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140384424970176 -> 140384412626144
	140384412626144 [label=AccumulateGrad]
	140384412622448 -> 140384038356304
	140384424984416 [label="model.model.encoder.features.12.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140384424984416 -> 140384412622448
	140384412622448 [label=AccumulateGrad]
	140383267781792 -> 140383267781360
	140384424983776 [label="model.model.encoder.features.13.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140384424983776 -> 140383267781792
	140383267781792 [label=AccumulateGrad]
	140383267781216 -> 140383267781072
	140384424983456 [label="model.model.encoder.features.13.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140384424983456 -> 140383267781216
	140383267781216 [label=AccumulateGrad]
	140383267780784 -> 140383267781072
	140384424982656 [label="model.model.encoder.features.13.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384424982656 -> 140383267780784
	140383267780784 [label=AccumulateGrad]
	140383267780208 -> 140383267779920
	140383267780208 [label=ReluBackward0]
	140383267781648 -> 140383267780208
	140383267781648 [label=CudnnBatchNormBackward0]
	140384036334240 -> 140383267781648
	140384036334240 [label=ConvolutionBackward0]
	140384412625568 -> 140384036334240
	140384412625568 [label=ReluBackward0]
	140384412623600 -> 140384412625568
	140384412623600 [label=CudnnBatchNormBackward0]
	140384412622352 -> 140384412623600
	140384412622352 [label=ConvolutionBackward0]
	140384412454192 -> 140384412622352
	140384412454192 [label=ReluBackward0]
	140384412466000 -> 140384412454192
	140384412466000 [label=CudnnBatchNormBackward0]
	140384412456160 -> 140384412466000
	140384412456160 [label=ConvolutionBackward0]
	140383267781936 -> 140384412456160
	140384412457792 -> 140384412456160
	140384424981536 [label="model.model.encoder.features.13.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384424981536 -> 140384412457792
	140384412457792 [label=AccumulateGrad]
	140384412465904 -> 140384412466000
	140384424981216 [label="model.model.encoder.features.13.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384424981216 -> 140384412465904
	140384412465904 [label=AccumulateGrad]
	140384412465232 -> 140384412466000
	140384424971296 [label="model.model.encoder.features.13.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384424971296 -> 140384412465232
	140384412465232 [label=AccumulateGrad]
	140384412454432 -> 140384412622352
	140384424971136 [label="model.model.encoder.features.13.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384424971136 -> 140384412454432
	140384412454432 [label=AccumulateGrad]
	140384412459280 -> 140384412623600
	140384424980896 [label="model.model.encoder.features.13.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384424980896 -> 140384412459280
	140384412459280 [label=AccumulateGrad]
	140384412462112 -> 140384412623600
	140384424978416 [label="model.model.encoder.features.13.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384424978416 -> 140384412462112
	140384412462112 [label=AccumulateGrad]
	140384412627584 -> 140384036334240
	140384424973856 [label="model.model.encoder.features.13.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140384424973856 -> 140384412627584
	140384412627584 [label=AccumulateGrad]
	140384036339376 -> 140383267781648
	140384424976336 [label="model.model.encoder.features.13.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384424976336 -> 140384036339376
	140384036339376 [label=AccumulateGrad]
	140383267780928 -> 140383267781648
	140384424971376 [label="model.model.encoder.features.13.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384424971376 -> 140383267780928
	140383267780928 [label=AccumulateGrad]
	140383267780064 -> 140383267779920
	140383267780064 [label=ReluBackward0]
	140383267781504 -> 140383267780064
	140383267781504 [label=CudnnBatchNormBackward0]
	140384412625424 -> 140383267781504
	140384412625424 [label=ConvolutionBackward0]
	140384412465136 -> 140384412625424
	140384412465136 [label=ReluBackward0]
	140384412461344 -> 140384412465136
	140384412461344 [label=CudnnBatchNormBackward0]
	140384412458656 -> 140384412461344
	140384412458656 [label=ConvolutionBackward0]
	140384412455056 -> 140384412458656
	140384412455056 [label=ReluBackward0]
	140384412455488 -> 140384412455056
	140384412455488 [label=CudnnBatchNormBackward0]
	140384412461920 -> 140384412455488
	140384412461920 [label=ConvolutionBackward0]
	140384412459616 -> 140384412461920
	140384412459616 [label=ReluBackward0]
	140384412458800 -> 140384412459616
	140384412458800 [label=CudnnBatchNormBackward0]
	140384412463216 -> 140384412458800
	140384412463216 [label=ConvolutionBackward0]
	140384412452800 -> 140384412463216
	140384412452800 [label=ReluBackward0]
	140384412464656 -> 140384412452800
	140384412464656 [label=CudnnBatchNormBackward0]
	140384412459088 -> 140384412464656
	140384412459088 [label=ConvolutionBackward0]
	140383267781936 -> 140384412459088
	140384412458272 -> 140384412459088
	140384424975856 [label="model.model.encoder.features.13.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384424975856 -> 140384412458272
	140384412458272 [label=AccumulateGrad]
	140384412465616 -> 140384412464656
	140384424971616 [label="model.model.encoder.features.13.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140384424971616 -> 140384412465616
	140384412465616 [label=AccumulateGrad]
	140384412462688 -> 140384412464656
	140384424982576 [label="model.model.encoder.features.13.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140384424982576 -> 140384412462688
	140384412462688 [label=AccumulateGrad]
	140384412462448 -> 140384412463216
	140384426035536 [label="model.model.encoder.features.13.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140384426035536 -> 140384412462448
	140384412462448 [label=AccumulateGrad]
	140384412460432 -> 140384412458800
	140384426034576 [label="model.model.encoder.features.13.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140384426034576 -> 140384412460432
	140384412460432 [label=AccumulateGrad]
	140384412467152 -> 140384412458800
	140384426033696 [label="model.model.encoder.features.13.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140384426033696 -> 140384412467152
	140384412467152 [label=AccumulateGrad]
	140384412462880 -> 140384412461920
	140384426048496 [label="model.model.encoder.features.13.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384426048496 -> 140384412462880
	140384412462880 [label=AccumulateGrad]
	140384412461872 -> 140384412455488
	140384426048656 [label="model.model.encoder.features.13.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140384426048656 -> 140384412461872
	140384412461872 [label=AccumulateGrad]
	140384412454960 -> 140384412455488
	140384426048176 [label="model.model.encoder.features.13.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140384426048176 -> 140384412454960
	140384412454960 [label=AccumulateGrad]
	140384412454624 -> 140384412458656
	140384426047536 [label="model.model.encoder.features.13.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140384426047536 -> 140384412454624
	140384412454624 [label=AccumulateGrad]
	140384412456064 -> 140384412461344
	140384426047456 [label="model.model.encoder.features.13.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140384426047456 -> 140384412456064
	140384412456064 [label=AccumulateGrad]
	140384412456976 -> 140384412461344
	140384426047616 [label="model.model.encoder.features.13.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140384426047616 -> 140384412456976
	140384412456976 [label=AccumulateGrad]
	140384412460864 -> 140384412625424
	140384426046816 [label="model.model.encoder.features.13.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140384426046816 -> 140384412460864
	140384412460864 [label=AccumulateGrad]
	140384412626480 -> 140383267781504
	140384426046496 [label="model.model.encoder.features.13.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140384426046496 -> 140384412626480
	140384412626480 [label=AccumulateGrad]
	140384412460288 -> 140383267781504
	140384426046416 [label="model.model.encoder.features.13.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140384426046416 -> 140384412460288
	140384412460288 [label=AccumulateGrad]
	140383267780496 -> 140383267779920
	140383267780496 [label=ReluBackward0]
	140384412628928 -> 140383267780496
	140384412628928 [label=CudnnBatchNormBackward0]
	140384412458608 -> 140384412628928
	140384412458608 [label=ConvolutionBackward0]
	140384412463744 -> 140384412458608
	140384412463744 [label=AvgPool2DBackward0]
	140383267781936 -> 140384412463744
	140384412460240 -> 140384412458608
	140384426045696 [label="model.model.encoder.features.13.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140384426045696 -> 140384412460240
	140384412460240 [label=AccumulateGrad]
	140384412458944 -> 140384412628928
	140384426045616 [label="model.model.encoder.features.13.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140384426045616 -> 140384412458944
	140384412458944 [label=AccumulateGrad]
	140384412466528 -> 140384412628928
	140384426045776 [label="model.model.encoder.features.13.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140384426045776 -> 140384412466528
	140384412466528 [label=AccumulateGrad]
	140383267779776 -> 140383267779344
	140384426045296 [label="model.model.encoder.features.14.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140384426045296 -> 140383267779776
	140383267779776 [label=AccumulateGrad]
	140383267779200 -> 140383267779056
	140384426044656 [label="model.model.encoder.features.14.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140384426044656 -> 140383267779200
	140383267779200 [label=AccumulateGrad]
	140383267778768 -> 140383267779056
	140384426044576 [label="model.model.encoder.features.14.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384426044576 -> 140383267778768
	140383267778768 [label=AccumulateGrad]
	140383267778192 -> 140383267778960
	140383267778192 [label=ReluBackward0]
	140383267779632 -> 140383267778192
	140383267779632 [label=CudnnBatchNormBackward0]
	140383267780640 -> 140383267779632
	140383267780640 [label=ConvolutionBackward0]
	140384412463360 -> 140383267780640
	140384412463360 [label=ReluBackward0]
	140384412451504 -> 140384412463360
	140384412451504 [label=CudnnBatchNormBackward0]
	140384412452032 -> 140384412451504
	140384412452032 [label=ConvolutionBackward0]
	140384412464176 -> 140384412452032
	140384412464176 [label=ReluBackward0]
	140384412459472 -> 140384412464176
	140384412459472 [label=CudnnBatchNormBackward0]
	140384412456592 -> 140384412459472
	140384412456592 [label=ConvolutionBackward0]
	140383267779920 -> 140384412456592
	140384412462208 -> 140384412456592
	140384426043776 [label="model.model.encoder.features.14.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384426043776 -> 140384412462208
	140384412462208 [label=AccumulateGrad]
	140384412466624 -> 140384412459472
	140384426044256 [label="model.model.encoder.features.14.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384426044256 -> 140384412466624
	140384412466624 [label=AccumulateGrad]
	140384412460816 -> 140384412459472
	140384426043616 [label="model.model.encoder.features.14.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384426043616 -> 140384412460816
	140384412460816 [label=AccumulateGrad]
	140384412455632 -> 140384412452032
	140384426042976 [label="model.model.encoder.features.14.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384426042976 -> 140384412455632
	140384412455632 [label=AccumulateGrad]
	140384412463648 -> 140384412451504
	140384426042736 [label="model.model.encoder.features.14.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384426042736 -> 140384412463648
	140384412463648 [label=AccumulateGrad]
	140384412467104 -> 140384412451504
	140384426043216 [label="model.model.encoder.features.14.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384426043216 -> 140384412467104
	140384412467104 [label=AccumulateGrad]
	140384412463936 -> 140383267780640
	140384426042256 [label="model.model.encoder.features.14.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140384426042256 -> 140384412463936
	140384412463936 [label=AccumulateGrad]
	140383267778912 -> 140383267779632
	140384426042416 [label="model.model.encoder.features.14.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384426042416 -> 140383267778912
	140383267778912 [label=AccumulateGrad]
	140384412456736 -> 140383267779632
	140384426041936 [label="model.model.encoder.features.14.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384426041936 -> 140384412456736
	140384412456736 [label=AccumulateGrad]
	140383267770320 -> 140383267778960
	140383267770320 [label=ReluBackward0]
	140383267779488 -> 140383267770320
	140383267779488 [label=CudnnBatchNormBackward0]
	140384412454576 -> 140383267779488
	140384412454576 [label=ConvolutionBackward0]
	140384412459856 -> 140384412454576
	140384412459856 [label=ReluBackward0]
	140384420003952 -> 140384412459856
	140384420003952 [label=CudnnBatchNormBackward0]
	140384420004384 -> 140384420003952
	140384420004384 [label=ConvolutionBackward0]
	140384420004864 -> 140384420004384
	140384420004864 [label=ReluBackward0]
	140384420005200 -> 140384420004864
	140384420005200 [label=CudnnBatchNormBackward0]
	140384420005440 -> 140384420005200
	140384420005440 [label=ConvolutionBackward0]
	140384420005920 -> 140384420005440
	140384420005920 [label=ReluBackward0]
	140384420006208 -> 140384420005920
	140384420006208 [label=CudnnBatchNormBackward0]
	140384420006448 -> 140384420006208
	140384420006448 [label=ConvolutionBackward0]
	140384420006928 -> 140384420006448
	140384420006928 [label=ReluBackward0]
	140384420007360 -> 140384420006928
	140384420007360 [label=CudnnBatchNormBackward0]
	140384420007600 -> 140384420007360
	140384420007600 [label=ConvolutionBackward0]
	140383267779920 -> 140384420007600
	140384420007984 -> 140384420007600
	140384426041616 [label="model.model.encoder.features.14.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384426041616 -> 140384420007984
	140384420007984 [label=AccumulateGrad]
	140384420007408 -> 140384420007360
	140384426041296 [label="model.model.encoder.features.14.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140384426041296 -> 140384420007408
	140384420007408 [label=AccumulateGrad]
	140384420007120 -> 140384420007360
	140384426041216 [label="model.model.encoder.features.14.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140384426041216 -> 140384420007120
	140384420007120 [label=AccumulateGrad]
	140384420006880 -> 140384420006448
	140384426040416 [label="model.model.encoder.features.14.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140384426040416 -> 140384420006880
	140384420006880 [label=AccumulateGrad]
	140384420006400 -> 140384420006208
	140384426040576 [label="model.model.encoder.features.14.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140384426040576 -> 140384420006400
	140384420006400 [label=AccumulateGrad]
	140384420005968 -> 140384420006208
	140384426040256 [label="model.model.encoder.features.14.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140384426040256 -> 140384420005968
	140384420005968 [label=AccumulateGrad]
	140384420005728 -> 140384420005440
	140384426039456 [label="model.model.encoder.features.14.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384426039456 -> 140384420005728
	140384420005728 [label=AccumulateGrad]
	140384420005248 -> 140384420005200
	140384426039376 [label="model.model.encoder.features.14.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140384426039376 -> 140384420005248
	140384420005248 [label=AccumulateGrad]
	140384420004960 -> 140384420005200
	140384426039536 [label="model.model.encoder.features.14.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140384426039536 -> 140384420004960
	140384420004960 [label=AccumulateGrad]
	140384420004816 -> 140384420004384
	140384426038576 [label="model.model.encoder.features.14.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140384426038576 -> 140384420004816
	140384420004816 [label=AccumulateGrad]
	140384420004336 -> 140384420003952
	140384426039056 [label="model.model.encoder.features.14.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140384426039056 -> 140384420004336
	140384420004336 [label=AccumulateGrad]
	140384420004144 -> 140384420003952
	140384426038416 [label="model.model.encoder.features.14.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140384426038416 -> 140384420004144
	140384420004144 [label=AccumulateGrad]
	140384412463600 -> 140384412454576
	140384426037776 [label="model.model.encoder.features.14.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140384426037776 -> 140384412463600
	140384412463600 [label=AccumulateGrad]
	140384412461584 -> 140383267779488
	140384426037536 [label="model.model.encoder.features.14.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140384426037536 -> 140384412461584
	140384412461584 [label=AccumulateGrad]
	140384412460960 -> 140383267779488
	140384426038016 [label="model.model.encoder.features.14.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140384426038016 -> 140384412460960
	140384412460960 [label=AccumulateGrad]
	140383267778480 -> 140383267778960
	140383267778480 [label=ReluBackward0]
	140384412455776 -> 140383267778480
	140384412455776 [label=CudnnBatchNormBackward0]
	140384420004576 -> 140384412455776
	140384420004576 [label=ConvolutionBackward0]
	140384420005008 -> 140384420004576
	140384420005008 [label=AvgPool2DBackward0]
	140383267779920 -> 140384420005008
	140384420005488 -> 140384420004576
	140384426037136 [label="model.model.encoder.features.14.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140384426037136 -> 140384420005488
	140384420005488 [label=AccumulateGrad]
	140384420004624 -> 140384412455776
	140384426037056 [label="model.model.encoder.features.14.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140384426037056 -> 140384420004624
	140384420004624 [label=AccumulateGrad]
	140384420004000 -> 140384412455776
	140384426037216 [label="model.model.encoder.features.14.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140384426037216 -> 140384420004000
	140384420004000 [label=AccumulateGrad]
	140383267778048 -> 140383267770032
	140384426036256 [label="model.model.encoder.features.15.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140384426036256 -> 140383267778048
	140383267778048 [label=AccumulateGrad]
	140383267769888 -> 140383267769744
	140384426036416 [label="model.model.encoder.features.15.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140384426036416 -> 140383267769888
	140383267769888 [label=AccumulateGrad]
	140383267777760 -> 140383267769744
	140384426036096 [label="model.model.encoder.features.15.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140384426036096 -> 140383267777760
	140383267777760 [label=AccumulateGrad]
	140383267770896 -> 140383267771184
	140383267770896 [label=ReluBackward0]
	140384412460480 -> 140383267770896
	140384412460480 [label=CudnnBatchNormBackward0]
	140383267778624 -> 140384412460480
	140383267778624 [label=ConvolutionBackward0]
	140384420006640 -> 140383267778624
	140384420006640 [label=ReluBackward0]
	140384420007648 -> 140384420006640
	140384420007648 [label=CudnnBatchNormBackward0]
	140384420008128 -> 140384420007648
	140384420008128 [label=ConvolutionBackward0]
	140384420008272 -> 140384420008128
	140384420008272 [label=ReluBackward0]
	140384420008464 -> 140384420008272
	140384420008464 [label=CudnnBatchNormBackward0]
	140384420008704 -> 140384420008464
	140384420008704 [label=ConvolutionBackward0]
	140383267778960 -> 140384420008704
	140384420009184 -> 140384420008704
	140384426035296 [label="model.model.encoder.features.15.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384426035296 -> 140384420009184
	140384420009184 [label=AccumulateGrad]
	140384420008656 -> 140384420008464
	140384426035216 [label="model.model.encoder.features.15.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140384426035216 -> 140384420008656
	140384420008656 [label=AccumulateGrad]
	140384420008320 -> 140384420008464
	140384426035376 [label="model.model.encoder.features.15.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140384426035376 -> 140384420008320
	140384420008320 [label=AccumulateGrad]
	140384420008176 -> 140384420008128
	140384426034896 [label="model.model.encoder.features.15.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140384426034896 -> 140384420008176
	140384420008176 [label=AccumulateGrad]
	140384420007168 -> 140384420007648
	140384426034256 [label="model.model.encoder.features.15.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140384426034256 -> 140384420007168
	140384420007168 [label=AccumulateGrad]
	140384420006160 -> 140384420007648
	140384426034176 [label="model.model.encoder.features.15.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140384426034176 -> 140384420006160
	140384420006160 [label=AccumulateGrad]
	140384420006688 -> 140383267778624
	140384426033856 [label="model.model.encoder.features.15.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140384426033856 -> 140384420006688
	140384420006688 [label=AccumulateGrad]
	140383267777904 -> 140384412460480
	140384426033296 [label="model.model.encoder.features.15.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140384426033296 -> 140383267777904
	140383267777904 [label=AccumulateGrad]
	140383267777616 -> 140384412460480
	140384426049056 [label="model.model.encoder.features.15.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140384426049056 -> 140383267777616
	140383267777616 [label=AccumulateGrad]
	140383267771040 -> 140383267771184
	140383267771040 [label=ReluBackward0]
	140383267770176 -> 140383267771040
	140383267770176 [label=CudnnBatchNormBackward0]
	140384420008032 -> 140383267770176
	140384420008032 [label=ConvolutionBackward0]
	140384420008416 -> 140384420008032
	140384420008416 [label=ReluBackward0]
	140384420008944 -> 140384420008416
	140384420008944 [label=CudnnBatchNormBackward0]
	140384420009664 -> 140384420008944
	140384420009664 [label=ConvolutionBackward0]
	140384420010144 -> 140384420009664
	140384420010144 [label=ReluBackward0]
	140384420010576 -> 140384420010144
	140384420010576 [label=CudnnBatchNormBackward0]
	140384420010816 -> 140384420010576
	140384420010816 [label=ConvolutionBackward0]
	140384420011200 -> 140384420010816
	140384420011200 [label=ReluBackward0]
	140384420011488 -> 140384420011200
	140384420011488 [label=CudnnBatchNormBackward0]
	140384420011728 -> 140384420011488
	140384420011728 [label=ConvolutionBackward0]
	140384420012208 -> 140384420011728
	140384420012208 [label=ReluBackward0]
	140384420012640 -> 140384420012208
	140384420012640 [label=CudnnBatchNormBackward0]
	140384420012880 -> 140384420012640
	140384420012880 [label=ConvolutionBackward0]
	140383267778960 -> 140384420012880
	140384420013264 -> 140384420012880
	140384426039776 [label="model.model.encoder.features.15.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140384426039776 -> 140384420013264
	140384420013264 [label=AccumulateGrad]
	140384420012688 -> 140384420012640
	140384426043056 [label="model.model.encoder.features.15.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140384426043056 -> 140384420012688
	140384420012688 [label=AccumulateGrad]
	140384420012400 -> 140384420012640
	140383249299104 [label="model.model.encoder.features.15.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140383249299104 -> 140384420012400
	140384420012400 [label=AccumulateGrad]
	140384420012160 -> 140384420011728
	140383249298224 [label="model.model.encoder.features.15.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140383249298224 -> 140384420012160
	140384420012160 [label=AccumulateGrad]
	140384420011680 -> 140384420011488
	140383249298624 [label="model.model.encoder.features.15.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140383249298624 -> 140384420011680
	140384420011680 [label=AccumulateGrad]
	140384420011248 -> 140384420011488
	140383249298704 [label="model.model.encoder.features.15.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140383249298704 -> 140384420011248
	140384420011248 [label=AccumulateGrad]
	140384420011008 -> 140384420010816
	140383249299904 [label="model.model.encoder.features.15.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140383249299904 -> 140384420011008
	140384420011008 [label=AccumulateGrad]
	140384420010624 -> 140384420010576
	140383249299984 [label="model.model.encoder.features.15.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140383249299984 -> 140384420010624
	140384420010624 [label=AccumulateGrad]
	140384420010336 -> 140384420010576
	140383249300064 [label="model.model.encoder.features.15.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140383249300064 -> 140384420010336
	140384420010336 [label=AccumulateGrad]
	140384420010096 -> 140384420009664
	140383249301104 [label="model.model.encoder.features.15.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140383249301104 -> 140384420010096
	140384420010096 [label=AccumulateGrad]
	140384420009616 -> 140384420008944
	140383249298944 [label="model.model.encoder.features.15.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140383249298944 -> 140384420009616
	140384420009616 [label=AccumulateGrad]
	140384420009424 -> 140384420008944
	140383249298384 [label="model.model.encoder.features.15.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140383249298384 -> 140384420009424
	140384420009424 [label=AccumulateGrad]
	140384420008896 -> 140384420008032
	140383249301344 [label="model.model.encoder.features.15.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140383249301344 -> 140384420008896
	140384420008896 [label=AccumulateGrad]
	140384420007744 -> 140383267770176
	140383249301184 [label="model.model.encoder.features.15.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140383249301184 -> 140384420007744
	140384420007744 [label=AccumulateGrad]
	140384420004096 -> 140383267770176
	140383249300864 [label="model.model.encoder.features.15.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140383249300864 -> 140384420004096
	140384420004096 [label=AccumulateGrad]
	140383267770608 -> 140383267771184
	140383267770608 [label=ReluBackward0]
	140384420009136 -> 140383267770608
	140384420009136 [label=CudnnBatchNormBackward0]
	140384420009856 -> 140384420009136
	140384420009856 [label=ConvolutionBackward0]
	140384420010384 -> 140384420009856
	140384420010384 [label=AvgPool2DBackward0]
	140383267778960 -> 140384420010384
	140384420010864 -> 140384420009856
	140383249299664 [label="model.model.encoder.features.15.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140383249299664 -> 140384420010864
	140384420010864 [label=AccumulateGrad]
	140384420009904 -> 140384420009136
	140383249298304 [label="model.model.encoder.features.15.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140383249298304 -> 140384420009904
	140384420009904 [label=AccumulateGrad]
	140384420005680 -> 140384420009136
	140383249299184 [label="model.model.encoder.features.15.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140383249299184 -> 140384420005680
	140384420005680 [label=AccumulateGrad]
	140383267771328 -> 140383267771760
	140383249285264 [label="model.model.encoder.features.16.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140383249285264 -> 140383267771328
	140383267771328 [label=AccumulateGrad]
	140383267771904 -> 140383267772048
	140383249285344 [label="model.model.encoder.features.16.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140383249285344 -> 140383267771904
	140383267771904 [label=AccumulateGrad]
	140383267772336 -> 140383267772048
	140383249285424 [label="model.model.encoder.features.16.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140383249285424 -> 140383267772336
	140383267772336 [label=AccumulateGrad]
	140383267772912 -> 140383267773200
	140383267772912 [label=ReluBackward0]
	140383267771472 -> 140383267772912
	140383267771472 [label=CudnnBatchNormBackward0]
	140383267770464 -> 140383267771472
	140383267770464 [label=ConvolutionBackward0]
	140384420011920 -> 140383267770464
	140384420011920 [label=ReluBackward0]
	140384420012928 -> 140384420011920
	140384420012928 [label=CudnnBatchNormBackward0]
	140384420013504 -> 140384420012928
	140384420013504 [label=ConvolutionBackward0]
	140384420013648 -> 140384420013504
	140384420013648 [label=ReluBackward0]
	140384420013936 -> 140384420013648
	140384420013936 [label=CudnnBatchNormBackward0]
	140384420014176 -> 140384420013936
	140384420014176 [label=ConvolutionBackward0]
	140383267771184 -> 140384420014176
	140384420014560 -> 140384420014176
	140383249285904 [label="model.model.encoder.features.16.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140383249285904 -> 140384420014560
	140384420014560 [label=AccumulateGrad]
	140384420014128 -> 140384420013936
	140383249285984 [label="model.model.encoder.features.16.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140383249285984 -> 140384420014128
	140384420014128 [label=AccumulateGrad]
	140384420013696 -> 140384420013936
	140383249286064 [label="model.model.encoder.features.16.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140383249286064 -> 140384420013696
	140384420013696 [label=AccumulateGrad]
	140384420013552 -> 140384420013504
	140383249286464 [label="model.model.encoder.features.16.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140383249286464 -> 140384420013552
	140384420013552 [label=AccumulateGrad]
	140384420012448 -> 140384420012928
	140383249286544 [label="model.model.encoder.features.16.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140383249286544 -> 140384420012448
	140384420012448 [label=AccumulateGrad]
	140384420011440 -> 140384420012928
	140383249286624 [label="model.model.encoder.features.16.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140383249286624 -> 140384420011440
	140384420011440 [label=AccumulateGrad]
	140384420011968 -> 140383267770464
	140383249287104 [label="model.model.encoder.features.16.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140383249287104 -> 140384420011968
	140384420011968 [label=AccumulateGrad]
	140383267772192 -> 140383267771472
	140383249287184 [label="model.model.encoder.features.16.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140383249287184 -> 140383267772192
	140383267772192 [label=AccumulateGrad]
	140384420009376 -> 140383267771472
	140383249287264 [label="model.model.encoder.features.16.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140383249287264 -> 140384420009376
	140384420009376 [label=AccumulateGrad]
	140383267773056 -> 140383267773200
	140383267773056 [label=ReluBackward0]
	140383267771616 -> 140383267773056
	140383267771616 [label=CudnnBatchNormBackward0]
	140384420013312 -> 140383267771616
	140384420013312 [label=ConvolutionBackward0]
	140384420013888 -> 140384420013312
	140384420013888 [label=ReluBackward0]
	140384420014320 -> 140384420013888
	140384420014320 [label=CudnnBatchNormBackward0]
	140384420015040 -> 140384420014320
	140384420015040 [label=ConvolutionBackward0]
	140384420015520 -> 140384420015040
	140384420015520 [label=ReluBackward0]
	140384420015856 -> 140384420015520
	140384420015856 [label=CudnnBatchNormBackward0]
	140384420016096 -> 140384420015856
	140384420016096 [label=ConvolutionBackward0]
	140384420016576 -> 140384420016096
	140384420016576 [label=ReluBackward0]
	140384420016864 -> 140384420016576
	140384420016864 [label=CudnnBatchNormBackward0]
	140384420017104 -> 140384420016864
	140384420017104 [label=ConvolutionBackward0]
	140384420017584 -> 140384420017104
	140384420017584 [label=ReluBackward0]
	140384420018016 -> 140384420017584
	140384420018016 [label=CudnnBatchNormBackward0]
	140384420018256 -> 140384420018016
	140384420018256 [label=ConvolutionBackward0]
	140383267771184 -> 140384420018256
	140384420018736 -> 140384420018256
	140383249287664 [label="model.model.encoder.features.16.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140383249287664 -> 140384420018736
	140384420018736 [label=AccumulateGrad]
	140384420018064 -> 140384420018016
	140383249287744 [label="model.model.encoder.features.16.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140383249287744 -> 140384420018064
	140384420018064 [label=AccumulateGrad]
	140384420017776 -> 140384420018016
	140383249287824 [label="model.model.encoder.features.16.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140383249287824 -> 140384420017776
	140384420017776 [label=AccumulateGrad]
	140384420017536 -> 140384420017104
	140383249288224 [label="model.model.encoder.features.16.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140383249288224 -> 140384420017536
	140384420017536 [label=AccumulateGrad]
	140384420017056 -> 140384420016864
	140383249288304 [label="model.model.encoder.features.16.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140383249288304 -> 140384420017056
	140384420017056 [label=AccumulateGrad]
	140384420016624 -> 140384420016864
	140383249288384 [label="model.model.encoder.features.16.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140383249288384 -> 140384420016624
	140384420016624 [label=AccumulateGrad]
	140384420016384 -> 140384420016096
	140383249288864 [label="model.model.encoder.features.16.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140383249288864 -> 140384420016384
	140384420016384 [label=AccumulateGrad]
	140384420015904 -> 140384420015856
	140383249288944 [label="model.model.encoder.features.16.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140383249288944 -> 140384420015904
	140384420015904 [label=AccumulateGrad]
	140384420015616 -> 140384420015856
	140383249289024 [label="model.model.encoder.features.16.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140383249289024 -> 140384420015616
	140384420015616 [label=AccumulateGrad]
	140384420015472 -> 140384420015040
	140383249289504 [label="model.model.encoder.features.16.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140383249289504 -> 140384420015472
	140384420015472 [label=AccumulateGrad]
	140384420014992 -> 140384420014320
	140383249289584 [label="model.model.encoder.features.16.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140383249289584 -> 140384420014992
	140384420014992 [label=AccumulateGrad]
	140384420014800 -> 140384420014320
	140383249289664 [label="model.model.encoder.features.16.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140383249289664 -> 140384420014800
	140384420014800 [label=AccumulateGrad]
	140384420014272 -> 140384420013312
	140383249290144 [label="model.model.encoder.features.16.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140383249290144 -> 140384420014272
	140384420014272 [label=AccumulateGrad]
	140384420013120 -> 140383267771616
	140383249290224 [label="model.model.encoder.features.16.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140383249290224 -> 140384420013120
	140384420013120 [label=AccumulateGrad]
	140384420007792 -> 140383267771616
	140383249290304 [label="model.model.encoder.features.16.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140383249290304 -> 140384420007792
	140384420007792 [label=AccumulateGrad]
	140383267772624 -> 140383267773200
	140383267772624 [label=ReluBackward0]
	140384420014512 -> 140383267772624
	140384420014512 [label=CudnnBatchNormBackward0]
	140384420015232 -> 140384420014512
	140384420015232 [label=ConvolutionBackward0]
	140384420015664 -> 140384420015232
	140384420015664 [label=AvgPool2DBackward0]
	140383267771184 -> 140384420015664
	140384420016144 -> 140384420015232
	140383249290704 [label="model.model.encoder.features.16.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140383249290704 -> 140384420016144
	140384420016144 [label=AccumulateGrad]
	140384420015280 -> 140384420014512
	140383268962848 [label="model.model.encoder.features.16.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140383268962848 -> 140384420015280
	140384420015280 [label=AccumulateGrad]
	140384420010960 -> 140384420014512
	140383268966608 [label="model.model.encoder.features.16.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140383268966608 -> 140384420010960
	140384420010960 [label=AccumulateGrad]
	140383267773392 -> 140383267773776
	140383268967488 [label="model.model.encoder.features.17.branch0.conv.weight
 (384, 1024, 1, 1)" fillcolor=lightblue]
	140383268967488 -> 140383267773392
	140383267773392 [label=AccumulateGrad]
	140383267773968 -> 140383267774064
	140383268967248 [label="model.model.encoder.features.17.branch0.bn.weight
 (384)" fillcolor=lightblue]
	140383268967248 -> 140383267773968
	140383267773968 [label=AccumulateGrad]
	140383267774352 -> 140383267774064
	140383268965968 [label="model.model.encoder.features.17.branch0.bn.bias
 (384)" fillcolor=lightblue]
	140383268965968 -> 140383267774352
	140383267774352 [label=AccumulateGrad]
	140383267774928 -> 140383267775216
	140383267774928 [label=ReluBackward0]
	140383267773488 -> 140383267774928
	140383267773488 [label=CudnnBatchNormBackward0]
	140383267772480 -> 140383267773488
	140383267772480 [label=ConvolutionBackward0]
	140384420017344 -> 140383267772480
	140384420017344 [label=ReluBackward0]
	140384420017824 -> 140384420017344
	140384420017824 [label=CudnnBatchNormBackward0]
	140384420018784 -> 140384420017824
	140384420018784 [label=ConvolutionBackward0]
	140384420019264 -> 140384420018784
	140384420019264 [label=ReluBackward0]
	140384420019696 -> 140384420019264
	140384420019696 [label=CudnnBatchNormBackward0]
	140384420019936 -> 140384420019696
	140384420019936 [label=ConvolutionBackward0]
	140383267773200 -> 140384420019936
	140384420004240 -> 140384420019936
	140383268968528 [label="model.model.encoder.features.17.branch1.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140383268968528 -> 140384420004240
	140384420004240 [label=AccumulateGrad]
	140384420019744 -> 140384420019696
	140383268968448 [label="model.model.encoder.features.17.branch1.0.bn.weight
 (192)" fillcolor=lightblue]
	140383268968448 -> 140384420019744
	140384420019744 [label=AccumulateGrad]
	140384420019456 -> 140384420019696
	140383268968368 [label="model.model.encoder.features.17.branch1.0.bn.bias
 (192)" fillcolor=lightblue]
	140383268968368 -> 140384420019456
	140384420019456 [label=AccumulateGrad]
	140384420019216 -> 140384420018784
	140383268969008 [label="model.model.encoder.features.17.branch1.1.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140383268969008 -> 140384420019216
	140384420019216 [label=AccumulateGrad]
	140384420018976 -> 140384420017824
	140383268968928 [label="model.model.encoder.features.17.branch1.1.bn.weight
 (224)" fillcolor=lightblue]
	140383268968928 -> 140384420018976
	140384420018976 [label=AccumulateGrad]
	140384420017296 -> 140384420017824
	140383268968768 [label="model.model.encoder.features.17.branch1.1.bn.bias
 (224)" fillcolor=lightblue]
	140383268968768 -> 140384420017296
	140384420017296 [label=AccumulateGrad]
	140384420018544 -> 140383267772480
	140383268969488 [label="model.model.encoder.features.17.branch1.2.conv.weight
 (256, 224, 7, 1)" fillcolor=lightblue]
	140383268969488 -> 140384420018544
	140384420018544 [label=AccumulateGrad]
	140383267774208 -> 140383267773488
	140383268969328 [label="model.model.encoder.features.17.branch1.2.bn.weight
 (256)" fillcolor=lightblue]
	140383268969328 -> 140383267774208
	140383267774208 [label=AccumulateGrad]
	140384420014752 -> 140383267773488
	140383268970048 [label="model.model.encoder.features.17.branch1.2.bn.bias
 (256)" fillcolor=lightblue]
	140383268970048 -> 140384420014752
	140384420014752 [label=AccumulateGrad]
	140383267775072 -> 140383267775216
	140383267775072 [label=ReluBackward0]
	140383267773632 -> 140383267775072
	140383267773632 [label=CudnnBatchNormBackward0]
	140384420018496 -> 140383267773632
	140384420018496 [label=ConvolutionBackward0]
	140384420019504 -> 140384420018496
	140384420019504 [label=ReluBackward0]
	140384420006784 -> 140384420019504
	140384420006784 [label=CudnnBatchNormBackward0]
	140384420005104 -> 140384420006784
	140384420005104 [label=ConvolutionBackward0]
	140384420006064 -> 140384420005104
	140384420006064 [label=ReluBackward0]
	140384420006304 -> 140384420006064
	140384420006304 [label=CudnnBatchNormBackward0]
	140384420007024 -> 140384420006304
	140384420007024 [label=ConvolutionBackward0]
	140384420007888 -> 140384420007024
	140384420007888 [label=ReluBackward0]
	140384420008800 -> 140384420007888
	140384420008800 [label=CudnnBatchNormBackward0]
	140384420009280 -> 140384420008800
	140384420009280 [label=ConvolutionBackward0]
	140384420010240 -> 140384420009280
	140384420010240 [label=ReluBackward0]
	140384420010480 -> 140384420010240
	140384420010480 [label=CudnnBatchNormBackward0]
	140384420010768 -> 140384420010480
	140384420010768 [label=ConvolutionBackward0]
	140383267773200 -> 140384420010768
	140384420011824 -> 140384420010768
	140383268968128 [label="model.model.encoder.features.17.branch2.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140383268968128 -> 140384420011824
	140384420011824 [label=AccumulateGrad]
	140384420011104 -> 140384420010480
	140383268966128 [label="model.model.encoder.features.17.branch2.0.bn.weight
 (192)" fillcolor=lightblue]
	140383268966128 -> 140384420011104
	140384420011104 [label=AccumulateGrad]
	140384420010000 -> 140384420010480
	140383268967888 [label="model.model.encoder.features.17.branch2.0.bn.bias
 (192)" fillcolor=lightblue]
	140383268967888 -> 140384420010000
	140384420010000 [label=AccumulateGrad]
	140384420009520 -> 140384420009280
	140383267082448 [label="model.model.encoder.features.17.branch2.1.conv.weight
 (192, 192, 7, 1)" fillcolor=lightblue]
	140383267082448 -> 140384420009520
	140384420009520 [label=AccumulateGrad]
	140384420008560 -> 140384420008800
	140383267082528 [label="model.model.encoder.features.17.branch2.1.bn.weight
 (192)" fillcolor=lightblue]
	140383267082528 -> 140384420008560
	140384420008560 [label=AccumulateGrad]
	140384420008224 -> 140384420008800
	140383267082608 [label="model.model.encoder.features.17.branch2.1.bn.bias
 (192)" fillcolor=lightblue]
	140383267082608 -> 140384420008224
	140384420008224 [label=AccumulateGrad]
	140384420007936 -> 140384420007024
	140383267083088 [label="model.model.encoder.features.17.branch2.2.conv.weight
 (224, 192, 1, 7)" fillcolor=lightblue]
	140383267083088 -> 140384420007936
	140384420007936 [label=AccumulateGrad]
	140384420007264 -> 140384420006304
	140383267083168 [label="model.model.encoder.features.17.branch2.2.bn.weight
 (224)" fillcolor=lightblue]
	140383267083168 -> 140384420007264
	140384420007264 [label=AccumulateGrad]
	140384420005824 -> 140384420006304
	140383267083248 [label="model.model.encoder.features.17.branch2.2.bn.bias
 (224)" fillcolor=lightblue]
	140383267083248 -> 140384420005824
	140384420005824 [label=AccumulateGrad]
	140384420005344 -> 140384420005104
	140383267083728 [label="model.model.encoder.features.17.branch2.3.conv.weight
 (224, 224, 7, 1)" fillcolor=lightblue]
	140383267083728 -> 140384420005344
	140384420005344 [label=AccumulateGrad]
	140384420004480 -> 140384420006784
	140383267083808 [label="model.model.encoder.features.17.branch2.3.bn.weight
 (224)" fillcolor=lightblue]
	140383267083808 -> 140384420004480
	140384420004480 [label=AccumulateGrad]
	140384420004720 -> 140384420006784
	140383267083888 [label="model.model.encoder.features.17.branch2.3.bn.bias
 (224)" fillcolor=lightblue]
	140383267083888 -> 140384420004720
	140384420004720 [label=AccumulateGrad]
	140384420019984 -> 140384420018496
	140383267084368 [label="model.model.encoder.features.17.branch2.4.conv.weight
 (256, 224, 1, 7)" fillcolor=lightblue]
	140383267084368 -> 140384420019984
	140384420019984 [label=AccumulateGrad]
	140384420019024 -> 140383267773632
	140383267084448 [label="model.model.encoder.features.17.branch2.4.bn.weight
 (256)" fillcolor=lightblue]
	140383267084448 -> 140384420019024
	140384420019024 [label=AccumulateGrad]
	140384420013168 -> 140383267773632
	140383267084528 [label="model.model.encoder.features.17.branch2.4.bn.bias
 (256)" fillcolor=lightblue]
	140383267084528 -> 140384420013168
	140384420013168 [label=AccumulateGrad]
	140383267774784 -> 140383267775216
	140383267774784 [label=ReluBackward0]
	140384420020176 -> 140383267774784
	140384420020176 [label=CudnnBatchNormBackward0]
	140384420004768 -> 140384420020176
	140384420004768 [label=ConvolutionBackward0]
	140384420006544 -> 140384420004768
	140384420006544 [label=AvgPool2DBackward0]
	140383267773200 -> 140384420006544
	140384420007552 -> 140384420004768
	140383267085008 [label="model.model.encoder.features.17.branch3.1.conv.weight
 (128, 1024, 1, 1)" fillcolor=lightblue]
	140383267085008 -> 140384420007552
	140384420007552 [label=AccumulateGrad]
	140384420005584 -> 140384420020176
	140383267085088 [label="model.model.encoder.features.17.branch3.1.bn.weight
 (128)" fillcolor=lightblue]
	140383267085088 -> 140384420005584
	140384420005584 [label=AccumulateGrad]
	140384420016336 -> 140384420020176
	140383267085168 [label="model.model.encoder.features.17.branch3.1.bn.bias
 (128)" fillcolor=lightblue]
	140383267085168 -> 140384420016336
	140384420016336 [label=AccumulateGrad]
	140383267775360 -> 140383267775792
	140383267085648 [label="model.model.encoder.features.18.branch0.0.conv.weight
 (192, 1024, 1, 1)" fillcolor=lightblue]
	140383267085648 -> 140383267775360
	140383267775360 [label=AccumulateGrad]
	140383267775936 -> 140383267776080
	140383267085728 [label="model.model.encoder.features.18.branch0.0.bn.weight
 (192)" fillcolor=lightblue]
	140383267085728 -> 140383267775936
	140383267775936 [label=AccumulateGrad]
	140383267776368 -> 140383267776080
	140383267085808 [label="model.model.encoder.features.18.branch0.0.bn.bias
 (192)" fillcolor=lightblue]
	140383267085808 -> 140383267776368
	140383267776368 [label=AccumulateGrad]
	140383267776656 -> 140383267777088
	140383267086208 [label="model.model.encoder.features.18.branch0.1.conv.weight
 (192, 192, 3, 3)" fillcolor=lightblue]
	140383267086208 -> 140383267776656
	140383267776656 [label=AccumulateGrad]
	140383267777232 -> 140383267777376
	140383267086288 [label="model.model.encoder.features.18.branch0.1.bn.weight
 (192)" fillcolor=lightblue]
	140383267086288 -> 140383267777232
	140383267777232 [label=AccumulateGrad]
	140383267782560 -> 140383267777376
	140383267086368 [label="model.model.encoder.features.18.branch0.1.bn.bias
 (192)" fillcolor=lightblue]
	140383267086368 -> 140383267782560
	140383267782560 [label=AccumulateGrad]
	140383267782464 -> 140383267782320
	140383267782464 [label=ReluBackward0]
	140383267776800 -> 140383267782464
	140383267776800 [label=CudnnBatchNormBackward0]
	140383267775648 -> 140383267776800
	140383267775648 [label=ConvolutionBackward0]
	140383267774496 -> 140383267775648
	140383267774496 [label=ReluBackward0]
	140384420009040 -> 140383267774496
	140384420009040 [label=CudnnBatchNormBackward0]
	140384420012064 -> 140384420009040
	140384420012064 [label=ConvolutionBackward0]
	140384420012544 -> 140384420012064
	140384420012544 [label=ReluBackward0]
	140384420012784 -> 140384420012544
	140384420012784 [label=CudnnBatchNormBackward0]
	140384420013072 -> 140384420012784
	140384420013072 [label=ConvolutionBackward0]
	140384420014032 -> 140384420013072
	140384420014032 [label=ReluBackward0]
	140384420015136 -> 140384420014032
	140384420015136 [label=CudnnBatchNormBackward0]
	140384420015424 -> 140384420015136
	140384420015424 [label=ConvolutionBackward0]
	140383267775216 -> 140384420015424
	140384420016480 -> 140384420015424
	140383267086768 [label="model.model.encoder.features.18.branch1.0.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140383267086768 -> 140384420016480
	140384420016480 [label=AccumulateGrad]
	140384420014896 -> 140384420015136
	140383267086848 [label="model.model.encoder.features.18.branch1.0.bn.weight
 (256)" fillcolor=lightblue]
	140383267086848 -> 140384420014896
	140384420014896 [label=AccumulateGrad]
	140384420014656 -> 140384420015136
	140383267086928 [label="model.model.encoder.features.18.branch1.0.bn.bias
 (256)" fillcolor=lightblue]
	140383267086928 -> 140384420014656
	140384420014656 [label=AccumulateGrad]
	140384420014080 -> 140384420013072
	140383267087408 [label="model.model.encoder.features.18.branch1.1.conv.weight
 (256, 256, 1, 7)" fillcolor=lightblue]
	140383267087408 -> 140384420014080
	140384420014080 [label=AccumulateGrad]
	140384420013408 -> 140384420012784
	140383267087488 [label="model.model.encoder.features.18.branch1.1.bn.weight
 (256)" fillcolor=lightblue]
	140383267087488 -> 140384420013408
	140384420013408 [label=AccumulateGrad]
	140384420011344 -> 140384420012784
	140383267087568 [label="model.model.encoder.features.18.branch1.1.bn.bias
 (256)" fillcolor=lightblue]
	140383267087568 -> 140384420011344
	140384420011344 [label=AccumulateGrad]
	140384420012304 -> 140384420012064
	140383267088048 [label="model.model.encoder.features.18.branch1.2.conv.weight
 (320, 256, 7, 1)" fillcolor=lightblue]
	140383267088048 -> 140384420012304
	140384420012304 [label=AccumulateGrad]
	140384420008080 -> 140384420009040
	140383267088128 [label="model.model.encoder.features.18.branch1.2.bn.weight
 (320)" fillcolor=lightblue]
	140383267088128 -> 140384420008080
	140384420008080 [label=AccumulateGrad]
	140384420007504 -> 140384420009040
	140383267088208 [label="model.model.encoder.features.18.branch1.2.bn.bias
 (320)" fillcolor=lightblue]
	140383267088208 -> 140384420007504
	140384420007504 [label=AccumulateGrad]
	140384420018304 -> 140383267775648
	140383267088688 [label="model.model.encoder.features.18.branch1.3.conv.weight
 (320, 320, 3, 3)" fillcolor=lightblue]
	140383267088688 -> 140384420018304
	140384420018304 [label=AccumulateGrad]
	140383267775504 -> 140383267776800
	140383267088768 [label="model.model.encoder.features.18.branch1.3.bn.weight
 (320)" fillcolor=lightblue]
	140383267088768 -> 140383267775504
	140383267775504 [label=AccumulateGrad]
	140383267777520 -> 140383267776800
	140383267088848 [label="model.model.encoder.features.18.branch1.3.bn.bias
 (320)" fillcolor=lightblue]
	140383267088848 -> 140383267777520
	140383267777520 [label=AccumulateGrad]
	140383267782272 -> 140383267782320
	140383267782272 [label=MaxPool2DWithIndicesBackward0]
	140383267775216 -> 140383267782272
	140383267782128 -> 140383267782032
	140383267084048 [label="model.model.encoder.features.19.branch0.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140383267084048 -> 140383267782128
	140383267782128 [label=AccumulateGrad]
	140383267781840 -> 140383267781888
	140383267089168 [label="model.model.encoder.features.19.branch0.bn.weight
 (256)" fillcolor=lightblue]
	140383267089168 -> 140383267781840
	140383267781840 [label=AccumulateGrad]
	140383267781744 -> 140383267781888
	140383267089248 [label="model.model.encoder.features.19.branch0.bn.bias
 (256)" fillcolor=lightblue]
	140383267089248 -> 140383267781744
	140383267781744 [label=AccumulateGrad]
	140383267781456 -> 140383267781312
	140383267781456 [label=CatBackward0]
	140383267782176 -> 140383267781456
	140383267782176 [label=ReluBackward0]
	140383267782608 -> 140383267782176
	140383267782608 [label=CudnnBatchNormBackward0]
	140383267776944 -> 140383267782608
	140383267776944 [label=ConvolutionBackward0]
	140384420013792 -> 140383267776944
	140384420013792 [label=ReluBackward0]
	140384420015376 -> 140384420013792
	140384420015376 [label=CudnnBatchNormBackward0]
	140384420016960 -> 140384420015376
	140384420016960 [label=ConvolutionBackward0]
	140383267782320 -> 140384420016960
	140384420017440 -> 140384420016960
	140383267089648 [label="model.model.encoder.features.19.branch1_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140383267089648 -> 140384420017440
	140384420017440 [label=AccumulateGrad]
	140384420014416 -> 140384420015376
	140383267089728 [label="model.model.encoder.features.19.branch1_0.bn.weight
 (384)" fillcolor=lightblue]
	140383267089728 -> 140384420014416
	140384420014416 [label=AccumulateGrad]
	140384420013024 -> 140384420015376
	140383267089808 [label="model.model.encoder.features.19.branch1_0.bn.bias
 (384)" fillcolor=lightblue]
	140383267089808 -> 140384420013024
	140384420013024 [label=AccumulateGrad]
	140384420013456 -> 140383267776944
	140383267090208 [label="model.model.encoder.features.19.branch1_1a.conv.weight
 (256, 384, 1, 3)" fillcolor=lightblue]
	140383267090208 -> 140384420013456
	140384420013456 [label=AccumulateGrad]
	140384420010720 -> 140383267782608
	140383267090288 [label="model.model.encoder.features.19.branch1_1a.bn.weight
 (256)" fillcolor=lightblue]
	140383267090288 -> 140384420010720
	140384420010720 [label=AccumulateGrad]
	140384420003904 -> 140383267782608
	140383267090368 [label="model.model.encoder.features.19.branch1_1a.bn.bias
 (256)" fillcolor=lightblue]
	140383267090368 -> 140384420003904
	140384420003904 [label=AccumulateGrad]
	140383267781984 -> 140383267781456
	140383267781984 [label=ReluBackward0]
	140383267776224 -> 140383267781984
	140383267776224 [label=CudnnBatchNormBackward0]
	140384420016240 -> 140383267776224
	140384420016240 [label=ConvolutionBackward0]
	140384420013792 -> 140384420016240
	140384420016000 -> 140384420016240
	140383267090848 [label="model.model.encoder.features.19.branch1_1b.conv.weight
 (256, 384, 3, 1)" fillcolor=lightblue]
	140383267090848 -> 140384420016000
	140384420016000 [label=AccumulateGrad]
	140384420016720 -> 140383267776224
	140383267090928 [label="model.model.encoder.features.19.branch1_1b.bn.weight
 (256)" fillcolor=lightblue]
	140383267090928 -> 140384420016720
	140384420016720 [label=AccumulateGrad]
	140384420011584 -> 140383267776224
	140383267091008 [label="model.model.encoder.features.19.branch1_1b.bn.bias
 (256)" fillcolor=lightblue]
	140383267091008 -> 140384420011584
	140384420011584 [label=AccumulateGrad]
	140383267781264 -> 140383267781312
	140383267781264 [label=CatBackward0]
	140383267781696 -> 140383267781264
	140383267781696 [label=ReluBackward0]
	140384420017680 -> 140383267781696
	140384420017680 [label=CudnnBatchNormBackward0]
	140384420018160 -> 140384420017680
	140384420018160 [label=ConvolutionBackward0]
	140384420019120 -> 140384420018160
	140384420019120 [label=ReluBackward0]
	140384420020128 -> 140384420019120
	140384420020128 [label=CudnnBatchNormBackward0]
	140384420020080 -> 140384420020128
	140384420020080 [label=ConvolutionBackward0]
	140384420053584 -> 140384420020080
	140384420053584 [label=ReluBackward0]
	140384420053536 -> 140384420053584
	140384420053536 [label=CudnnBatchNormBackward0]
	140384420053776 -> 140384420053536
	140384420053776 [label=ConvolutionBackward0]
	140384420054256 -> 140384420053776
	140384420054256 [label=ReluBackward0]
	140384420055024 -> 140384420054256
	140384420055024 [label=CudnnBatchNormBackward0]
	140384420055264 -> 140384420055024
	140384420055264 [label=ConvolutionBackward0]
	140383267782320 -> 140384420055264
	140384420055744 -> 140384420055264
	140383267091488 [label="model.model.encoder.features.19.branch2_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140383267091488 -> 140384420055744
	140384420055744 [label=AccumulateGrad]
	140384420054736 -> 140384420055024
	140383267091568 [label="model.model.encoder.features.19.branch2_0.bn.weight
 (384)" fillcolor=lightblue]
	140383267091568 -> 140384420054736
	140384420054736 [label=AccumulateGrad]
	140384420054784 -> 140384420055024
	140383267091648 [label="model.model.encoder.features.19.branch2_0.bn.bias
 (384)" fillcolor=lightblue]
	140383267091648 -> 140384420054784
	140384420054784 [label=AccumulateGrad]
	140384420054544 -> 140384420053776
	140383267092128 [label="model.model.encoder.features.19.branch2_1.conv.weight
 (448, 384, 3, 1)" fillcolor=lightblue]
	140383267092128 -> 140384420054544
	140384420054544 [label=AccumulateGrad]
	140384420054064 -> 140384420053536
	140383267092208 [label="model.model.encoder.features.19.branch2_1.bn.weight
 (448)" fillcolor=lightblue]
	140383267092208 -> 140384420054064
	140384420054064 [label=AccumulateGrad]
	140384420053296 -> 140384420053536
	140383267092288 [label="model.model.encoder.features.19.branch2_1.bn.bias
 (448)" fillcolor=lightblue]
	140383267092288 -> 140384420053296
	140384420053296 [label=AccumulateGrad]
	140384420053152 -> 140384420020080
	140383267092768 [label="model.model.encoder.features.19.branch2_2.conv.weight
 (512, 448, 1, 3)" fillcolor=lightblue]
	140383267092768 -> 140384420053152
	140384420053152 [label=AccumulateGrad]
	140384420019840 -> 140384420020128
	140383267092848 [label="model.model.encoder.features.19.branch2_2.bn.weight
 (512)" fillcolor=lightblue]
	140383267092848 -> 140384420019840
	140384420019840 [label=AccumulateGrad]
	140384420053200 -> 140384420020128
	140383267092928 [label="model.model.encoder.features.19.branch2_2.bn.bias
 (512)" fillcolor=lightblue]
	140383267092928 -> 140384420053200
	140384420053200 [label=AccumulateGrad]
	140384420019360 -> 140384420018160
	140383267093328 [label="model.model.encoder.features.19.branch2_3a.conv.weight
 (256, 512, 1, 3)" fillcolor=lightblue]
	140383267093328 -> 140384420019360
	140384420019360 [label=AccumulateGrad]
	140384420017920 -> 140384420017680
	140383267093408 [label="model.model.encoder.features.19.branch2_3a.bn.weight
 (256)" fillcolor=lightblue]
	140383267093408 -> 140384420017920
	140384420017920 [label=AccumulateGrad]
	140384420017200 -> 140384420017680
	140383267093488 [label="model.model.encoder.features.19.branch2_3a.bn.bias
 (256)" fillcolor=lightblue]
	140383267093488 -> 140384420017200
	140384420017200 [label=AccumulateGrad]
	140384420015760 -> 140383267781264
	140384420015760 [label=ReluBackward0]
	140384420018640 -> 140384420015760
	140384420018640 [label=CudnnBatchNormBackward0]
	140384420019600 -> 140384420018640
	140384420019600 [label=ConvolutionBackward0]
	140384420019120 -> 140384420019600
	140384420053824 -> 140384420019600
	140383267093888 [label="model.model.encoder.features.19.branch2_3b.conv.weight
 (256, 512, 3, 1)" fillcolor=lightblue]
	140383267093888 -> 140384420053824
	140384420053824 [label=AccumulateGrad]
	140384420018400 -> 140384420018640
	140383267093968 [label="model.model.encoder.features.19.branch2_3b.bn.weight
 (256)" fillcolor=lightblue]
	140383267093968 -> 140384420018400
	140384420018400 [label=AccumulateGrad]
	140384420053344 -> 140384420018640
	140383267094048 [label="model.model.encoder.features.19.branch2_3b.bn.bias
 (256)" fillcolor=lightblue]
	140383267094048 -> 140384420053344
	140384420053344 [label=AccumulateGrad]
	140383267781600 -> 140383267781312
	140383267781600 [label=ReluBackward0]
	140384420018880 -> 140383267781600
	140384420018880 [label=CudnnBatchNormBackward0]
	140384420054976 -> 140384420018880
	140384420054976 [label=ConvolutionBackward0]
	140384420055984 -> 140384420054976
	140384420055984 [label=AvgPool2DBackward0]
	140383267782320 -> 140384420055984
	140384420054496 -> 140384420054976
	140383266987104 [label="model.model.encoder.features.19.branch3.1.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140383266987104 -> 140384420054496
	140384420054496 [label=AccumulateGrad]
	140384420054304 -> 140384420018880
	140383266987664 [label="model.model.encoder.features.19.branch3.1.bn.weight
 (256)" fillcolor=lightblue]
	140383266987664 -> 140384420054304
	140384420054304 [label=AccumulateGrad]
	140384420053056 -> 140384420018880
	140383266987504 [label="model.model.encoder.features.19.branch3.1.bn.bias
 (256)" fillcolor=lightblue]
	140383266987504 -> 140384420053056
	140384420053056 [label=AccumulateGrad]
	140383267781120 -> 140383267781024
	140383266987024 [label="model.model.encoder.features.20.branch0.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140383266987024 -> 140383267781120
	140383267781120 [label=AccumulateGrad]
	140383267780832 -> 140383267780880
	140383266986784 [label="model.model.encoder.features.20.branch0.bn.weight
 (256)" fillcolor=lightblue]
	140383266986784 -> 140383267780832
	140383267780832 [label=AccumulateGrad]
	140383267780736 -> 140383267780880
	140383266986944 [label="model.model.encoder.features.20.branch0.bn.bias
 (256)" fillcolor=lightblue]
	140383266986944 -> 140383267780736
	140383267780736 [label=AccumulateGrad]
	140383267780448 -> 140383267780304
	140383267780448 [label=CatBackward0]
	140384420009760 -> 140383267780448
	140384420009760 [label=ReluBackward0]
	140383267781552 -> 140384420009760
	140383267781552 [label=CudnnBatchNormBackward0]
	140384420055456 -> 140383267781552
	140384420055456 [label=ConvolutionBackward0]
	140384420055936 -> 140384420055456
	140384420055936 [label=ReluBackward0]
	140384420056608 -> 140384420055936
	140384420056608 [label=CudnnBatchNormBackward0]
	140384420056848 -> 140384420056608
	140384420056848 [label=ConvolutionBackward0]
	140383267781312 -> 140384420056848
	140384420057232 -> 140384420056848
	140384415580384 [label="model.model.encoder.features.20.branch1_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140384415580384 -> 140384420057232
	140384420057232 [label=AccumulateGrad]
	140384420056416 -> 140384420056608
	140384415583184 [label="model.model.encoder.features.20.branch1_0.bn.weight
 (384)" fillcolor=lightblue]
	140384415583184 -> 140384420056416
	140384420056416 [label=AccumulateGrad]
	140384420056464 -> 140384420056608
	140384415587584 [label="model.model.encoder.features.20.branch1_0.bn.bias
 (384)" fillcolor=lightblue]
	140384415587584 -> 140384420056464
	140384420056464 [label=AccumulateGrad]
	140384420056224 -> 140384420055456
	140384415595984 [label="model.model.encoder.features.20.branch1_1a.conv.weight
 (256, 384, 1, 3)" fillcolor=lightblue]
	140384415595984 -> 140384420056224
	140384420056224 [label=AccumulateGrad]
	140384420054016 -> 140383267781552
	140384415595744 [label="model.model.encoder.features.20.branch1_1a.bn.weight
 (256)" fillcolor=lightblue]
	140384415595744 -> 140384420054016
	140384420054016 [label=AccumulateGrad]
	140384420055216 -> 140383267781552
	140384415595424 [label="model.model.encoder.features.20.branch1_1a.bn.bias
 (256)" fillcolor=lightblue]
	140384415595424 -> 140384420055216
	140384420055216 [label=AccumulateGrad]
	140383267780976 -> 140383267780448
	140383267780976 [label=ReluBackward0]
	140383267781168 -> 140383267780976
	140383267781168 [label=CudnnBatchNormBackward0]
	140384420056560 -> 140383267781168
	140384420056560 [label=ConvolutionBackward0]
	140384420055936 -> 140384420056560
	140384420056992 -> 140384420056560
	140384415594624 [label="model.model.encoder.features.20.branch1_1b.conv.weight
 (256, 384, 3, 1)" fillcolor=lightblue]
	140384415594624 -> 140384420056992
	140384420056992 [label=AccumulateGrad]
	140384420056800 -> 140383267781168
	140384415594464 [label="model.model.encoder.features.20.branch1_1b.bn.weight
 (256)" fillcolor=lightblue]
	140384415594464 -> 140384420056800
	140384420056800 [label=AccumulateGrad]
	140384420055504 -> 140383267781168
	140384415594384 [label="model.model.encoder.features.20.branch1_1b.bn.bias
 (256)" fillcolor=lightblue]
	140384415594384 -> 140384420055504
	140384420055504 [label=AccumulateGrad]
	140383267780256 -> 140383267780304
	140383267780256 [label=CatBackward0]
	140383267780688 -> 140383267780256
	140383267780688 [label=ReluBackward0]
	140384420057184 -> 140383267780688
	140384420057184 [label=CudnnBatchNormBackward0]
	140384420057424 -> 140384420057184
	140384420057424 [label=ConvolutionBackward0]
	140384420057808 -> 140384420057424
	140384420057808 [label=ReluBackward0]
	140384420058576 -> 140384420057808
	140384420058576 [label=CudnnBatchNormBackward0]
	140384420058816 -> 140384420058576
	140384420058816 [label=ConvolutionBackward0]
	140384420059200 -> 140384420058816
	140384420059200 [label=ReluBackward0]
	140384420059152 -> 140384420059200
	140384420059152 [label=CudnnBatchNormBackward0]
	140384420059392 -> 140384420059152
	140384420059392 [label=ConvolutionBackward0]
	140384420059872 -> 140384420059392
	140384420059872 [label=ReluBackward0]
	140384420060544 -> 140384420059872
	140384420060544 [label=CudnnBatchNormBackward0]
	140384420060784 -> 140384420060544
	140384420060784 [label=ConvolutionBackward0]
	140383267781312 -> 140384420060784
	140384420061168 -> 140384420060784
	140384415593264 [label="model.model.encoder.features.20.branch2_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140384415593264 -> 140384420061168
	140384420061168 [label=AccumulateGrad]
	140384420060352 -> 140384420060544
	140384415593104 [label="model.model.encoder.features.20.branch2_0.bn.weight
 (384)" fillcolor=lightblue]
	140384415593104 -> 140384420060352
	140384420060352 [label=AccumulateGrad]
	140384420060400 -> 140384420060544
	140384415593024 [label="model.model.encoder.features.20.branch2_0.bn.bias
 (384)" fillcolor=lightblue]
	140384415593024 -> 140384420060400
	140384420060400 [label=AccumulateGrad]
	140384420060160 -> 140384420059392
	140384415591904 [label="model.model.encoder.features.20.branch2_1.conv.weight
 (448, 384, 3, 1)" fillcolor=lightblue]
	140384415591904 -> 140384420060160
	140384420060160 [label=AccumulateGrad]
	140384420059680 -> 140384420059152
	140384415591584 [label="model.model.encoder.features.20.branch2_1.bn.weight
 (448)" fillcolor=lightblue]
	140384415591584 -> 140384420059680
	140384420059680 [label=AccumulateGrad]
	140384420059008 -> 140384420059152
	140384415591344 [label="model.model.encoder.features.20.branch2_1.bn.bias
 (448)" fillcolor=lightblue]
	140384415591344 -> 140384420059008
	140384420059008 [label=AccumulateGrad]
	140384420058768 -> 140384420058816
	140384415590464 [label="model.model.encoder.features.20.branch2_2.conv.weight
 (512, 448, 1, 3)" fillcolor=lightblue]
	140384415590464 -> 140384420058768
	140384420058768 [label=AccumulateGrad]
	140384420058288 -> 140384420058576
	140384415590384 [label="model.model.encoder.features.20.branch2_2.bn.weight
 (512)" fillcolor=lightblue]
	140384415590384 -> 140384420058288
	140384420058288 [label=AccumulateGrad]
	140384420058336 -> 140384420058576
	140384415590224 [label="model.model.encoder.features.20.branch2_2.bn.bias
 (512)" fillcolor=lightblue]
	140384415590224 -> 140384420058336
	140384420058336 [label=AccumulateGrad]
	140384420058096 -> 140384420057424
	140384415589424 [label="model.model.encoder.features.20.branch2_3a.conv.weight
 (256, 512, 1, 3)" fillcolor=lightblue]
	140384415589424 -> 140384420058096
	140384420058096 [label=AccumulateGrad]
	140384420057472 -> 140384420057184
	140384415589344 [label="model.model.encoder.features.20.branch2_3a.bn.weight
 (256)" fillcolor=lightblue]
	140384415589344 -> 140384420057472
	140384420057472 [label=AccumulateGrad]
	140384420056944 -> 140384420057184
	140384415589184 [label="model.model.encoder.features.20.branch2_3a.bn.bias
 (256)" fillcolor=lightblue]
	140384415589184 -> 140384420056944
	140384420056944 [label=AccumulateGrad]
	140384420056176 -> 140383267780256
	140384420056176 [label=ReluBackward0]
	140384420057664 -> 140384420056176
	140384420057664 [label=CudnnBatchNormBackward0]
	140384420058528 -> 140384420057664
	140384420058528 [label=ConvolutionBackward0]
	140384420057808 -> 140384420058528
	140384420059440 -> 140384420058528
	140384415587664 [label="model.model.encoder.features.20.branch2_3b.conv.weight
 (256, 512, 3, 1)" fillcolor=lightblue]
	140384415587664 -> 140384420059440
	140384420059440 [label=AccumulateGrad]
	140384420059056 -> 140384420057664
	140384415587504 [label="model.model.encoder.features.20.branch2_3b.bn.weight
 (256)" fillcolor=lightblue]
	140384415587504 -> 140384420059056
	140384420059056 [label=AccumulateGrad]
	140384420057712 -> 140384420057664
	140384415587184 [label="model.model.encoder.features.20.branch2_3b.bn.bias
 (256)" fillcolor=lightblue]
	140384415587184 -> 140384420057712
	140384420057712 [label=AccumulateGrad]
	140383267780592 -> 140383267780304
	140383267780592 [label=ReluBackward0]
	140384420058048 -> 140383267780592
	140384420058048 [label=CudnnBatchNormBackward0]
	140384420060496 -> 140384420058048
	140384420060496 [label=ConvolutionBackward0]
	140384420061408 -> 140384420060496
	140384420061408 [label=AvgPool2DBackward0]
	140383267781312 -> 140384420061408
	140384420060112 -> 140384420060496
	140384415585984 [label="model.model.encoder.features.20.branch3.1.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140384415585984 -> 140384420060112
	140384420060112 [label=AccumulateGrad]
	140384420059920 -> 140384420058048
	140384415585744 [label="model.model.encoder.features.20.branch3.1.bn.weight
 (256)" fillcolor=lightblue]
	140384415585744 -> 140384420059920
	140384420059920 [label=AccumulateGrad]
	140384420055696 -> 140384420058048
	140384415585504 [label="model.model.encoder.features.20.branch3.1.bn.bias
 (256)" fillcolor=lightblue]
	140384415585504 -> 140384420055696
	140384420055696 [label=AccumulateGrad]
	140383267780112 -> 140383267780016
	140384415584624 [label="model.model.encoder.features.21.branch0.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140384415584624 -> 140383267780112
	140383267780112 [label=AccumulateGrad]
	140383267779824 -> 140383267779872
	140384415584464 [label="model.model.encoder.features.21.branch0.bn.weight
 (256)" fillcolor=lightblue]
	140384415584464 -> 140383267779824
	140383267779824 [label=AccumulateGrad]
	140383267779728 -> 140383267779872
	140384415584384 [label="model.model.encoder.features.21.branch0.bn.bias
 (256)" fillcolor=lightblue]
	140384415584384 -> 140383267779728
	140383267779728 [label=AccumulateGrad]
	140383267779440 -> 140383267779248
	140383267779440 [label=CatBackward0]
	140383267780160 -> 140383267779440
	140383267780160 [label=ReluBackward0]
	140383267780544 -> 140383267780160
	140383267780544 [label=CudnnBatchNormBackward0]
	140384420060976 -> 140383267780544
	140384420060976 [label=ConvolutionBackward0]
	140384420061360 -> 140384420060976
	140384420061360 [label=ReluBackward0]
	140384420062032 -> 140384420061360
	140384420062032 [label=CudnnBatchNormBackward0]
	140384420062272 -> 140384420062032
	140384420062272 [label=ConvolutionBackward0]
	140383267780304 -> 140384420062272
	140384420062752 -> 140384420062272
	140384415582784 [label="model.model.encoder.features.21.branch1_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140384415582784 -> 140384420062752
	140384420062752 [label=AccumulateGrad]
	140384420061744 -> 140384420062032
	140384415582464 [label="model.model.encoder.features.21.branch1_0.bn.weight
 (384)" fillcolor=lightblue]
	140384415582464 -> 140384420061744
	140384420061744 [label=AccumulateGrad]
	140384420061792 -> 140384420062032
	140384415582304 [label="model.model.encoder.features.21.branch1_0.bn.bias
 (384)" fillcolor=lightblue]
	140384415582304 -> 140384420061792
	140384420061792 [label=AccumulateGrad]
	140384420061552 -> 140384420060976
	140384415581344 [label="model.model.encoder.features.21.branch1_1a.conv.weight
 (256, 384, 1, 3)" fillcolor=lightblue]
	140384415581344 -> 140384420061552
	140384420061552 [label=AccumulateGrad]
	140384420059632 -> 140383267780544
	140384415581024 [label="model.model.encoder.features.21.branch1_1a.bn.weight
 (256)" fillcolor=lightblue]
	140384415581024 -> 140384420059632
	140384420059632 [label=AccumulateGrad]
	140384420060736 -> 140383267780544
	140384415580784 [label="model.model.encoder.features.21.branch1_1a.bn.bias
 (256)" fillcolor=lightblue]
	140384415580784 -> 140384420060736
	140384420060736 [label=AccumulateGrad]
	140383267779968 -> 140383267779440
	140383267779968 [label=ReluBackward0]
	140384420061120 -> 140383267779968
	140384420061120 [label=CudnnBatchNormBackward0]
	140384420061984 -> 140384420061120
	140384420061984 [label=ConvolutionBackward0]
	140384420061360 -> 140384420061984
	140384420062512 -> 140384420061984
	140384427121600 [label="model.model.encoder.features.21.branch1_1b.conv.weight
 (256, 384, 3, 1)" fillcolor=lightblue]
	140384427121600 -> 140384420062512
	140384420062512 [label=AccumulateGrad]
	140384420062224 -> 140384420061120
	140384427127840 [label="model.model.encoder.features.21.branch1_1b.bn.weight
 (256)" fillcolor=lightblue]
	140384427127840 -> 140384420062224
	140384420062224 [label=AccumulateGrad]
	140384420057856 -> 140384420061120
	140384427128960 [label="model.model.encoder.features.21.branch1_1b.bn.bias
 (256)" fillcolor=lightblue]
	140384427128960 -> 140384420057856
	140384420057856 [label=AccumulateGrad]
	140383267779104 -> 140383267779248
	140383267779104 [label=CatBackward0]
	140383267779680 -> 140383267779104
	140383267779680 [label=ReluBackward0]
	140384420062704 -> 140383267779680
	140384420062704 [label=CudnnBatchNormBackward0]
	140384420062944 -> 140384420062704
	140384420062944 [label=ConvolutionBackward0]
	140384420063424 -> 140384420062944
	140384420063424 [label=ReluBackward0]
	140384420064096 -> 140384420063424
	140384420064096 [label=CudnnBatchNormBackward0]
	140384420064336 -> 140384420064096
	140384420064336 [label=ConvolutionBackward0]
	140384420064720 -> 140384420064336
	140384420064720 [label=ReluBackward0]
	140384420064672 -> 140384420064720
	140384420064672 [label=CudnnBatchNormBackward0]
	140384420064912 -> 140384420064672
	140384420064912 [label=ConvolutionBackward0]
	140384420065392 -> 140384420064912
	140384420065392 [label=ReluBackward0]
	140384420066160 -> 140384420065392
	140384420066160 [label=CudnnBatchNormBackward0]
	140384420066400 -> 140384420066160
	140384420066400 [label=ConvolutionBackward0]
	140383267780304 -> 140384420066400
	140384420066784 -> 140384420066400
	140384427126000 [label="model.model.encoder.features.21.branch2_0.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	140384427126000 -> 140384420066784
	140384420066784 [label=AccumulateGrad]
	140384420065872 -> 140384420066160
	140384427125920 [label="model.model.encoder.features.21.branch2_0.bn.weight
 (384)" fillcolor=lightblue]
	140384427125920 -> 140384420065872
	140384420065872 [label=AccumulateGrad]
	140384420065920 -> 140384420066160
	140384427125680 [label="model.model.encoder.features.21.branch2_0.bn.bias
 (384)" fillcolor=lightblue]
	140384427125680 -> 140384420065920
	140384420065920 [label=AccumulateGrad]
	140384420065680 -> 140384420064912
	140384427123280 [label="model.model.encoder.features.21.branch2_1.conv.weight
 (448, 384, 3, 1)" fillcolor=lightblue]
	140384427123280 -> 140384420065680
	140384420065680 [label=AccumulateGrad]
	140384420065200 -> 140384420064672
	140384427122960 [label="model.model.encoder.features.21.branch2_1.bn.weight
 (448)" fillcolor=lightblue]
	140384427122960 -> 140384420065200
	140384420065200 [label=AccumulateGrad]
	140384420064432 -> 140384420064672
	140384427122160 [label="model.model.encoder.features.21.branch2_1.bn.bias
 (448)" fillcolor=lightblue]
	140384427122160 -> 140384420064432
	140384420064432 [label=AccumulateGrad]
	140384420064288 -> 140384420064336
	140384427115520 [label="model.model.encoder.features.21.branch2_2.conv.weight
 (512, 448, 1, 3)" fillcolor=lightblue]
	140384427115520 -> 140384420064288
	140384420064288 [label=AccumulateGrad]
	140384420063904 -> 140384420064096
	140384427124720 [label="model.model.encoder.features.21.branch2_2.bn.weight
 (512)" fillcolor=lightblue]
	140384427124720 -> 140384420063904
	140384420063904 [label=AccumulateGrad]
	140384420063952 -> 140384420064096
	140384427115920 [label="model.model.encoder.features.21.branch2_2.bn.bias
 (512)" fillcolor=lightblue]
	140384427115920 -> 140384420063952
	140384420063952 [label=AccumulateGrad]
	140384420063712 -> 140384420062944
	140384427129200 [label="model.model.encoder.features.21.branch2_3a.conv.weight
 (256, 512, 1, 3)" fillcolor=lightblue]
	140384427129200 -> 140384420063712
	140384420063712 [label=AccumulateGrad]
	140384420062992 -> 140384420062704
	140384427128240 [label="model.model.encoder.features.21.branch2_3a.bn.weight
 (256)" fillcolor=lightblue]
	140384427128240 -> 140384420062992
	140384420062992 [label=AccumulateGrad]
	140384420062464 -> 140384420062704
	140384427127440 [label="model.model.encoder.features.21.branch2_3a.bn.bias
 (256)" fillcolor=lightblue]
	140384427127440 -> 140384420062464
	140384420062464 [label=AccumulateGrad]
	140384420061504 -> 140383267779104
	140384420061504 [label=ReluBackward0]
	140384420063184 -> 140384420061504
	140384420063184 [label=CudnnBatchNormBackward0]
	140384420064048 -> 140384420063184
	140384420064048 [label=ConvolutionBackward0]
	140384420063424 -> 140384420064048
	140384420064960 -> 140384420064048
	140384427124480 [label="model.model.encoder.features.21.branch2_3b.conv.weight
 (256, 512, 3, 1)" fillcolor=lightblue]
	140384427124480 -> 140384420064960
	140384420064960 [label=AccumulateGrad]
	140384420064480 -> 140384420063184
	140384427123920 [label="model.model.encoder.features.21.branch2_3b.bn.weight
 (256)" fillcolor=lightblue]
	140384427123920 -> 140384420064480
	140384420064480 [label=AccumulateGrad]
	140384420063232 -> 140384420063184
	140384427123840 [label="model.model.encoder.features.21.branch2_3b.bn.bias
 (256)" fillcolor=lightblue]
	140384427123840 -> 140384420063232
	140384420063232 [label=AccumulateGrad]
	140383267779584 -> 140383267779248
	140383267779584 [label=ReluBackward0]
	140384420063664 -> 140383267779584
	140384420063664 [label=CudnnBatchNormBackward0]
	140384420066112 -> 140384420063664
	140384420066112 [label=ConvolutionBackward0]
	140384420067024 -> 140384420066112
	140384420067024 [label=AvgPool2DBackward0]
	140383267780304 -> 140384420067024
	140384420065632 -> 140384420066112
	140384427120000 [label="model.model.encoder.features.21.branch3.1.conv.weight
 (256, 1536, 1, 1)" fillcolor=lightblue]
	140384427120000 -> 140384420065632
	140384420065632 [label=AccumulateGrad]
	140384420065440 -> 140384420063664
	140384427119760 [label="model.model.encoder.features.21.branch3.1.bn.weight
 (256)" fillcolor=lightblue]
	140384427119760 -> 140384420065440
	140384420065440 [label=AccumulateGrad]
	140384420061024 -> 140384420063664
	140384427119680 [label="model.model.encoder.features.21.branch3.1.bn.bias
 (256)" fillcolor=lightblue]
	140384427119680 -> 140384420061024
	140384420061024 [label=AccumulateGrad]
	140383267778960 -> 140383267778816
	140383267778864 -> 140383267778528
	140384418299424 [label="model.model.decoder.blocks.0.conv1.0.weight
 (256, 2560, 3, 3)" fillcolor=lightblue]
	140384418299424 -> 140383267778864
	140383267778864 [label=AccumulateGrad]
	140383267778576 -> 140383267778384
	140384418299344 [label="model.model.decoder.blocks.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	140384418299344 -> 140383267778576
	140383267778576 [label=AccumulateGrad]
	140383267778240 -> 140383267778384
	140384418299264 [label="model.model.decoder.blocks.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	140384418299264 -> 140383267778240
	140383267778240 [label=AccumulateGrad]
	140383267778096 -> 140383267778000
	140384418298704 [label="model.model.decoder.blocks.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140384418298704 -> 140383267778096
	140383267778096 [label=AccumulateGrad]
	140383267777808 -> 140383267777856
	140384418298624 [label="model.model.decoder.blocks.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	140384418298624 -> 140383267777808
	140383267777808 [label=AccumulateGrad]
	140383267770128 -> 140383267777856
	140384418298464 [label="model.model.decoder.blocks.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	140384418298464 -> 140383267770128
	140383267770128 [label=AccumulateGrad]
	140383267769984 -> 140383267769840
	140383267769648 -> 140383267777664
	140384418297824 [label="model.model.decoder.blocks.1.conv1.0.weight
 (128, 640, 3, 3)" fillcolor=lightblue]
	140384418297824 -> 140383267769648
	140383267769648 [label=AccumulateGrad]
	140383267770416 -> 140383267770368
	140384418297744 [label="model.model.decoder.blocks.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	140384418297744 -> 140383267770416
	140383267770416 [label=AccumulateGrad]
	140383267770512 -> 140383267770368
	140384418297584 [label="model.model.decoder.blocks.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	140384418297584 -> 140383267770512
	140383267770512 [label=AccumulateGrad]
	140383267770800 -> 140383267771136
	140384418296864 [label="model.model.decoder.blocks.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140384418296864 -> 140383267770800
	140383267770800 [label=AccumulateGrad]
	140383267771232 -> 140383267771280
	140384418296624 [label="model.model.decoder.blocks.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	140384418296624 -> 140383267771232
	140383267771232 [label=AccumulateGrad]
	140383267771712 -> 140383267771280
	140384418296464 [label="model.model.decoder.blocks.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	140384418296464 -> 140383267771712
	140383267771712 [label=AccumulateGrad]
	140383267772000 -> 140383267772288
	140383267772528 -> 140383267772720
	140384418295904 [label="model.model.decoder.blocks.2.conv1.0.weight
 (64, 320, 3, 3)" fillcolor=lightblue]
	140384418295904 -> 140383267772528
	140383267772528 [label=AccumulateGrad]
	140383267772816 -> 140383267772864
	140384418295824 [label="model.model.decoder.blocks.2.conv1.1.weight
 (64)" fillcolor=lightblue]
	140384418295824 -> 140383267772816
	140383267772816 [label=AccumulateGrad]
	140383267773152 -> 140383267772864
	140384418295664 [label="model.model.decoder.blocks.2.conv1.1.bias
 (64)" fillcolor=lightblue]
	140384418295664 -> 140383267773152
	140383267773152 [label=AccumulateGrad]
	140383267773296 -> 140383267773920
	140384418295024 [label="model.model.decoder.blocks.2.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140384418295024 -> 140383267773296
	140383267773296 [label=AccumulateGrad]
	140383267773872 -> 140383267774112
	140384418294944 [label="model.model.decoder.blocks.2.conv2.1.weight
 (64)" fillcolor=lightblue]
	140384418294944 -> 140383267773872
	140383267773872 [label=AccumulateGrad]
	140383267774544 -> 140383267774112
	140384418294784 [label="model.model.decoder.blocks.2.conv2.1.bias
 (64)" fillcolor=lightblue]
	140384418294784 -> 140383267774544
	140383267774544 [label=AccumulateGrad]
	140383267774832 -> 140383267775120
	140383267775168 -> 140383267775552
	140384418293744 [label="model.model.decoder.blocks.3.conv1.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	140384418293744 -> 140383267775168
	140383267775168 [label=AccumulateGrad]
	140383267775600 -> 140383267775696
	140384418293584 [label="model.model.decoder.blocks.3.conv1.1.weight
 (32)" fillcolor=lightblue]
	140384418293584 -> 140383267775600
	140383267775600 [label=AccumulateGrad]
	140383267775984 -> 140383267775696
	140384418293504 [label="model.model.decoder.blocks.3.conv1.1.bias
 (32)" fillcolor=lightblue]
	140384418293504 -> 140383267775984
	140383267775984 [label=AccumulateGrad]
	140383267776272 -> 140383267776608
	140384418292864 [label="model.model.decoder.blocks.3.conv2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140384418292864 -> 140383267776272
	140383267776272 [label=AccumulateGrad]
	140383267776848 -> 140383267776896
	140384418292704 [label="model.model.decoder.blocks.3.conv2.1.weight
 (32)" fillcolor=lightblue]
	140384418292704 -> 140383267776848
	140383267776848 [label=AccumulateGrad]
	140383267777184 -> 140383267776896
	140384418292624 [label="model.model.decoder.blocks.3.conv2.1.bias
 (32)" fillcolor=lightblue]
	140384418292624 -> 140383267777184
	140383267777184 [label=AccumulateGrad]
	140383267777424 -> 140384425703984
	140384418291904 [label="model.model.decoder.blocks.4.conv1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	140384418291904 -> 140383267777424
	140383267777424 [label=AccumulateGrad]
	140384425702112 -> 140384425690400
	140384418291824 [label="model.model.decoder.blocks.4.conv1.1.weight
 (16)" fillcolor=lightblue]
	140384418291824 -> 140384425702112
	140384425702112 [label=AccumulateGrad]
	140384425695344 -> 140384425690400
	140384418291664 [label="model.model.decoder.blocks.4.conv1.1.bias
 (16)" fillcolor=lightblue]
	140384418291664 -> 140384425695344
	140384425695344 [label=AccumulateGrad]
	140384425699088 -> 140384425698368
	140384418290944 [label="model.model.decoder.blocks.4.conv2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140384418290944 -> 140384425699088
	140384425699088 [label=AccumulateGrad]
	140384425702208 -> 140384425700192
	140384418290864 [label="model.model.decoder.blocks.4.conv2.1.weight
 (16)" fillcolor=lightblue]
	140384418290864 -> 140384425702208
	140384425702208 [label=AccumulateGrad]
	140384425696928 -> 140384425700192
	140384418290704 [label="model.model.decoder.blocks.4.conv2.1.bias
 (16)" fillcolor=lightblue]
	140384418290704 -> 140384425696928
	140384425696928 [label=AccumulateGrad]
	140384425702784 -> 140384425699520
	140384418289984 [label="model.model.segmentation_head.0.weight
 (1, 16, 3, 3)" fillcolor=lightblue]
	140384418289984 -> 140384425702784
	140384425702784 [label=AccumulateGrad]
	140384425698752 -> 140384425699520
	140384418289824 [label="model.model.segmentation_head.0.bias
 (1)" fillcolor=lightblue]
	140384418289824 -> 140384425698752
	140384425698752 [label=AccumulateGrad]
	140384425699520 -> 140384419991440
}
